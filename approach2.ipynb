{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code for Approach 2 mentioned in the project report.\n",
    "We train an auxillary network to take LLaMA embeddings as input to play the game TicTacToe.\n",
    "The MCTS part of the code is adopted from https://github.com/suragnair/alpha-zero-general\n",
    "The checkpoint for the testing results showed in the paper is available upon request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "veY59RpiitlD",
    "outputId": "ddd0309b-be8b-48ae-ff31-88fc57d98b0d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git: 'lfs' is not a git command. See 'git --help'.\n",
      "\n",
      "The most similar command is\n",
      "\tlog\n",
      "fatal: destination path 'alpaca-lora-7b' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git lfs install\n",
    "!git clone https://huggingface.co/tloen/alpaca-lora-7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FpJI0exijME-",
    "outputId": "482a313e-68cf-4523-9ec4-be7daa8a66de",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'alpaca-lora' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tloen/alpaca-lora.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFMfcsD3i57d",
    "outputId": "572aef41-1f11-4e83-971c-b232e1561b05",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting git+https://github.com/huggingface/peft.git (from -r alpaca-lora/requirements.txt (line 9))\n",
      "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-yw8e4sa5\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-yw8e4sa5\n",
      "  Resolved https://github.com/huggingface/peft.git to commit 632997d1fb776c3cf05d8c2537ac9a98a7ce9435\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r alpaca-lora/requirements.txt (line 1)) (0.18.0)\n",
      "Requirement already satisfied: appdirs in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r alpaca-lora/requirements.txt (line 2)) (1.4.4)\n",
      "Requirement already satisfied: loralib in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r alpaca-lora/requirements.txt (line 3)) (0.1.1)\n",
      "Requirement already satisfied: bitsandbytes in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r alpaca-lora/requirements.txt (line 4)) (0.38.1)\n",
      "Requirement already satisfied: black in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r alpaca-lora/requirements.txt (line 5)) (22.10.0)\n",
      "Requirement already satisfied: datasets in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r alpaca-lora/requirements.txt (line 7)) (2.12.0)\n",
      "Requirement already satisfied: fire in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r alpaca-lora/requirements.txt (line 8)) (0.5.0)\n",
      "Requirement already satisfied: transformers>=4.28.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r alpaca-lora/requirements.txt (line 10)) (4.28.1)\n",
      "Requirement already satisfied: sentencepiece in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r alpaca-lora/requirements.txt (line 11)) (0.1.98)\n",
      "Requirement already satisfied: gradio in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from -r alpaca-lora/requirements.txt (line 12)) (3.28.1)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from accelerate->-r alpaca-lora/requirements.txt (line 1)) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from accelerate->-r alpaca-lora/requirements.txt (line 1)) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from accelerate->-r alpaca-lora/requirements.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from accelerate->-r alpaca-lora/requirements.txt (line 1)) (5.9.4)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from accelerate->-r alpaca-lora/requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from black->-r alpaca-lora/requirements.txt (line 5)) (0.10.3)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from black->-r alpaca-lora/requirements.txt (line 5)) (4.4.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from black->-r alpaca-lora/requirements.txt (line 5)) (0.4.3)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from black->-r alpaca-lora/requirements.txt (line 5)) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from black->-r alpaca-lora/requirements.txt (line 5)) (8.1.3)\n",
      "Requirement already satisfied: platformdirs>=2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from black->-r alpaca-lora/requirements.txt (line 5)) (2.6.2)\n",
      "Requirement already satisfied: ipython>=7.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from black->-r alpaca-lora/requirements.txt (line 5)) (7.32.0)\n",
      "Requirement already satisfied: tokenize-rt>=3.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from black->-r alpaca-lora/requirements.txt (line 5)) (5.0.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (4.63.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (2022.11.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (0.14.1)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (3.8.3)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (0.70.14)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (0.3.6)\n",
      "Requirement already satisfied: responses<0.19 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (0.18.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (2.28.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (10.0.1)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (3.2.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (1.4.4)\n",
      "Requirement already satisfied: termcolor in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from fire->-r alpaca-lora/requirements.txt (line 8)) (2.2.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from fire->-r alpaca-lora/requirements.txt (line 8)) (1.16.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers>=4.28.0->-r alpaca-lora/requirements.txt (line 10)) (3.6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers>=4.28.0->-r alpaca-lora/requirements.txt (line 10)) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from transformers>=4.28.0->-r alpaca-lora/requirements.txt (line 10)) (2022.10.31)\n",
      "Requirement already satisfied: pydub in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (0.25.1)\n",
      "Requirement already satisfied: uvicorn in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (0.22.0)\n",
      "Requirement already satisfied: markupsafe in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (2.1.1)\n",
      "Requirement already satisfied: fastapi in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (0.95.1)\n",
      "Requirement already satisfied: aiofiles in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (23.1.0)\n",
      "Requirement already satisfied: websockets>=10.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (11.0.2)\n",
      "Requirement already satisfied: altair>=4.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (4.2.2)\n",
      "Requirement already satisfied: gradio-client>=0.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (0.1.4)\n",
      "Requirement already satisfied: orjson in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (3.8.11)\n",
      "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (0.3.3)\n",
      "Requirement already satisfied: pydantic in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (1.10.4)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (3.1.2)\n",
      "Requirement already satisfied: semantic-version in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (2.10.0)\n",
      "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (2.2.0)\n",
      "Requirement already satisfied: ffmpy in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (0.3.0)\n",
      "Requirement already satisfied: python-multipart in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (0.0.6)\n",
      "Requirement already satisfied: httpx in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (0.24.0)\n",
      "Requirement already satisfied: pillow in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (9.2.0)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (3.5.3)\n",
      "Requirement already satisfied: toolz in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from altair>=4.2.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (0.12.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from altair>=4.2.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (3.2.0)\n",
      "Requirement already satisfied: entrypoints in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from altair>=4.2.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets->-r alpaca-lora/requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets->-r alpaca-lora/requirements.txt (line 7)) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets->-r alpaca-lora/requirements.txt (line 7)) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets->-r alpaca-lora/requirements.txt (line 7)) (6.0.4)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets->-r alpaca-lora/requirements.txt (line 7)) (2.1.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets->-r alpaca-lora/requirements.txt (line 7)) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from aiohttp->datasets->-r alpaca-lora/requirements.txt (line 7)) (1.8.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.18.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (3.0.36)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (5.8.1)\n",
      "Requirement already satisfied: pygments in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (2.14.0)\n",
      "Requirement already satisfied: matplotlib-inline in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.1.6)\n",
      "Requirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (4.8.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (65.6.3)\n",
      "Requirement already satisfied: backcall in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (0.1.2)\n",
      "Requirement already satisfied: linkify-it-py<3,>=1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (2.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=20.0->accelerate->-r alpaca-lora/requirements.txt (line 1)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas->datasets->-r alpaca-lora/requirements.txt (line 7)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pandas->datasets->-r alpaca-lora/requirements.txt (line 7)) (2022.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests>=2.19.0->datasets->-r alpaca-lora/requirements.txt (line 7)) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests>=2.19.0->datasets->-r alpaca-lora/requirements.txt (line 7)) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests>=2.19.0->datasets->-r alpaca-lora/requirements.txt (line 7)) (1.26.8)\n",
      "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from fastapi->gradio->-r alpaca-lora/requirements.txt (line 12)) (0.26.1)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from httpx->gradio->-r alpaca-lora/requirements.txt (line 12)) (1.3.0)\n",
      "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from httpx->gradio->-r alpaca-lora/requirements.txt (line 12)) (0.17.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib->gradio->-r alpaca-lora/requirements.txt (line 12)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib->gradio->-r alpaca-lora/requirements.txt (line 12)) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from matplotlib->gradio->-r alpaca-lora/requirements.txt (line 12)) (1.4.4)\n",
      "Requirement already satisfied: h11>=0.8 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from uvicorn->gradio->-r alpaca-lora/requirements.txt (line 12)) (0.14.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio->-r alpaca-lora/requirements.txt (line 12)) (3.6.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.8.3)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (0.19.3)\n",
      "Requirement already satisfied: uc-micro-py in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (1.0.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from pexpect>4.3->ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r alpaca-lora/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YFDyLinaiIUz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cJaAB-KMn3yW",
    "outputId": "3c0a6dff-585f-4289-f75c-42177f739c52",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\"decapoda-research/llama-7b-hf\", device_map = \"sequential\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ompDB92V47dd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id = (\n",
    "    0  # unk. we want this to be different from the eos token\n",
    ")\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hvOGrA6N4RsY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids = tokenizer(['   1 2 3 \\n  A |X| |O|\\n  B | |X|X|\\n  C | | |O|\\n', '   1 2 3 \\n  A |O|X|O|\\n  B |X|X| |\\n  C |X|O| |\\n', '   1 2 3 \\n  A |O| |X|\\n  B | |X| |\\n  C | | | |\\n', '   1 2 3 \\n  A | | | |\\n  B | | | |\\n  C | | | |\\n', '   1 2 3 \\n  A |O| | |\\n  B | | | |\\n  C |X| | |\\n', '   1 2 3 \\n  A | | | |\\n  B | | | |\\n  C | | | |\\n', '   1 2 3 \\n  A | | |X|\\n  B | |O| |\\n  C | | | |\\n', '   1 2 3 \\n  A |O| |X|\\n  B | |X| |\\n  C | | | |\\n', '   1 2 3 \\n  A |X|X|O|\\n  B |O|X|X|\\n  C | | |O|\\n', '   1 2 3 \\n  A |X| |O|\\n  B | |X|X|\\n  C | | |O|\\n', '   1 2 3 \\n  A | | | |\\n  B | | | |\\n  C | | | |\\n', '   1 2 3 \\n  A | | | |\\n  B | | | |\\n  C | | | |\\n', '   1 2 3 \\n  A |X|O|X|\\n  B | |O| |\\n  C |O|X| |\\n', '   1 2 3 \\n  A | | | |\\n  B | | | |\\n  C | | | |\\n', '   1 2 3 \\n  A |O| |X|\\n  B |X|X| |\\n  C |O| | |\\n', '   1 2 3 \\n  A | | | |\\n  B | | | |\\n  C | | | |\\n', '   1 2 3 \\n  A | | | |\\n  B | | | |\\n  C | | | |\\n', '   1 2 3 \\n  A |O| | |\\n  B | |O| |\\n  C |X| |X|\\n', '   1 2 3 \\n  A | | | |\\n  B | |X| |\\n  C | | | |\\n', '   1 2 3 \\n  A | | | |\\n  B | |X| |\\n  C |X| |O|\\n', '   1 2 3 \\n  A | |X|X|\\n  B | | | |\\n  C | | |O|\\n', '   1 2 3 \\n  A |O|X|X|\\n  B |X|X|O|\\n  C |O| | |\\n', '   1 2 3 \\n  A |X| | |\\n  B | |O| |\\n  C | | | |\\n', '   1 2 3 \\n  A | | | |\\n  B | |X| |\\n  C | | | |\\n', '   1 2 3 \\n  A | | | |\\n  B | |X| |\\n  C | | | |\\n', '   1 2 3 \\n  A |X|X| |\\n  B | | | |\\n  C |O| | |\\n', '   1 2 3 \\n  A |X| |X|\\n  B | |O| |\\n  C | | |O|\\n', '   1 2 3 \\n  A |O|X|O|\\n  B |X|X| |\\n  C |X|O| |\\n', '   1 2 3 \\n  A | | |X|\\n  B | | | |\\n  C | | | |\\n', '   1 2 3 \\n  A |O|X|O|\\n  B |X|X| |\\n  C |X|O| |\\n', '   1 2 3 \\n  A | | | |\\n  B | |X| |\\n  C | | | |\\n', '   1 2 3 \\n  A |X| |X|\\n  B | |O| |\\n  C | | |O|\\n'],return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M34vE1em4oei",
    "outputId": "6a1e0c82-d169-441e-cf1f-f01196230845",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,     0,     0,  ..., 29949, 29989,    13],\n",
       "        [    0,   268, 29896,  ..., 29989,   891,    13],\n",
       "        [    0,     0,     0,  ...,   891,   891,    13],\n",
       "        ...,\n",
       "        [    0,   268, 29896,  ..., 29989,   891,    13],\n",
       "        [    0,     0,     0,  ...,   891,   891,    13],\n",
       "        [    0,     0,     0,  ..., 29949, 29989,    13]]), 'attention_mask': tensor([[0, 0, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1],\n",
       "        [0, 0, 0,  ..., 1, 1, 1]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TeU_IEaZ5dug",
    "outputId": "4b3efc0d-1d1c-44ca-8012-167a557e481e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,  ..., 29949, 29989,    13],\n",
       "        [    0,   268, 29896,  ..., 29989,   891,    13],\n",
       "        [    0,     0,     0,  ...,   891,   891,    13],\n",
       "        ...,\n",
       "        [    0,   268, 29896,  ..., 29989,   891,    13],\n",
       "        [    0,     0,     0,  ...,   891,   891,    13],\n",
       "        [    0,     0,     0,  ..., 29949, 29989,    13]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605,
     "referenced_widgets": [
      "88c4db8b412244caacca55ec5d7828f0",
      "f27fc1ca21624218a069e554859ecf06",
      "e834f9fa03434737b116fbf3a808c12f",
      "c7ab2c7f31b04358bac9f0fdf1306503",
      "747456c4a45140d98f6e3beb2ae705c0",
      "366713dc81e0475b8787e0d5f5e63f87",
      "181c2fea027e4ec2b9905a3420d0b791",
      "a8389b8ff8f4463faf3b70c6c34ecc68",
      "184511b850f943449114f118bff31b15",
      "98b5ce6d082b45e8a0427bbbc289a76a",
      "c1cafff96f0245dcb918aa7895374710"
     ]
    },
    "id": "czh0UbrvQZ7C",
    "outputId": "0c1ed8a1-3b5b-4e70-fee0-b281f6b778d0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/home/ec2-user/anaconda3/envs/pytorch_p39/lib/libcudart.so'), PosixPath('/home/ec2-user/anaconda3/envs/pytorch_p39/lib/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda117.so\n",
      "CUDA SETUP: CUDA runtime path found: /home/ec2-user/anaconda3/envs/pytorch_p39/lib/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0051059722900390625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 33,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15774bc28f0c49bf8082545dcb832fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "import transformers\n",
    "\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig\n",
    "import bitsandbytes as bnb\n",
    "load_8bit = True\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "            'decapoda-research/llama-7b-hf',\n",
    "            # load_in_8bit=load_8bit,\n",
    "            # load_in_8bit_fp32_cpu_offload=True,\n",
    "            offload_folder=\"content\",\n",
    "            torch_dtype=torch.float32,\n",
    "            device_map=\"auto\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tRmfP8ssNF-q",
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_output_embeddings(sentence):\n",
    "    token = tokenizer(sentence,padding= True, return_tensors=\"pt\")\n",
    "    output = model(\n",
    "        token['input_ids'],output_hidden_states=True\n",
    "    )\n",
    "    return output.hidden_states[-1][:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "bylkaNuVQ5WT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate embeddings given a list of instruction\n",
    "def generate_embedding(instruction, input):\n",
    "  if isinstance(input, list):\n",
    "    output = []\n",
    "    for item in input:\n",
    "      output.append(f\"\"\"{item}\"\"\")\n",
    "    return get_output_embeddings(output)\n",
    "  # print(input)\n",
    "  if input:\n",
    "          output = f\"\"\"{input}\"\"\"\n",
    "  else:\n",
    "          output = f\"\"\"{input}\"\"\"\n",
    "\n",
    "  return get_output_embeddings(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "qVmpH2CqTyIo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "rgtH8O2ITz68",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeedforwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeedforwardNet, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(4096, 4096)\n",
    "        self.bn1 = nn.BatchNorm1d(4096)\n",
    "        self.fc2 = nn.Linear(4096, 1024)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.fc4 = nn.Linear(1024, 512)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.fc5 = nn.Linear(512, 10)\n",
    "        self.fc6 = nn.Linear(512, 1)\n",
    "        self.softmax_layer = nn.Softmax(dim=1)\n",
    "        self.sigmoid_layer = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.bn1(self.fc1(x)))\n",
    "        x = nn.ReLU()(self.bn3(self.fc2(x)))\n",
    "        x = nn.ReLU()(self.bn4(self.fc4(x)))\n",
    "        action_probs = F.log_softmax(self.fc5(x),dim=-1)\n",
    "        value = torch.tanh(self.fc6(x))\n",
    "        \n",
    "        return action_probs, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "XhMYAmQcT4Ch",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_board(board_list):\n",
    "  if board_list.ndim == 3:\n",
    "    lst = []\n",
    "    for board in board_list:\n",
    "          board = board.reshape(3,3)\n",
    "          n = board.shape[0]\n",
    "          letters = ['A', 'B', 'C']\n",
    "          string = '   '\n",
    "          for y in range(n):\n",
    "              string += f'{y+1} '\n",
    "          string += '\\n'\n",
    "\n",
    "          for x in range(n):\n",
    "              string += f'  {letters[x]} '\n",
    "              string += '|'\n",
    "              for y in range(n):\n",
    "                  string += 'X' * int(board[x, y] == -1)\n",
    "                  string += 'O' * int(board[x, y] == 1)\n",
    "                  string += ' ' * int(board[x, y] == 0)\n",
    "                  string += '|'\n",
    "              string += '''\\n'''\n",
    "          lst.append(string)\n",
    "  else:\n",
    "        board = board_list.reshape(3,3)\n",
    "        n = board.shape[0]\n",
    "        letters = ['A', 'B', 'C']\n",
    "        string = '   '\n",
    "        for y in range(n):\n",
    "            string += f'{y+1} '\n",
    "        string += '\\n'\n",
    "\n",
    "        for x in range(n):\n",
    "            string += f'  {letters[x]} '\n",
    "            string += '|'\n",
    "            for y in range(n):\n",
    "                string += 'X' * int(board[x, y] == -1)\n",
    "                string += 'O' * int(board[x, y] == 1)\n",
    "                string += ' ' * int(board[x, y] == 0)\n",
    "                string += '|'\n",
    "            string += '''\\n'''\n",
    "        lst = string\n",
    "  return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xr6SOC2gghav",
    "outputId": "eaf7ed4c-61de-4827-cbf1-ec97b5c834c8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15687/2454519674.py:6: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(m.weight)\n"
     ]
    }
   ],
   "source": [
    "# log.info('Loading %s...', nn.__name__)\n",
    "device = 'cuda'\n",
    "nnet = FeedforwardNet().to(device)\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "nnet.apply(init_weights)\n",
    "optimizer = torch.optim.AdamW(nnet.parameters(),lr=0.003,eps=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "dL-kq_SCVl3I",
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "mmf_fRI6T5Oi",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"I am the O player in a game tic-tac-toe, the other player is X and I'm supposed to play next. The board configuration is given in input. If I play optimally and the opponent play optimally, output the value (between -1 and 1, with 1 reprsenting me winning and -1 losing) and policy functions for the current configuration, no explanations.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "jutBLbH9M_Dr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(board):\n",
    "    \"\"\"\n",
    "    board: np array with board\n",
    "    \"\"\"\n",
    "    # timing\n",
    "    start = time.time()\n",
    "\n",
    "    # preparing input\n",
    "    board = board.astype(np.float64)\n",
    "    boardstr = print_board(board)\n",
    "    emb = generate_embedding(prompt, boardstr)\n",
    "    data = emb.to(device)\n",
    "    data.requires_grad = True\n",
    "\n",
    "    if args.cuda: data = data.contiguous().cuda()\n",
    "\n",
    "    with torch.cuda.amp.autocast():\n",
    "        nnet.eval()\n",
    "        pi, v = nnet(data)\n",
    "        \n",
    "    alpha = 1.1\n",
    "    alpha = 1.1\n",
    "    sample_size = 10\n",
    "\n",
    "      # Generate sample from Dirichlet distribution\n",
    "    sample = np.random.dirichlet([alpha] * sample_size)\n",
    "\n",
    "    # print(board)\n",
    "\n",
    "    # print('PREDICTION TIME TAKEN : {0:03f}'.format(time.time()-start))\n",
    "    return torch.exp(pi).data.cpu().numpy()[0]*0.85+sample*0.15, v.data.cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_hist = []\n",
    "episode_count = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "nnj0iwtWT9Ea",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "class dotdict(dict):\n",
    "    def __getattr__(self, name):\n",
    "        return self[name]\n",
    " \n",
    "class AverageMeter(object):\n",
    "    \"\"\"From https://github.com/pytorch/examples/blob/master/imagenet/main.py\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.avg:.2e}'\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "args = dotdict({\n",
    "    'lr': 0.001,\n",
    "    'dropout': 0.3,\n",
    "    'epochs': 20,\n",
    "    'batch_size': 20,\n",
    "    'cuda': torch.cuda.is_available(),\n",
    "    'num_channels': 512,\n",
    "})\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "def loss_pi(targets, outputs):\n",
    "    return -torch.sum(targets * outputs) / targets.size()[0]\n",
    "\n",
    "def loss_v(targets, outputs):\n",
    "    return torch.sum((targets - outputs.view(-1)) ** 2) / targets.size()[0]\n",
    "\n",
    "\n",
    "def train(examples):\n",
    "    \"\"\"\n",
    "    examples: list of examples, each example is of form (board, pi, v)\n",
    "    \"\"\"\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        print('EPOCH ::: ' + str(epoch + 1))\n",
    "        pi_losses = AverageMeter()\n",
    "        v_losses = AverageMeter()\n",
    "\n",
    "        batch_count = int(len(examples) / args.batch_size)\n",
    "\n",
    "        t = tqdm(range(batch_count), desc='Training Net')\n",
    "        for step, _ in enumerate(t):\n",
    "            sample_ids = np.random.randint(len(examples), size=args.batch_size)\n",
    "            boards, pis, vs = list(zip(*[examples[i] for i in sample_ids]))\n",
    "            boards = np.array(boards).astype(np.float64)\n",
    "            boardstr = print_board(boards) # (batchsize, )\n",
    "            # print(boardstr,\"nst\")\n",
    "            # print(np.shape(boardstr))\n",
    "            emb = generate_embedding(prompt, boardstr).to(device)\n",
    "            # print(emb.size(),\"ccc\")\n",
    "            emb.requires_grad = True\n",
    "            # print(emb, \"embeddings\")\n",
    "            # compute output\n",
    "\n",
    "            target_pis = torch.FloatTensor(np.array(pis)).to(device)\n",
    "            target_vs = torch.FloatTensor(np.array(vs).astype(np.float64)).to(device)\n",
    "\n",
    "            # # predict\n",
    "            # if args.cuda:\n",
    "            #     data, target_pis, target_vs = data.contiguous().cuda(), target_pis.contiguous().cuda(), target_vs.contiguous().cuda()\n",
    "            with torch.cuda.amp.autocast():\n",
    "              out_pi, out_v = nnet(emb)\n",
    "      \n",
    "              l_pi = loss_pi(target_pis, out_pi)\n",
    "              l_v = loss_v(target_vs, out_v)\n",
    "\n",
    "            total_loss = l_pi + l_v\n",
    "            # print(\"Target_pi: \", target_pis, \"predicted_pi\", torch.exp(out_pi))\n",
    "            # print(\"targetv\", target_vs, \"predicted_v\", out_v)\n",
    "            loss_hist.append(total_loss.item())\n",
    "\n",
    "            # record loss\n",
    "            pi_losses.update(l_pi.item(), torch.from_numpy(boards).size(0))\n",
    "            v_losses.update(l_v.item(), torch.from_numpy(boards).size(0))\n",
    "            t.set_postfix(Loss_pi=pi_losses, Loss_v=v_losses)\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            # for param in nnet.parameters():\n",
    "            #   print(param.grad)\n",
    "            optimizer.step()\n",
    "        episode_count.append(len(loss_hist))\n",
    "\n",
    "def save_checkpoint(folder='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    # filepath = os.path.join(folder, filename)\n",
    "    # if not os.path.exists(folder):\n",
    "    #     print(\"Checkpoint Directory does not exist! Making directory {}\".format(folder))\n",
    "    #     os.mkdir(folder)\n",
    "    # else:\n",
    "    #     print(\"Checkpoint Directory exists! \")\n",
    "    # torch.save({\n",
    "    #     'state_dict': self.nnet.state_dict(),\n",
    "    # }, filepath)\n",
    "    pass\n",
    "\n",
    "def load_checkpoint(folder='checkpoint', filename='checkpoint.pth.tar'):\n",
    "    # https://github.com/pytorch/examples/blob/master/imagenet/main.py#L98\n",
    "    # filepath = os.path.join(folder, filename)\n",
    "    # if not os.path.exists(filepath):\n",
    "    #     raise (\"No model in path {}\".format(filepath))\n",
    "    # map_location = None if args.cuda else 'cpu'\n",
    "    # checkpoint = torch.load(filepath, map_location=map_location)\n",
    "    # self.nnet.load_state_dict(checkpoint['state_dict'])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "up9ZVknHUniK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "EPS = 1e-7\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class MCTS():\n",
    "    \"\"\"\n",
    "    This class handles the MCTS tree.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, game, args):\n",
    "        self.game = game\n",
    "        self.args = args\n",
    "        self.Qsa = {}  # stores Q values for s,a (as defined in the paper)\n",
    "        self.Nsa = {}  # stores #times edge s,a was visited\n",
    "        self.Ns = {}  # stores #times board s was visited\n",
    "        self.Ps = {}  # stores initial policy (returned by neural net)\n",
    "\n",
    "        self.Es = {}  # stores game.getGameEnded ended for board s\n",
    "        self.Vs = {}  # stores game.getValidMoves for board s\n",
    "\n",
    "    def getActionProb(self, canonicalBoard, temp=1):\n",
    "        \"\"\"\n",
    "        This function performs numMCTSSims simulations of MCTS starting from\n",
    "        canonicalBoard.\n",
    "        Returns:\n",
    "            probs: a policy vector where the probability of the ith action is\n",
    "                   proportional to Nsa[(s,a)]**(1./temp)\n",
    "        \"\"\"\n",
    "        for i in range(self.args.numMCTSSims):\n",
    "            self.search(canonicalBoard)\n",
    "\n",
    "        s = self.game.stringRepresentation(canonicalBoard)\n",
    "        counts = [self.Nsa[(s, a)] if (s, a) in self.Nsa else 0 for a in range(self.game.getActionSize())]\n",
    "\n",
    "        if temp == 0:\n",
    "            bestAs = np.array(np.argwhere(counts == np.max(counts))).flatten()\n",
    "            bestA = np.random.choice(bestAs)\n",
    "            probs = [0] * len(counts)\n",
    "            probs[bestA] = 1\n",
    "            return probs\n",
    "\n",
    "        counts = [x ** (1. / temp) for x in counts]\n",
    "        counts_sum = float(sum(counts))\n",
    "        probs = [x / counts_sum for x in counts]\n",
    "        return probs\n",
    "\n",
    "    def search(self, canonicalBoard):\n",
    "        \"\"\"\n",
    "        This function performs one iteration of MCTS. It is recursively called\n",
    "        till a leaf node is found. The action chosen at each node is one that\n",
    "        has the maximum upper confidence bound as in the paper.\n",
    "        Once a leaf node is found, the neural network is called to return an\n",
    "        initial policy P and a value v for the state. This value is propagated\n",
    "        up the search path. In case the leaf node is a terminal state, the\n",
    "        outcome is propagated up the search path. The values of Ns, Nsa, Qsa are\n",
    "        updated.\n",
    "        NOTE: the return values are the negative of the value of the current\n",
    "        state. This is done since v is in [-1,1] and if v is the value of a\n",
    "        state for the current player, then its value is -v for the other player.\n",
    "        Returns:\n",
    "            v: the negative of the value of the current canonicalBoard\n",
    "        \"\"\"\n",
    "\n",
    "        s = self.game.stringRepresentation(canonicalBoard)\n",
    "\n",
    "        if s not in self.Es:\n",
    "            self.Es[s] = self.game.getGameEnded(canonicalBoard, 1)\n",
    "        if self.Es[s] != 0:\n",
    "            # terminal node\n",
    "            return -self.Es[s]\n",
    "\n",
    "        if s not in self.Ps:\n",
    "            # leaf node\n",
    "            self.Ps[s], v = predict(canonicalBoard)\n",
    "            valids = self.game.getValidMoves(canonicalBoard, 1)\n",
    "            self.Ps[s] = self.Ps[s] * valids  # masking invalid moves\n",
    "            sum_Ps_s = np.sum(self.Ps[s])\n",
    "            if sum_Ps_s > 0:\n",
    "                self.Ps[s] /= sum_Ps_s  # renormalize\n",
    "            else:\n",
    "                # if all valid moves were masked make all valid moves equally probable\n",
    "\n",
    "                # NB! All valid moves may be masked if either your NNet architecture is insufficient or you've get overfitting or something else.\n",
    "                # If you have got dozens or hundreds of these messages you should pay attention to your NNet and/or training process.   \n",
    "                log.error(\"All valid moves were masked, doing a workaround.\")\n",
    "                self.Ps[s] = self.Ps[s] + valids\n",
    "                self.Ps[s] /= np.sum(self.Ps[s])\n",
    "\n",
    "            self.Vs[s] = valids\n",
    "            self.Ns[s] = 0\n",
    "            return -v\n",
    "\n",
    "        valids = self.Vs[s]\n",
    "        cur_best = -float('inf')\n",
    "        best_act = -1\n",
    "\n",
    "        # pick the action with the highest upper confidence bound\n",
    "        for a in range(self.game.getActionSize()):\n",
    "            if valids[a]:\n",
    "                if (s, a) in self.Qsa:\n",
    "                    u = self.Qsa[(s, a)] + self.args.cpuct * self.Ps[s][a] * math.sqrt(self.Ns[s]) / (\n",
    "                            1 + self.Nsa[(s, a)])\n",
    "                else:\n",
    "                    u = self.args.cpuct * self.Ps[s][a] * math.sqrt(self.Ns[s] + EPS)  # Q = 0 ?\n",
    "\n",
    "                if u > cur_best:\n",
    "                    cur_best = u\n",
    "                    best_act = a\n",
    "\n",
    "        a = best_act\n",
    "        next_s, next_player = self.game.getNextState(canonicalBoard, 1, a)\n",
    "        next_s = self.game.getCanonicalForm(next_s, next_player)\n",
    "\n",
    "        v = self.search(next_s)\n",
    "\n",
    "        if (s, a) in self.Qsa:\n",
    "            self.Qsa[(s, a)] = (self.Nsa[(s, a)] * self.Qsa[(s, a)] + v) / (self.Nsa[(s, a)] + 1)\n",
    "            self.Nsa[(s, a)] += 1\n",
    "\n",
    "        else:\n",
    "            self.Qsa[(s, a)] = v\n",
    "            self.Nsa[(s, a)] = 1\n",
    "\n",
    "        self.Ns[s] += 1\n",
    "        return -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "u6QjwpT7Up6y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from collections import deque\n",
    "from pickle import Pickler, Unpickler\n",
    "from random import shuffle\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class Coach():\n",
    "    \"\"\"\n",
    "    This class executes the self-play + learning. It uses the functions defined\n",
    "    in Game and NeuralNet. args are specified in main.py.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, game, args):\n",
    "        self.game = game\n",
    "        # self.pnet = self.nnet.__class__(self.game)  # the competitor network\n",
    "        self.args = args\n",
    "        self.mcts = MCTS(self.game, self.args)\n",
    "        self.trainExamplesHistory = []  # history of examples from args.numItersForTrainExamplesHistory latest iterations\n",
    "        self.skipFirstSelfPlay = False  # can be overriden in loadTrainExamples()\n",
    "\n",
    "    def executeEpisode(self):\n",
    "        \"\"\"\n",
    "        This function executes one episode of self-play, starting with player 1.\n",
    "        As the game is played, each turn is added as a training example to\n",
    "        trainExamples. The game is played till the game ends. After the game\n",
    "        ends, the outcome of the game is used to assign values to each example\n",
    "        in trainExamples.\n",
    "\n",
    "        It uses a temp=1 if episodeStep < tempThreshold, and thereafter\n",
    "        uses temp=0.\n",
    "\n",
    "        Returns:\n",
    "            trainExamples: a list of examples of the form (canonicalBoard, currPlayer, pi,v)\n",
    "                           pi is the MCTS informed policy vector, v is +1 if\n",
    "                           the player eventually won the game, else -1.\n",
    "        \"\"\"\n",
    "        trainExamples = []\n",
    "        board = self.game.getInitBoard()\n",
    "        self.curPlayer = 1\n",
    "        episodeStep = 0\n",
    "\n",
    "        while True:\n",
    "            episodeStep += 1\n",
    "            canonicalBoard = self.game.getCanonicalForm(board, self.curPlayer)\n",
    "            temp = int(episodeStep < self.args.tempThreshold)\n",
    "\n",
    "            pi = self.mcts.getActionProb(canonicalBoard, temp=temp)\n",
    "            sym = self.game.getSymmetries(canonicalBoard, pi)\n",
    "\n",
    "            for b, p in sym:\n",
    "                trainExamples.append([b, self.curPlayer, p, None])\n",
    "\n",
    "            action = np.random.choice(len(pi), p=pi)\n",
    "            board, self.curPlayer = self.game.getNextState(board, self.curPlayer, action)\n",
    "\n",
    "            r = self.game.getGameEnded(board, self.curPlayer)\n",
    "            if r != 0:\n",
    "                return [(x[0], x[2], r * ((-1) ** (x[1] != self.curPlayer))) for x in trainExamples]\n",
    "\n",
    "    def learn(self):\n",
    "        \"\"\"\n",
    "        Performs numIters iterations with numEps episodes of self-play in each\n",
    "        iteration. After every iteration, it retrains neural network with\n",
    "        examples in trainExamples (which has a maximum length of maxlenofQueue).\n",
    "        It then pits the new neural network against the old one and accepts it\n",
    "        only if it wins >= updateThreshold fraction of games.\n",
    "        \"\"\"\n",
    "\n",
    "        for i in range(1, self.args.numIters + 1):\n",
    "            # bookkeeping\n",
    "            log.info(f'Starting Iter #{i} ...')\n",
    "            # examples of the iteration\n",
    "            if not self.skipFirstSelfPlay or i > 1:\n",
    "                iterationTrainExamples = deque([], maxlen=self.args.maxlenOfQueue)\n",
    "\n",
    "                for _ in tqdm(range(self.args.numEps), desc=\"Self Play\"):\n",
    "                    self.mcts = MCTS(self.game, self.args)  # reset search tree\n",
    "                    iterationTrainExamples += self.executeEpisode()\n",
    "\n",
    "                # save the iteration examples to the history \n",
    "                self.trainExamplesHistory.append(iterationTrainExamples)\n",
    "\n",
    "            if len(self.trainExamplesHistory) > self.args.numItersForTrainExamplesHistory:\n",
    "                log.warning(\n",
    "                    f\"Removing the oldest entry in trainExamples. len(trainExamplesHistory) = {len(self.trainExamplesHistory)}\")\n",
    "                self.trainExamplesHistory.pop(0)\n",
    "            # backup history to a file\n",
    "            # NB! the examples were collected using the model from the previous iteration, so (i-1)  \n",
    "            # self.saveTrainExamples(i - 1)\n",
    "\n",
    "            # shuffle examples before training\n",
    "            trainExamples = []\n",
    "            for e in self.trainExamplesHistory:\n",
    "                trainExamples.extend(e)\n",
    "            shuffle(trainExamples)\n",
    "            # print(trainExamples)\n",
    "\n",
    "            # # training new network, keeping a copy of the old one\n",
    "            # self.nnet.save_checkpoint(folder=self.args.checkpoint, filename='temp.pth.tar')\n",
    "            # self.pnet.load_checkpoint(folder=self.args.checkpoint, filename='temp.pth.tar')\n",
    "            # pmcts = MCTS(self.game, self.pnet, self.args)\n",
    "\n",
    "            train(trainExamples)\n",
    "            # nmcts = MCTS(self.game, self.nnet, self.args)\n",
    "\n",
    "            # log.info('PITTING AGAINST PREVIOUS VERSION')\n",
    "            # arena = Arena(lambda x: np.argmax(pmcts.getActionProb(x, temp=0)),\n",
    "            #               lambda x: np.argmax(nmcts.getActionProb(x, temp=0)), self.game)\n",
    "            # pwins, nwins, draws = arena.playGames(self.args.arenaCompare)\n",
    "\n",
    "            # log.info('NEW/PREV WINS : %d / %d ; DRAWS : %d' % (nwins, pwins, draws))\n",
    "            # if pwins + nwins == 0 or float(nwins) / (pwins + nwins) < self.args.updateThreshold:\n",
    "            #     log.info('REJECTING NEW MODEL')\n",
    "            #     self.nnet.load_checkpoint(folder=self.args.checkpoint, filename='temp.pth.tar')\n",
    "            # else:\n",
    "            #     log.info('ACCEPTING NEW MODEL')\n",
    "            #     self.nnet.save_checkpoint(folder=self.args.checkpoint, filename=self.getCheckpointFile(i))\n",
    "            #     self.nnet.save_checkpoint(folder=self.args.checkpoint, filename='best.pth.tar')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def getCheckpointFile(self, iteration):\n",
    "        # return 'checkpoint_' + str(iteration) + '.pth.tar'\n",
    "        pass\n",
    "\n",
    "    def saveTrainExamples(self, iteration):\n",
    "        folder = self.args.checkpoint\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        filename = os.path.join(folder, self.getCheckpointFile(iteration) + \".examples\")\n",
    "        with open(filename, \"wb+\") as f:\n",
    "            Pickler(f).dump(self.trainExamplesHistory)\n",
    "        f.closed\n",
    "\n",
    "    def loadTrainExamples(self):\n",
    "        modelFile = os.path.join(self.args.load_folder_file[0], self.args.load_folder_file[1])\n",
    "        examplesFile = modelFile + \".examples\"\n",
    "        if not os.path.isfile(examplesFile):\n",
    "            log.warning(f'File \"{examplesFile}\" with trainExamples not found!')\n",
    "            r = input(\"Continue? [y|n]\")\n",
    "            if r != \"y\":\n",
    "                sys.exit()\n",
    "        else:\n",
    "            log.info(\"File with trainExamples found. Loading it...\")\n",
    "            with open(examplesFile, \"rb\") as f:\n",
    "                self.trainExamplesHistory = Unpickler(f).load()\n",
    "            log.info('Loading done!')\n",
    "\n",
    "            # examples based on the model were already collected (loaded)\n",
    "            self.skipFirstSelfPlay = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "TiRYD4DVU0FD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tictactoe.TicTacToeGame import TicTacToeGame as Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "qr9s_TjIU4Hq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run training loop\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "args = dotdict({\n",
    "    'numIters': 1000,\n",
    "    'numEps': 50,              # Number of complete self-play games to simulate during a new iteration.\n",
    "    'tempThreshold': 15,        #\n",
    "    'updateThreshold': 0.6,     # During arena playoff, new neural net will be accepted if threshold or more of games are won.\n",
    "    'maxlenOfQueue': 200000,    # Number of game examples to train the neural networks.\n",
    "    'numMCTSSims': 25,          # Number of games moves for MCTS to simulate.\n",
    "    'arenaCompare': 40,         # Number of games to play during arena play to determine if new net will be accepted.\n",
    "    'cpuct': 1,\n",
    "    'epochs': 1,\n",
    "     'lr': 0.001,\n",
    "    'dropout': 0.3,\n",
    "    'batch_size': 8,\n",
    "    'cuda': torch.cuda.is_available(),\n",
    "    'num_channels': 512,\n",
    "\n",
    "    'checkpoint': './temp/',\n",
    "    'load_model': False,\n",
    "    'load_folder_file': ('/dev/models/8x100x50','best.pth.tar'),\n",
    "    'numItersForTrainExamplesHistory': 20,\n",
    "\n",
    "})\n",
    "\n",
    "\n",
    "def main():\n",
    "    log.info('Loading %s...', Game.__name__)\n",
    "    g = Game(3)\n",
    "\n",
    "    # log.info('Loading %s...', nn.__name__)\n",
    "\n",
    "\n",
    "    log.info('Loading the Coach...')\n",
    "    c = Coach(g, args)\n",
    "\n",
    "    if args.load_model:\n",
    "        log.info(\"Loading 'trainExamples' from file...\")\n",
    "        c.loadTrainExamples()\n",
    "\n",
    "    log.info('Starting the learning process 🎉')\n",
    "    c.learn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "lUGM27uEU40L",
    "tags": []
   },
   "outputs": [],
   "source": [
    "args_main = dotdict({\n",
    "    'numIters': 1000,\n",
    "    'numEps': 50,              # Number of complete self-play games to simulate during a new iteration.\n",
    "    'tempThreshold': 15,        #\n",
    "    'updateThreshold': 0.6,     # During arena playoff, new neural net will be accepted if threshold or more of games are won.\n",
    "    'maxlenOfQueue': 200000,    # Number of game examples to train the neural networks.\n",
    "    'numMCTSSims': 25,          # Number of games moves for MCTS to simulate.\n",
    "    'arenaCompare': 40,         # Number of games to play during arena play to determine if new net will be accepted.\n",
    "    'cpuct': 1,\n",
    "    'epochs': 1,\n",
    "     'lr': 0.001,\n",
    "    'dropout': 0.3,\n",
    "    'batch_size': 8,\n",
    "    'cuda': torch.cuda.is_available(),\n",
    "    'num_channels': 512,\n",
    "    'checkpoint': './temp/',\n",
    "    'load_model': False,\n",
    "    'load_folder_file': ('/dev/models/8x100x50','best.pth.tar'),\n",
    "    'numItersForTrainExamplesHistory': 20,\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aIqbQ3fJVrhi",
    "outputId": "b8b72966-a424-4352-b385-65c06e893227",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15687/55355528.py:6: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(m.weight)\n"
     ]
    }
   ],
   "source": [
    "# log.info('Loading %s...', nn.__name__)\n",
    "device = 'cuda'\n",
    "nnet = FeedforwardNet().to(device)\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "nnet.apply(init_weights)\n",
    "optimizer = torch.optim.AdamW(nnet.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(nnet.parameters(),lr=0.002, eps = 1e-06, weight_decay = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TO8cEZWrU7HF",
    "outputId": "5e0a4a8e-0984-4d29-9be1-e8e0fa71f278",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Self Play: 100%|██████████| 50/50 [07:15<00:00,  8.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH ::: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Net: 100%|██████████| 361/361 [01:55<00:00,  3.12it/s, Loss_pi=1.40e+00, Loss_v=4.97e-01]\n",
      "Self Play: 100%|██████████| 50/50 [07:10<00:00,  8.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH ::: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Net: 100%|██████████| 743/743 [03:59<00:00,  3.11it/s, Loss_pi=1.30e+00, Loss_v=4.34e-01]\n",
      "Self Play: 100%|██████████| 50/50 [06:58<00:00,  8.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH ::: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Net: 100%|██████████| 1115/1115 [05:58<00:00,  3.11it/s, Loss_pi=1.28e+00, Loss_v=4.34e-01]\n",
      "Self Play: 100%|██████████| 50/50 [07:22<00:00,  8.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH ::: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Net: 100%|██████████| 1501/1501 [07:59<00:00,  3.13it/s, Loss_pi=1.28e+00, Loss_v=4.20e-01]\n",
      "Self Play: 100%|██████████| 50/50 [07:24<00:00,  8.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH ::: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Net: 100%|██████████| 1882/1882 [10:01<00:00,  3.13it/s, Loss_pi=1.26e+00, Loss_v=4.23e-01]\n",
      "Self Play: 100%|██████████| 50/50 [07:18<00:00,  8.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH ::: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Net: 100%|██████████| 2266/2266 [12:04<00:00,  3.13it/s, Loss_pi=1.24e+00, Loss_v=4.13e-01]\n",
      "Self Play: 100%|██████████| 50/50 [07:35<00:00,  9.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH ::: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Net: 100%|██████████| 2631/2631 [14:17<00:00,  3.07it/s, Loss_pi=1.24e+00, Loss_v=4.13e-01]\n",
      "Self Play: 100%|██████████| 50/50 [07:13<00:00,  8.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH ::: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Net: 100%|██████████| 3018/3018 [16:24<00:00,  3.07it/s, Loss_pi=1.24e+00, Loss_v=4.14e-01]\n",
      "Self Play: 100%|██████████| 50/50 [07:15<00:00,  8.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH ::: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Net: 100%|██████████| 3405/3405 [18:29<00:00,  3.07it/s, Loss_pi=1.22e+00, Loss_v=3.92e-01]\n",
      "Self Play:   0%|          | 0/50 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15687/3971060375.py\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting the learning process 🎉'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_15687/2990550623.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumEps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Self Play\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmcts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMCTS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# reset search tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0miterationTrainExamples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuteEpisode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;31m# save the iteration examples to the history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15687/2990550623.py\u001b[0m in \u001b[0;36mexecuteEpisode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodeStep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtempThreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmcts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetActionProb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanonicalBoard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0msym\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetSymmetries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanonicalBoard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15687/1239316376.py\u001b[0m in \u001b[0;36mgetActionProb\u001b[0;34m(self, canonicalBoard, temp)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \"\"\"\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumMCTSSims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanonicalBoard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstringRepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanonicalBoard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15687/1239316376.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, canonicalBoard)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mnext_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCanonicalForm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_player\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQsa\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15687/1239316376.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, canonicalBoard)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mnext_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetCanonicalForm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_player\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQsa\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15687/1239316376.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, canonicalBoard)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# leaf node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanonicalBoard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mvalids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetValidMoves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanonicalBoard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvalids\u001b[0m  \u001b[0;31m# masking invalid moves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15687/2746040169.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(board)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mboardstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprint_board\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboardstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15687/654032380.py\u001b[0m in \u001b[0;36mgenerate_embedding\u001b[0;34m(instruction, input)\u001b[0m\n\u001b[1;32m     11\u001b[0m           \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\"\"{input}\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mget_output_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15687/1296676977.py\u001b[0m in \u001b[0;36mget_output_embeddings\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_output_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     output = model(\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mtoken\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m    688\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    575\u001b[0m                 )\n\u001b[1;32m    576\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    578\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_forward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnew_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "log.info('Loading %s...', Game.__name__)\n",
    "g = Game(3)\n",
    "\n",
    "\n",
    "log.info('Loading the Coach...')\n",
    "c = Coach(g, args_main)\n",
    "\n",
    "if args_main.load_model:\n",
    "    log.info(\"Loading 'trainExamples' from file...\")\n",
    "    c.loadTrainExamples()\n",
    "\n",
    "log.info('Starting the learning process 🎉')\n",
    "c.learn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# state_dict = torch.load('nnet7.pth')\n",
    "# nnet.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('loss.pkl', 'wb') as f:\n",
    "    my_list = pickle.dump(loss_hist, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the loss values\n",
    "ax.plot(loss_hist)\n",
    "\n",
    "# Set the title and labels for the plot\n",
    "ax.set_title('Loss Values')\n",
    "ax.set_xlabel('Iterations')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_ylim([0, 5])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "fig.savefig('loss_values.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(nnet.state_dict(), 'nnet7.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Generate all possible configurations\n",
    "possible_configs = product([-1, 0, 1], repeat=9)\n",
    "\n",
    "# Filter out the ones where the number of 1's is greater than the number of -1's\n",
    "configs = []\n",
    "for config in possible_configs:\n",
    "    config_array = np.array(config).reshape(3, 3)\n",
    "    if (((config_array == 1).sum() <= (config_array == -1).sum()) and  (abs((config_array == -1).sum() - (config_array == 1).sum()) <= 1)) and (config_array == 0).sum() >= 1:\n",
    "        configs.append(config_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter = []\n",
    "for config in configs:\n",
    "    config_array = np.array(config).reshape(3, 3)\n",
    "    if (config_array == 1).sum() <= (config_array == -1).sum():\n",
    "        row_check = any((config_array == row).all() for row in [-1, 0, 1])\n",
    "        col_check = any((config_array == col).all(axis=0).all() for col in [-1, 0, 1])\n",
    "        diag_check = any((config_array == diag).all() for diag in [[-1, 0, 1], [1, 0, -1]])\n",
    "\n",
    "        if not (row_check or col_check or diag_check):\n",
    "            filter.append(config_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5917"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing validity of actions of the 5000 random board configurations generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_for_valids(arr):\n",
    "    string = print_board(np.array(arr))\n",
    "    emb = generate_embedding(prompt, string).to(device)\n",
    "    pi, v = nnet(emb)\n",
    "    actions = torch.argmax(torch.exp(pi), dim=-1)\n",
    "    bat1 = np.array(arr).reshape((20,9))\n",
    "    inds = actions\n",
    "    bat = bat1[range(20), inds.detach().cpu().numpy()]\n",
    "    return sum(abs(bat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:58<00:00,  1.40it/s]\n"
     ]
    }
   ],
   "source": [
    "ctr = 0\n",
    "for i in tqdm(range(250)):\n",
    "    ctr += test_for_valids(filter[i*20: (i+1)*20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of total invalid moves in all 5,000 configurations tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_for_valids_random(arr):\n",
    "    inds = np.random.randint(0, 9, size=20)\n",
    "    bat1 = np.array(arr).reshape((20,9))\n",
    "    bat = bat1[range(20), inds]\n",
    "    return sum(abs(bat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# using probability of that randomly guessing will be correct to roughly estimate number of total invalid moves in all 5,000 configurations tested under random guessing\n",
    "# what is the invalid actions frequency for a random agent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 28538.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3158"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctr2 = 0\n",
    "for i in tqdm(range(250)):\n",
    "    ctr2 += test_for_valids_random(filter[i*20: (i+1)*20])\n",
    "ctr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class Arena():\n",
    "    \"\"\"\n",
    "    An Arena class where any 2 agents can be pit against each other.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, player1, player2, game, display=None):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            player 1,2: two functions that takes board as input, return action\n",
    "            game: Game object\n",
    "            display: a function that takes board as input and prints it (e.g.\n",
    "                     display in othello/OthelloGame). Is necessary for verbose\n",
    "                     mode.\n",
    "\n",
    "        see othello/OthelloPlayers.py for an example. See pit.py for pitting\n",
    "        human players/other baselines with each other.\n",
    "        \"\"\"\n",
    "        self.player1 = player1\n",
    "        self.player2 = player2\n",
    "        self.game = game\n",
    "        self.display = display\n",
    "\n",
    "    def playGame(self, verbose=False):\n",
    "        \"\"\"\n",
    "        Executes one episode of a game.\n",
    "\n",
    "        Returns:\n",
    "            either\n",
    "                winner: player who won the game (1 if player1, -1 if player2)\n",
    "            or\n",
    "                draw result returned from the game that is neither 1, -1, nor 0.\n",
    "        \"\"\"\n",
    "        players = [self.player2, None, self.player1]\n",
    "        curPlayer = 1\n",
    "        board = self.game.getInitBoard()\n",
    "        it = 0\n",
    "        while self.game.getGameEnded(board, curPlayer) == 0:\n",
    "            it += 1\n",
    "            if verbose:\n",
    "                assert self.display\n",
    "                print(\"Turn \", str(it), \"Player \", str(curPlayer))\n",
    "                self.display(board)\n",
    "            action = players[curPlayer + 1](self.game.getCanonicalForm(board, curPlayer))\n",
    "\n",
    "            valids = self.game.getValidMoves(self.game.getCanonicalForm(board, curPlayer), 1)\n",
    "\n",
    "            if valids[action] == 0:\n",
    "                log.error(f'Action {action} is not valid!')\n",
    "                log.debug(f'valids = {valids}')\n",
    "                assert valids[action] > 0\n",
    "            board, curPlayer = self.game.getNextState(board, curPlayer, action)\n",
    "        if verbose:\n",
    "            assert self.display\n",
    "            print(\"Game over: Turn \", str(it), \"Result \", str(self.game.getGameEnded(board, 1)))\n",
    "            self.display(board)\n",
    "        return curPlayer * self.game.getGameEnded(board, curPlayer)\n",
    "\n",
    "    def playGames(self, num, verbose=False):\n",
    "        \"\"\"\n",
    "        Plays num games in which player1 starts num/2 games and player2 starts\n",
    "        num/2 games.\n",
    "\n",
    "        Returns:\n",
    "            oneWon: games won by player1\n",
    "            twoWon: games won by player2\n",
    "            draws:  games won by nobody\n",
    "        \"\"\"\n",
    "\n",
    "        num = int(num / 2)\n",
    "        oneWon = 0\n",
    "        twoWon = 0\n",
    "        draws = 0\n",
    "        for _ in tqdm(range(num), desc=\"Arena.playGames (1)\"):\n",
    "            gameResult = self.playGame(verbose=verbose)\n",
    "            if gameResult == 1:\n",
    "                oneWon += 1\n",
    "            elif gameResult == -1:\n",
    "                twoWon += 1\n",
    "            else:\n",
    "                draws += 1\n",
    "        print(oneWon, twoWon, draws)\n",
    "\n",
    "        self.player1, self.player2 = self.player2, self.player1\n",
    "\n",
    "        for _ in tqdm(range(num), desc=\"Arena.playGames (2)\"):\n",
    "            gameResult = self.playGame(verbose=verbose)\n",
    "            if gameResult == -1:\n",
    "                oneWon += 1\n",
    "            elif gameResult == 1:\n",
    "                twoWon += 1\n",
    "            else:\n",
    "                draws += 1\n",
    "\n",
    "        return oneWon, twoWon, draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RandomPlayer():\n",
    "    def __init__(self, game):\n",
    "        self.game = game\n",
    "\n",
    "    def play(self, board):\n",
    "        a = np.random.randint(self.game.getActionSize())\n",
    "        valids = self.game.getValidMoves(board, 1)\n",
    "        while valids[a]!=1:\n",
    "            a = np.random.randint(self.game.getActionSize())\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Netplayer():\n",
    "    def __init__(self, game):\n",
    "        self.game = game\n",
    "        self.invalid = 0\n",
    "    def play(self, board):\n",
    "        with torch.no_grad():\n",
    "            boardtsr = torch.FloatTensor(board.astype(np.float64)).to(device)\n",
    "            string = print_board(boardtsr)\n",
    "            emb = generate_embedding(prompt, string).to(device)\n",
    "            out_pi, _ = nnet(emb)\n",
    "            _, actions = torch.topk(torch.exp(out_pi), 9, dim = -1)\n",
    "            actions = actions.detach().cpu()[0]\n",
    "            valids = self.game.getValidMoves(board, 1)\n",
    "            ctr = 0\n",
    "            # print(actions)\n",
    "            while valids[actions[ctr]] == 0:\n",
    "                self.invalid += 1\n",
    "                ctr += 1\n",
    "            return actions[ctr]\n",
    "    def query(self):\n",
    "        return self.invalid\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = Netplayer(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = Game(3)\n",
    "rp = RandomPlayer(g).play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "arena = Arena(net.play, rp, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Arena.playGames (1): 100%|██████████| 1000/1000 [05:46<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937 22 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Arena.playGames (2): 100%|██████████| 1000/1000 [05:17<00:00,  3.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1535, 234, 231)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trained auxillary network + LLaMA embedding playing against a random agent\n",
    "arena.playGames(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Testing random board configurations\n",
    "boards_test = np.array([np.array([[1, 0, 1],[-1,0,-1],[0,0,0]]), np.array([[1,0,1],[0,-1,0],[-1,0,0]]), np.array([[-1, -1,1],[-1,0,0],[1,0,1]]), np.array([[-1,-1,0],[0,0,1],[1,0,0]]),np.array([[1,-1,0],[1,0,1],[0,0,-1]]),np.array([[1,-1,0],[1,0,0],[0,0,-1]]),np.array([[-1,1,0],[0,1,0],[0,0,-1]]),np.array([[1,-1,0],[0,1,-1],[0,0,0]]),np.array([[0,-1,1],[0,1,0],[0,0,-1]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.4635e-09, 2.3983e-01, 1.5828e-01, 1.6069e-03, 2.7979e-02, 2.3128e-02,\n",
      "         3.0533e-01, 3.4339e-02, 2.0950e-01, 2.8687e-14],\n",
      "        [3.2397e-03, 2.9815e-01, 1.0262e-02, 1.8115e-01, 7.3711e-03, 8.2058e-02,\n",
      "         4.9930e-03, 4.9410e-02, 3.6337e-01, 3.8289e-09],\n",
      "        [4.0914e-11, 2.6209e-04, 1.3396e-07, 3.7654e-04, 6.9575e-01, 1.2105e-01,\n",
      "         6.7576e-05, 1.8235e-01, 1.4910e-04, 3.6910e-16],\n",
      "        [9.7960e-07, 6.3140e-03, 1.9579e-01, 2.0310e-01, 6.8619e-02, 7.2571e-03,\n",
      "         7.2616e-04, 1.4672e-01, 3.7147e-01, 1.2035e-12],\n",
      "        [2.8313e-09, 1.2575e-04, 1.0579e-01, 1.0516e-02, 1.3224e-02, 8.4282e-02,\n",
      "         2.3371e-01, 5.4828e-01, 4.0775e-03, 4.7840e-13],\n",
      "        [5.0209e-09, 3.3650e-04, 1.4054e-01, 1.7337e-02, 1.1921e-01, 5.9871e-02,\n",
      "         3.1278e-01, 3.4927e-01, 6.6568e-04, 7.7948e-13],\n",
      "        [1.7981e-06, 2.9461e-03, 1.9103e-01, 4.8758e-02, 2.1890e-02, 1.3999e-01,\n",
      "         3.1213e-01, 2.8201e-01, 1.2392e-03, 3.6600e-11],\n",
      "        [2.8114e-06, 1.5785e-02, 6.7679e-02, 7.4025e-02, 4.8805e-04, 2.2656e-02,\n",
      "         2.7732e-01, 4.6410e-01, 7.7941e-02, 2.7406e-11],\n",
      "        [7.6451e-02, 9.7462e-04, 9.6806e-09, 9.0870e-02, 1.3033e-02, 2.3399e-01,\n",
      "         2.9191e-01, 2.9271e-01, 5.8643e-05, 5.0501e-11]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    nnet.eval()\n",
    "    boardstr = print_board(boards_test) # (batchsize, )\n",
    "    # print(boardstr,\"nst\")\n",
    "    # print(np.shape(boardstr))\n",
    "    emb = generate_embedding(prompt, boardstr).to(device)\n",
    "    out_pi, _ = nnet(emb)\n",
    "    print(torch.exp(out_pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4 (default, Apr  5 2021, 01:50:46) \n[Clang 12.0.0 (clang-1200.0.32.29)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "181c2fea027e4ec2b9905a3420d0b791": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "184511b850f943449114f118bff31b15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "366713dc81e0475b8787e0d5f5e63f87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "747456c4a45140d98f6e3beb2ae705c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88c4db8b412244caacca55ec5d7828f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f27fc1ca21624218a069e554859ecf06",
       "IPY_MODEL_e834f9fa03434737b116fbf3a808c12f",
       "IPY_MODEL_c7ab2c7f31b04358bac9f0fdf1306503"
      ],
      "layout": "IPY_MODEL_747456c4a45140d98f6e3beb2ae705c0"
     }
    },
    "98b5ce6d082b45e8a0427bbbc289a76a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8389b8ff8f4463faf3b70c6c34ecc68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1cafff96f0245dcb918aa7895374710": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c7ab2c7f31b04358bac9f0fdf1306503": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98b5ce6d082b45e8a0427bbbc289a76a",
      "placeholder": "​",
      "style": "IPY_MODEL_c1cafff96f0245dcb918aa7895374710",
      "value": " 33/33 [00:17&lt;00:00,  1.77it/s]"
     }
    },
    "e834f9fa03434737b116fbf3a808c12f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8389b8ff8f4463faf3b70c6c34ecc68",
      "max": 33,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_184511b850f943449114f118bff31b15",
      "value": 33
     }
    },
    "f27fc1ca21624218a069e554859ecf06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_366713dc81e0475b8787e0d5f5e63f87",
      "placeholder": "​",
      "style": "IPY_MODEL_181c2fea027e4ec2b9905a3420d0b791",
      "value": "Loading checkpoint shards: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
