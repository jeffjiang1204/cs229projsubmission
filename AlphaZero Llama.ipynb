{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["This file contains the code for directly optimizing llama through the algorithms\n","mentioned in the project report. Due to GPU memory constraint, the code below\n","requires more than 50G of GPU memory to run, so I did not use this code as part of\n","project. Still, I include this as a proof of concept that training large models\n","like LLaMA is possible and illustrate a way to do this.\n","\n","Attempt was made to run it in 8 bits float precision, but the gradients didn't\n","work out very well so we reverted to approach 1 and 2 in the paper.\n","\n","The MCTS part of the code is adopted from https://github.com/suragnair/alpha-zero-general"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["To run this code, since the action space is different, please change the files in\n","tictactoe/TicTacToeGame.py, by replacing it with tictactoe/TicTacToeGame_llama.py\n","and renaming it to TicTacToeGame.py."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2459,"status":"ok","timestamp":1682021942247,"user":{"displayName":"Jeff Jiang","userId":"05345923776204115994"},"user_tz":240},"id":"veY59RpiitlD","outputId":"c3cd3bdf-a490-445c-8630-e37155d03082"},"outputs":[{"name":"stdout","output_type":"stream","text":["Error: Failed to call git rev-parse --git-dir: exit status 128 \n","Git LFS initialized.\n","Cloning into 'alpaca-lora-7b'...\n","remote: Enumerating objects: 48, done.\u001b[K\n","remote: Counting objects: 100% (48/48), done.\u001b[K\n","remote: Compressing objects: 100% (47/47), done.\u001b[K\n","remote: Total 48 (delta 19), reused 0 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (48/48), 5.87 KiB | 600.00 KiB/s, done.\n"]}],"source":["!git lfs install\n","!git clone https://huggingface.co/tloen/alpaca-lora-7b"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6099,"status":"ok","timestamp":1682021948338,"user":{"displayName":"Jeff Jiang","userId":"05345923776204115994"},"user_tz":240},"id":"FpJI0exijME-","outputId":"c6ad8134-c4c6-4811-edfd-1c1b924ce5e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'alpaca-lora'...\n","remote: Enumerating objects: 607, done.\u001b[K\n","remote: Counting objects: 100% (51/51), done.\u001b[K\n","remote: Compressing objects: 100% (32/32), done.\u001b[K\n","remote: Total 607 (delta 28), reused 34 (delta 19), pack-reused 556\u001b[K\n","Receiving objects: 100% (607/607), 27.78 MiB | 6.62 MiB/s, done.\n","Resolving deltas: 100% (360/360), done.\n"]}],"source":["!git clone https://github.com/tloen/alpaca-lora.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46955,"status":"ok","timestamp":1682021995291,"user":{"displayName":"Jeff Jiang","userId":"05345923776204115994"},"user_tz":240},"id":"xFMfcsD3i57d","outputId":"d69a44fd-dbc9-41a2-fde7-84bd2883c094"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/huggingface/peft.git (from -r /content/alpaca-lora/requirements.txt (line 9))\n","  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-h1qhf0cx\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-h1qhf0cx\n","  Resolved https://github.com/huggingface/peft.git to commit 2822398fbe896f25d4dac5e468624dc5fd65a51b\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting accelerate\n","  Downloading accelerate-0.18.0-py3-none-any.whl (215 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.3/215.3 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: appdirs in /usr/local/lib/python3.9/dist-packages (from -r /content/alpaca-lora/requirements.txt (line 2)) (1.4.4)\n","Collecting loralib\n","  Downloading loralib-0.1.1-py3-none-any.whl (8.8 kB)\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.38.1-py3-none-any.whl (104.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting black\n","  Downloading black-23.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets\n","  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fire\n","  Downloading fire-0.5.0.tar.gz (88 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting transformers>=4.28.0\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.98-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gradio\n","  Downloading gradio-3.27.0-py3-none-any.whl (17.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from accelerate->-r /content/alpaca-lora/requirements.txt (line 1)) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from accelerate->-r /content/alpaca-lora/requirements.txt (line 1)) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from accelerate->-r /content/alpaca-lora/requirements.txt (line 1)) (23.1)\n","Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from accelerate->-r /content/alpaca-lora/requirements.txt (line 1)) (2.0.0+cu118)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate->-r /content/alpaca-lora/requirements.txt (line 1)) (5.9.5)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from black->-r /content/alpaca-lora/requirements.txt (line 5)) (2.0.1)\n","Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.9/dist-packages (from black->-r /content/alpaca-lora/requirements.txt (line 5)) (4.5.0)\n","Collecting pathspec>=0.9.0\n","  Downloading pathspec-0.11.1-py3-none-any.whl (29 kB)\n","Collecting mypy-extensions>=0.4.3\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from black->-r /content/alpaca-lora/requirements.txt (line 5)) (8.1.3)\n","Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.9/dist-packages (from black->-r /content/alpaca-lora/requirements.txt (line 5)) (3.2.0)\n","Requirement already satisfied: ipython>=7.8.0 in /usr/local/lib/python3.9/dist-packages (from black->-r /content/alpaca-lora/requirements.txt (line 5)) (7.34.0)\n","Collecting tokenize-rt>=3.2.0\n","  Downloading tokenize_rt-5.0.0-py2.py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets->-r /content/alpaca-lora/requirements.txt (line 7)) (1.5.3)\n","Collecting huggingface-hub<1.0.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess\n","  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets->-r /content/alpaca-lora/requirements.txt (line 7)) (9.0.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets->-r /content/alpaca-lora/requirements.txt (line 7)) (2023.4.0)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets->-r /content/alpaca-lora/requirements.txt (line 7)) (4.65.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets->-r /content/alpaca-lora/requirements.txt (line 7)) (2.27.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from fire->-r /content/alpaca-lora/requirements.txt (line 8)) (1.16.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.9/dist-packages (from fire->-r /content/alpaca-lora/requirements.txt (line 8)) (2.2.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.28.0->-r /content/alpaca-lora/requirements.txt (line 10)) (2022.10.31)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers>=4.28.0->-r /content/alpaca-lora/requirements.txt (line 10)) (3.11.0)\n","Requirement already satisfied: markupsafe in /usr/local/lib/python3.9/dist-packages (from gradio->-r /content/alpaca-lora/requirements.txt (line 12)) (2.1.2)\n","Collecting python-multipart\n","  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from gradio->-r /content/alpaca-lora/requirements.txt (line 12)) (3.7.1)\n","Collecting mdit-py-plugins<=0.3.3\n","  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from gradio->-r /content/alpaca-lora/requirements.txt (line 12)) (4.2.2)\n","Collecting httpx\n","  Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from gradio->-r /content/alpaca-lora/requirements.txt (line 12)) (3.1.2)\n","Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from gradio->-r /content/alpaca-lora/requirements.txt (line 12)) (2.2.0)\n","Collecting gradio-client>=0.1.3\n","  Downloading gradio_client-0.1.3-py3-none-any.whl (286 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.2/286.2 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.9/dist-packages (from gradio->-r /content/alpaca-lora/requirements.txt (line 12)) (1.10.7)\n","Collecting orjson\n","  Downloading orjson-3.8.10-cp39-cp39-manylinux_2_28_x86_64.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.5/140.5 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastapi\n","  Downloading fastapi-0.95.1-py3-none-any.whl (56 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from gradio->-r /content/alpaca-lora/requirements.txt (line 12)) (8.4.0)\n","Collecting uvicorn\n","  Downloading uvicorn-0.21.1-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting semantic-version\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Collecting ffmpy\n","  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting websockets>=10.0\n","  Downloading websockets-11.0.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.7/129.7 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiofiles\n","  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.9/dist-packages (from altair>=4.2.0->gradio->-r /content/alpaca-lora/requirements.txt (line 12)) (4.3.3)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.9/dist-packages (from altair>=4.2.0->gradio->-r /content/alpaca-lora/requirements.txt (line 12)) (0.4)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.9/dist-packages (from altair>=4.2.0->gradio->-r /content/alpaca-lora/requirements.txt (line 12)) (0.12.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->-r /content/alpaca-lora/requirements.txt (line 7)) (2.0.12)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->-r /content/alpaca-lora/requirements.txt (line 7)) (23.1.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython>=7.8.0->black->-r /content/alpaca-lora/requirements.txt (line 5)) (0.7.5)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython>=7.8.0->black->-r /content/alpaca-lora/requirements.txt (line 5)) (0.2.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipython>=7.8.0->black->-r /content/alpaca-lora/requirements.txt (line 5)) (5.7.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.9/dist-packages (from ipython>=7.8.0->black->-r /content/alpaca-lora/requirements.txt (line 5)) (67.6.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython>=7.8.0->black->-r /content/alpaca-lora/requirements.txt (line 5)) (4.4.2)\n","Collecting jedi>=0.16\n","  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython>=7.8.0->black->-r /content/alpaca-lora/requirements.txt (line 5)) (2.14.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython>=7.8.0->black->-r /content/alpaca-lora/requirements.txt (line 5)) (4.8.0)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython>=7.8.0->black->-r /content/alpaca-lora/requirements.txt (line 5)) (3.0.38)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/dist-packages (from ipython>=7.8.0->black->-r /content/alpaca-lora/requirements.txt (line 5)) (0.1.6)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio->-r /content/alpaca-lora/requirements.txt (line 12)) (0.1.2)\n","Collecting linkify-it-py<3,>=1\n","  Downloading linkify_it_py-2.0.0-py3-none-any.whl (19 kB)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->-r /content/alpaca-lora/requirements.txt (line 7)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->-r /content/alpaca-lora/requirements.txt (line 7)) (2022.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets->-r /content/alpaca-lora/requirements.txt (line 7)) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets->-r /content/alpaca-lora/requirements.txt (line 7)) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets->-r /content/alpaca-lora/requirements.txt (line 7)) (2022.12.7)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate->-r /content/alpaca-lora/requirements.txt (line 1)) (3.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate->-r /content/alpaca-lora/requirements.txt (line 1)) (2.0.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.4.0->accelerate->-r /content/alpaca-lora/requirements.txt (line 1)) (1.11.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate->-r /content/alpaca-lora/requirements.txt (line 1)) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.4.0->accelerate->-r /content/alpaca-lora/requirements.txt (line 1)) (16.0.1)\n","Collecting starlette<0.27.0,>=0.26.1\n","  Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpcore<0.18.0,>=0.15.0\n","  Downloading httpcore-0.17.0-py3-none-any.whl (70 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.9/dist-packages (from httpx->gradio->-r /content/alpaca-lora/requirements.txt (line 12)) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio->-r /content/alpaca-lora/requirements.txt (line 12)) (1.0.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio->-r /content/alpaca-lora/requirements.txt (line 12)) (3.0.9)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio->-r /content/alpaca-lora/requirements.txt (line 12)) (4.39.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio->-r /content/alpaca-lora/requirements.txt (line 12)) (0.11.0)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio->-r /content/alpaca-lora/requirements.txt (line 12)) (5.12.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->gradio->-r /content/alpaca-lora/requirements.txt (line 12)) (1.4.4)\n","Collecting h11>=0.8\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.9/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio->-r /content/alpaca-lora/requirements.txt (line 12)) (3.6.2)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->gradio->-r /content/alpaca-lora/requirements.txt (line 12)) (3.15.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython>=7.8.0->black->-r /content/alpaca-lora/requirements.txt (line 5)) (0.8.3)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r /content/alpaca-lora/requirements.txt (line 12)) (0.19.3)\n","Collecting uc-micro-py\n","  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect>4.3->ipython>=7.8.0->black->-r /content/alpaca-lora/requirements.txt (line 5)) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.8.0->black->-r /content/alpaca-lora/requirements.txt (line 5)) (0.2.6)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.4.0->accelerate->-r /content/alpaca-lora/requirements.txt (line 1)) (1.3.0)\n","Building wheels for collected packages: fire, peft, ffmpy\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116952 sha256=0292ac243e092e029ad5db55f1ccfa5df05e4f5af714791b978949c59d121793\n","  Stored in directory: /root/.cache/pip/wheels/f7/f1/89/b9ea2bf8f80ec027a88fef1d354b3816b4d3d29530988972f6\n","  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for peft: filename=peft-0.3.0.dev0-py3-none-any.whl size=50500 sha256=d1da1d73b8d4b87fd9dac2b0c16b2ed5be260002c54932412aeb9b9291002a4e\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-cdj449d5/wheels/2d/60/1b/0edd9dc0f0c489738b1166bc1b0b560ee368f7721f89d06e3a\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4707 sha256=cbeb302537c15c55d958524029d7e4c8895c63e78882ef8ebc15d92775ae3f95\n","  Stored in directory: /root/.cache/pip/wheels/91/e2/96/f676aa08bfd789328c6576cd0f1fde4a3d686703bb0c247697\n","Successfully built fire peft ffmpy\n","Installing collected packages: tokenizers, sentencepiece, pydub, ffmpy, bitsandbytes, xxhash, websockets, uc-micro-py, tokenize-rt, semantic-version, python-multipart, pathspec, orjson, mypy-extensions, multidict, loralib, jedi, h11, frozenlist, fire, dill, async-timeout, aiofiles, yarl, uvicorn, starlette, responses, multiprocess, mdit-py-plugins, linkify-it-py, huggingface-hub, httpcore, black, aiosignal, transformers, httpx, fastapi, aiohttp, gradio-client, gradio, datasets, accelerate, peft\n","Successfully installed accelerate-0.18.0 aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 bitsandbytes-0.38.1 black-23.3.0 datasets-2.11.0 dill-0.3.6 fastapi-0.95.1 ffmpy-0.3.0 fire-0.5.0 frozenlist-1.3.3 gradio-3.27.0 gradio-client-0.1.3 h11-0.14.0 httpcore-0.17.0 httpx-0.24.0 huggingface-hub-0.13.4 jedi-0.18.2 linkify-it-py-2.0.0 loralib-0.1.1 mdit-py-plugins-0.3.3 multidict-6.0.4 multiprocess-0.70.14 mypy-extensions-1.0.0 orjson-3.8.10 pathspec-0.11.1 peft-0.3.0.dev0 pydub-0.25.1 python-multipart-0.0.6 responses-0.18.0 semantic-version-2.10.0 sentencepiece-0.1.98 starlette-0.26.1 tokenize-rt-5.0.0 tokenizers-0.13.3 transformers-4.28.1 uc-micro-py-1.0.1 uvicorn-0.21.1 websockets-11.0.2 xxhash-3.2.0 yarl-1.8.2\n"]}],"source":["!pip install -r /content/alpaca-lora/requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":567,"status":"ok","timestamp":1682021995855,"user":{"displayName":"Jeff Jiang","userId":"05345923776204115994"},"user_tz":240},"id":"RDc0SUzZtQmS","outputId":"ec165899-dc93-4a4a-ed3f-348e5b9d2367"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found existing installation: transformers 4.28.1\n","Uninstalling transformers-4.28.1:\n","  Successfully uninstalled transformers-4.28.1\n"]}],"source":["!pip uninstall transformers --yes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24944,"status":"ok","timestamp":1682022020798,"user":{"displayName":"Jeff Jiang","userId":"05345923776204115994"},"user_tz":240},"id":"NwE7I3snR8Gq","outputId":"45dbf59c-2e97-4f1b-f1f8-f8ba8fc70a65"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/huggingface/transformers.git\n","  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-lwcocf8o\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-lwcocf8o\n","  Resolved https://github.com/huggingface/transformers.git to commit 8a817e1ecac6a420b1bdc701fcc33535a3b96ff5\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers==4.29.0.dev0) (4.65.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.29.0.dev0) (0.13.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers==4.29.0.dev0) (3.11.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.29.0.dev0) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers==4.29.0.dev0) (2.27.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers==4.29.0.dev0) (2022.10.31)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.29.0.dev0) (0.13.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers==4.29.0.dev0) (6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers==4.29.0.dev0) (23.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.29.0.dev0) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.29.0.dev0) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.29.0.dev0) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.29.0.dev0) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers==4.29.0.dev0) (3.4)\n","Building wheels for collected packages: transformers\n","  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for transformers: filename=transformers-4.29.0.dev0-py3-none-any.whl size=6972118 sha256=cb8cb97608149bcd442cfc4c6ca715abd395ec934c75ac3e73c70d41cebf3635\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-vyevrulv/wheels/f7/92/8c/752ff3bfcd3439805d8bbf641614da38ef3226e127ebea86ee\n","Successfully built transformers\n","Installing collected packages: transformers\n","Successfully installed transformers-4.29.0.dev0\n"]}],"source":["!pip install git+\"https://github.com/huggingface/transformers.git\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YFDyLinaiIUz"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":167,"referenced_widgets":["ded04993afcc4fbfb18a0e54a295d3f5","a52e950e50564e8abaa2cd03d4efc0d5","6d662b3e834d4d3e8b2924bb155dff6e","5ed86517d80b4ca6b143be263a39ee38","1375ad7d5d40476fab2b41d424045918","4c46f89faf034a82ab5dadb290190c14","07cdb99081ac44c2b3d06ef63b66cabc","eaf5d16ad0d6476f8114f3d48382d5bc","dc4e77f23f0345e28362eaf5b1fdcf4b","e1b63017ec9e46acae9cd00cf4c7b583","65a3267c85e246869e408a0ff4a97a2b","ecb27d8aa7804e399e8dc4ddd4fffc49","dbcb503d914b42ea9bc5236e5d0359dd","10e5af09ba1a453b826d03432f1b34b7","6af6692c58e04fdeaa5cb1794a2502ca","2920268322564183b5e64ba60a27c3ab","621ecaf45a3d4fd7a5779b558d7eba9c","5954be8ed4de45dca077a61827f58f7d","fdb2016f20c247eeaaedbea0c98e57a0","7a5afdee8207411180d7fb93734b35cb","d663936857b34349b663f04e658d4f79","c7ef005be75b44688983b750b670aa83","31cca05966c84f6cb3a7cbefd6d975a1","080ef55e07d14c788a6bae9d1166b572","891030b031774d2ebbfc49b54daef975","296e6204fc0c441ab46800ed0bbd3605","4ee3c20df98347aeb0e16e8d45bcbda0","0869b7b66edd4b0dbc7e6b62d08d5855","b2bae635a39645c6bddddb4e31de11c8","e6a2dfd63b75451db3b4b977581b059e","9db8b790e14c49a6b3c0d5b419df24ed","2af88ddbbe6841919a59e1d659545a74","5dcaf658a59b48b7bcbfd0487fec1698"]},"executionInfo":{"elapsed":4233,"status":"ok","timestamp":1682022029358,"user":{"displayName":"Jeff Jiang","userId":"05345923776204115994"},"user_tz":240},"id":"cJaAB-KMn3yW","outputId":"5563509e-a26b-44fc-ec92-91b068582d72"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ded04993afcc4fbfb18a0e54a295d3f5","version_major":2,"version_minor":0},"text/plain":["Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ecb27d8aa7804e399e8dc4ddd4fffc49","version_major":2,"version_minor":0},"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"31cca05966c84f6cb3a7cbefd6d975a1","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/141 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n","The class this function is called from is 'LlamaTokenizer'.\n"]}],"source":["from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig\n","\n","tokenizer = LlamaTokenizer.from_pretrained(\"decapoda-research/llama-7b-hf\", device_map = \"sequential\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["7a6bdd782f2843fb95c3df481b5e86a8","c07282a57d5a4ca1be9cb0e4a84c58dc","edd1d59f8331467fa8f7935a9c6bbfb3","5b8aa4241cf94ca6bfc76b10ed0a579b","07429a9e87b843f2b01d5c761d6e6c29","675ae21144054138a9a27496f546124a","e6e0a79f815c4bbc832cb2456349f39a","5252574f0d344d79814fac0e0c5ba1e7","834327cdea334a8a8f155c4e636c9b05","4cab97120b7b487298e31250679ee56b","7db5d7c87836463eabcd6f4d4d0a7ca6","2989d9a1d56d48d2acfbb7487633193d","9c48881e87784ede84833a2a6404ac5f","de30cb9c6a38436297cdbba37885a2ef","3ddfcea1fe5042e6aef2f1638fa9fd0b","1659e741da2844aaad85fb2ab90f9c14","0cc5104baa8a4944acc7c4b148941c4a","2f1acb21268a4cf9bf3eb2dab5b43c44","f5d677b263e44a5691cc69806ba7b2b8","33ea174a446a4c8bb5749cf35aa9991a","d03feda17f894c2f8b2a8591377a3e5a","19ea2782063445bbb92e0b0e6dd2a1ed","03adfaa468ec4706ba014c391ebe4632","3ce67e35bef4454e854db35295282849","6f1c0d6641094de9b1a623bbbb4bcfec","6306ae343baf4a4c828be4b0c4d514f3","f6ddc9d7ab304ac4a1da614f6c129ffa","2292e961586e4bcfb3ccb65458943e8c","217cbdc4549b452992bf1e3312f93da1","6051455ec9304e73beb2b21c892f8f0b","9fefd41b0f6f41eb8e6b30c61afe65ff","4251140e871b43c599b53562f2fca638","6b65c0f4e0eb44a09c67207e2dc3b256","6fd5c0b2b30e4a9baeaa1e7438684750","f2991dc06b0649488805508d7c4ab514","622b8620e4f24d6880fe750eb5e32296","d5b05b085c5f479889a904311a2607ea","538365548bc34cb9a79e1cf3c05e4452","4f3ff3ee545b471f9983cee836361061","2d2db084ba374a6aa25305b394c5ca6d","c9c8d439953f4241bd424a8de55366e3","b7f83d7c8b19459fb603122b5a5db404","ff39181bdd104a7e8a6e447e8996dc64","7c10fffe2ddb421e9e5c3d0a590e1e91","e8b6b8d2382646ea9db91c6b381174ea","2713b560b609439b8f17f4684b414eef","a5c865cf2f334096979fcd805351876b","acf2b6eaec424613967d90464e52323f","0531d1d2b374414ea1242d4029b5392e","806df847872f47e58bc4f628a0a0dcee","6d08e81fc23443b68c7603c504510a13","1e1935bd9f094eb0b8041b8f3b95436c","02b58fd6e3e64702813aa310c2b8e459","224199e5048c49ff9ee7bb530437ccc6","4b5b9a0a5fea44c389ad9caf8b2a420a","326a0370bbc94612ac8843cdbdcdc6f2","aa5d1cf956d04f39ae2978580a0414d1","ba2a42f9119740b5a6a9edfb1d000f55","76200c148d1d4ad09ded14e13c388e14","300f4b03d77e4782a58f12613868d757","49e3d2cd0c7540f1893892c594fb9e56","f19ab356113b4926bd8f370f929cfc97","63bc83a2ff11415ab82234960b2de4ee","daf3e22b4dbe455484d54560856114dc","81d1482374ff4fac9880d604f8c3fcf2","309071bf77984ce79967e84407b73269","8033f1942ec5422a8c71a3102211e8d2","cb48a65651bc46b09c397bb517ce7cb9","4dab4ad120d745c29b2f42307003523b","1fe4ded222154edeba30e77e9260773d","81bf2ba42fe64e639967f2e54b6af73c","d2612f3ab4f84a9a8def02dc2c3c124c","96ba4e86d54347c4a205dfa2b54e0fe1","4cbda4eeff7a4d9c84686a7a1812be32","93359a1442a6497dbe9e096e230cdf34","03adc8dc38a14ddd80beeddb44c2fa8e","ef407fa0457e443192cc617cbe5e0f49","d3f34db45df34f67b8df3940e7707d50","772ebb281bdc449fa5973c63957c6dab","8ca3047266884168a377bba848f646dc","28b729ad75fb433486a5f82e8a639193","08c8d23e49b74e4a8b848bb481b03729","275e32f137ab423b886440f186f8600c","a93fd5d66649411aab73d8dbe5b1d131","04892873b0e642e989cbbace33973e88","fdbba0bd6a194816b6750772a886f211","7ac89649a165475fa915d6717306c065","b08d5602d5d3421fbf66cd0bae9a16fc","b2215ef477b641d486a65a049f138a4c","68b504c242fd4a3a8822cba4e15aebed","40bdefd10a784082ad1b0992534db63a","97a595ea27794f838a64dc1c2e060263","88ef750286674c39bb2170ac58d983ca","72604a0a39cf4d96907bc1a85b4adcf2","13639ece1395409fb71fae2e508dbd41","b96734b4f8574204bd8e02e6d5d5880e","ee91a18ae6a449c192e8681ca5012107","a87f84ff30f241d2ab883c234d8d52a2","044fbbb90c6640cc8b9ebda3c16cd72b","6b6b14dcfaf640e28123232d130af904","163d16c53d334b33ae25eaf622ff20af","033ff16b1afa42798711765acec529aa","1ce6563d3d7440eebdd7808f54507d96","4ca93de37e82426f992f55fed3e929a1","f06eef64926441e9be98abf6736527db","56c82ae40cc84d3a8d95e8a22b14ca85","492fdfd3ca1b42e9a78ccadc5bc678d5","d6268ff8599240d8a8375a889d7178c4","47ff2747e6d74c159296eedb2bbc209e","4a660e1a3ee048299381990a0ac0e5bf","bfebb4958fc848b0ab9f9a4fd9e8b0ba","3ccfbc27c29043acbcef6af6d1a47b5e","c96d84b11d0a47919fc49964a44d2a23","279270a5962547beacca7ab6bfab92f0","2bbeb52be9114e05b7477d6b8a6413e1","767c78406a5a4f03a3ea04a0726497d5","459e3bcaa84e445d982a2cfe3f10768d","f8a7a2b0f1084f9c9b0295ff697832bf","86be58cdc80d494a9283592cfff434f5","c5a1a18d1d334d4baddfe5fdbed680fa","05986de6d71044f1a39292f028c84921","cc8b877145d5422aa4abb1fa69d872b5","496b150c67104f1cb6c17d82a67f355c","9e40a606239547398923e187d088256a","3eb5221191504acaa2f3023f57d01f9e","f26e617647ef4740bdb4df6ecacf12ce","553576da43a8411bba036a97eac1b444","bbff36bba0804aff935d06f1d136dec8","76ae2522e0334b6fbaa1c4df0a0358b5","8bf6bd57937041109750a62a1f605aa1","b51f833be9d14aa08796417d5131fb89","d5ec81c262634d1aa3fb31efbe1cfa7e","ff5b01bd39f24d96aac95835fab709f2","dfbc96b7a92b45f380229d13b7817ce6","c4bdf3a1d07048d6adb32d88bdd0dcf4","fe8126a27c9e4eed9d802043ec2bcd98","57faa31bb00d4b0881ba092167024be5","dc5f56ce4be94c88b01533f1777d33dd","f28a2b6ce504415db8b90671da5259f8","a274061fabf74a3fa60f8bd6fba18581","ea65daa886c2432cb8d2486c0c2795e6","6897df6af87c453c99902b732599a0db","d32f233ee3124d49945e71dbe71ed11d","30564e66c93641018d0ea9080d6e9178","39c2ed9224184e2d87146fc535c759f6","a4ba4dc5ea8c402c9ac517108f8a8513","34e8dbaae7d24356bb729e901dc02ff6","bedc33aac60d41b3add4c05a091252d4","f7cab19974bd4cbf86e5fcf3b571b3ab","230ac2c689f44216bb50e24d7449bf4c","33260738fdfc4faa80bc5d2b772ded81","73a0fe92b5a049868e0f2e04f949b8cc","69261fc2e9044af78fd33e971f5da467","bfe17488de134e64abf775e1aa244843","6a633e4948f846a59a20ef06d87f0f1a","12be3ef31b4e40dd939a44aa49d9f88e","89d8bd0d45e34080b0cd8a1b49a87a8c","4a57a9a827ba4ba8a5f212b668810187","837095352e2f4827a07c25aa39e6c73c","4f477940af1a43bcb186c9775692558a","2aac1b6b485048e3970547613ccfe391","3c9f789b2659472c97fa75382751c4b3","bd31cb861c114218a1ab377a607b1667","1ba42c0c2c57450f85ed2e644804a8de","fdada141380a42f69a83f2c86301a833","aaf8d98ee15544aabc069ff4a5b99ec4","53b4fc3df5024193abdfa37f6c11d244","d9e75af7c70a4a3985e740cfcaf4808d","95dce5ca6887461a860852357dfaa2d8","1bfb58e5f599444e87e915f406e48dd2","ed1a155ec81d40adaaaa578b3fc982d5","62fe9547e6404e72a628a6f0ddd169d3","4058530a8a4c4fd68d18615da5ab3d66","fa85c23f76ea415ba22dc00372d5b076","55dc35414c7e42dbb8682b953a8b06e9","0a254c8160a04f7797102087d8f5aa28","79c336da6677462abc0d43b0d75a8798","edd6fa8825194c8aa15396dcee532f56","f1a604336e6642ac8d8576cce68103be","3fc2bd19a41b430981f031a71cfa942d","c203332179b140b4854ae6a2af347f5e","2b6bc72951174cfdbca6bc0f277e313f","22380dbd2b7a4fd1894a83edcd906705","749dd6dfa80948c58a6ebb241851d2aa","93ccf0d2022b465fb99d68dae70d4d68","fbd592116f7f4b8480e2f18a3b2b9cb4","77e0b189478c49c5acca113fce59b211","eed3fd84f2ce47aeb7192d35071893c3","2323fe279cd046b1bc75563a1cc8314a","c76a85d2f842492ebbd6c350a23ea125","ee3ad2d627ab49198327c38b9a274041","5901207325ce46aeaf752a752127251a","45806317c9a9451d9e1780a487b379bb","259536c9d8304d0f8185920ca4210352","c77ca6c604cc44a69d7f9f6c4f725176","230c5a394fc6433bbbb5134fa3dd42cb","adf2a17d826749438a74b4eeb050ed8e","267a440ce7b14ad49aec86f627b6af29","3019805d5fd14a68ae12583aaa109edb","e7563fc0e2e641a187254627f785b8f0","5b7ad6dd5b0c48efbf8b5abd5b4439c6","950a01ac64324e2ca920b3f211b39d0c","02dc901719cf458eab4c0072e3e7ee67","917de8cc343e49ffa35d83808ca2ca67","3661989d4b854295899d2619a27099fd","1cd303bec54e4a54a9f55831c5c9cbd7","524b2064b9844e6980f2395edd39962c","2cc77f6ca28b4e95922573984db1bbbf","b5c7b6dd0212458abd3878695c29307d","8b1d07ac27944d079ba03cbfdc367019","6491df7e510a49609a9c971f4c046cb5","611bcfd221314b67b107741761e9ecd1","feaf16c83b314035b4cfce3554ff5490","43e272d30b0d450d9afe265412964be2","2af07e00df4240fd9c014b0cd0ba695a","5525992033a043ed8958851e0a20d757","b36d93c5ccb14b8690d173bd5f73c2f3","27e3bc5aa9bc4b759846b99964807bb2","8bebcc05ca254a5c8e81081c67bdba1e","d19e7998c9154fe7aa74c1dd0a5ac0e4","eba8f36a561b48f58b971ba849c1873e","d7eff3cb51f141278054d630255c6ada","444677ff9b1f46ffa8aadeefb4c0f888","811723bc79b14d7cbdeaf4b8fedb9067","b99f9088154d402f92e64c5a86125810","b36185910e4f4e2b8703c59531be8917","509ac9e404aa40f3a1812629f9dfea40","0c7be7bbf37740ec82a7c4562345ca68","0d1ca330de0047cf90dd6232c2aa17fa","3192e0d3d4c64c298ba9db2300ed805b","0b7ec61c651249c48568a46a9c72e6f4","1e2fe830fb644298b100999eb81170b3","da2cc3f552d746fc81e3f5b0ee54695f","bb09e98724d0469abffd21d174e3036d","11e90d7d4c4c47258ce5512837bde636","8c12b2ed681047c4b94031715d27c2d2","d29327c4fd4941c4a87d47854d2d3939","34b35fce32174340897d65c99c83db52","d4e8fa4e620a4cd2bc11dea1b8c64009","96f09e2e68dc4a22980d584beecb2692","6fdd0174607a4a5589a0ebab24c73868","f65d31b8674b4050867b8e8eee3125f8","a664fadb5c84459eade67e52e9fa3841","ece4ebd5a024472da4632c9ad3df489c","4096833b255544bca501af863de2a48f","b916676b7076423f8c616328a391666d","976761ca52034ed0ba22356c0821e84d","51635d3d50204d91a67852afe2d21fcc","7c3497c97cb24475ac1e198ca2a63cc3","ad1914fc0dd4424291770669656f3c77","33ee693d3ab148e38582516043ff96bf","61ccad893b494587b538d1d4789c078f","5c800f3e95a747e8b97a1209a50ceb2b","70f301f0ac404fd2beb36bed90f5f87e","291b4ae422794f39acc4c50658f8c398","80e81f4bc0cd4e2c8c12a9c745a5ab46","057123908a194f5190a0bedad16ece13","8f28afab2d364f849ae34bc24bdbe047","4dc1761688ad4f4fa9a36423188aa122","f0d9da7ab2a944d39f0f88f109499864","c865db7d7af1446c8441e2fec5fc96b8","b2c603cc81af48b6bdf4e56bf3c71a9d","f59330d0c0434aac8820e38c010be4e0","20fd5e0f65e94b518d9ebefb31f98a59","f74e733ce2964fa79643b7ae2d7cb9dd","62f5e6d2df744773bfd1d38f8bc8726f","ff585de9a9c745e5a7b9c3e93e25e1d8","d7251ab77c64462087ea4b645d16b7ae","7369b61e99d94034a8c84f6b51496584","c71d50520c564ce08c2fe8ef82ea444e","94b554e148a4459787597e960b4c94a6","9c80b2dbd26c4f5d8b36312032c9423e","6324ffc664b54a92817c0b9e53855ada","ce393a99d58c47c2b2ec8ce1f704d0e8","77c14af5b2f94e49a7e5442e4666b4fa","87852e152acb42ce9905812b314d04b7","c1063d696d8d417a8470c9cf5131d30d","12dc8dd6213444618b1e9d33d15a4a1e","86650cf5f66349aa88bc6c6246955a29","11791b9feecb4afbb839134be84b342c","61b179a79400441f801c319a5ca06dfa","d9dd0458c7df4f29830db1cce793a465","a6e4110cd072425684f1b13fd6ce81c2","c8a126219ca842b9a551e5b13f3c9a11","db796914c43448cdb07c55df71216b82","f74fe44e1bb341809436acbb5e5abc8c","904b2155d41b4a7d8cd95c1b8d885e04","228ba66c821f456593c94930cefdd193","d56110e3f7b0453cabe6f0a741b4fb80","25ed5328fce94fa1ab41287b722b1e55","97ff210e18fb43469b1d5e796b5076cd","436ce45d7fcb40a6b0852ec4b3d0efa7","761932d5e36749e0ae65f17020696a9f","a4afbc35d1664c48b764ba3bad454466","7327897a1fc14ffb88a80c09d09741d1","ab66dd82694d449c94d19e09491264f3","90a03cdf588c40109801ee0289d3cfad","a1a2760281254e7bb74af8e2909bba01","18beb410ec99404f814fa354e5edda80","fec17c6b41894f63ab7bbb81d62657cb","474125e3d35b4c5b8cd6088a4536e299","b391f47369d043a8b0697f22e67d53ee","d2393441c1684f508b6712410bd1b6b3","3c835be0c7004679859649ba023d5823","fd4b7c0f6eaf44418df7a5ca7f627d00","9036bd5283d14584822543a779408dbb","174faf8507e8469b94c840bbef42b078","f58400974faf4296b83b6392b7c08bca","74b522861d6f4a12959fbb2801cb3a91","fccc9f29b16b4eab9c57a26141bf564e","da34bb387f12428c858ef69e4fe0ed39","1c4027366f3c4d448c3f30a3f87a1c95","c63781df290b40929fe0b92aac51790b","4d3d457757854832be472bbc42e2d00c","59269357b6644033b7a55afd4225543b","7d3e34a22d674575b6f62c4e261fffa4","5fc5b2a4b7c9432996ab114e71fd2ce5","2c28ae6e6c554e7c939b92f6f30bab87","8d13cb6c86aa4dd9ab00550048ba0b30","2b9bd1d5afe14f95b64cd73868e8200c","b0dd2d0718604186ae849f36d3671654","383e3567218d4771873f4788014bf741","7b5bf6746a85489db22893309a5ae2a8","e1adbaaa713b446885865937817bf0fd","86463fa528c04a0f9cf0bf11cdd2a996","d60df0c6f9364b0bb9db5455f6a2498d","496f31de0798436caec837c2d98afa88","5406db2bf51a4200a2aa50a0b9b89346","cd41362a444649be961103bedbba6742","dc63e0b9527846c4bb843617c3a92e16","f20ddfa75a3f4439aa794c1048e4e6f4","18b592fab0fb44c3aafc77ce68659f62","8f6dbe64e5ae4eada01ed59a72163a3f","d93464e84cc147169bbb2523d0794a5e","51050ea48e534131aab846c44da12b50","54a2c3994d044c43987febdd36b36488","b323ba493b434d7a929dd72473b59ec0","55a991d196d34b309524268e681ff433","049a698cbb7d4ccc98c072da50c9d915","9e7c2943ea034b4dbb34ef61720c527e","ce450ceaf7964143a5525cffffcc1fb0","3eaf2830c25b4e108f7d8ff4f5e0d555","221c8471f00945aaa5221b007ebe751a","a2350b42aa05470c835636f8983e5e0e","10cfb716814a4f36a30c482ce13a0054","e424354dec9f4226be42ab07c6d10d1a","09202b7416b5416eb99a040f02293956","c17bfe158dbd4a429145be8794851869","d3cb484eb0dd4889a0d17addf7e9e3bc","40ea8208a76a48b3aba23ac0005d2071","c8b12ec0bb7c4b3bb64f6206b18e6d87","bd705b411c6d42d5af3dbe8c02572a4f","cf05d1ab847a4b7da15ca8e7c47c7066","8e7e9e1857634db981d9aee2e63ec374","99fee544842249d59ede89e21aeda41b","a7d757c5e2aa4578aed32d65038e36f4","875b15f894574b9cbbf0c150dcb5257c","e9ba0c629bb74e6aa42e3b55c3ee378b","cf5436a706c148e1a75cad0ac25598e1","4d2e19951ebe46ce9226aa0a171efd34","a7d9818c24e54c199907ea236bb725fc","ab6e0280765040d381698a4ab7955cd4","da901fcb1941421e9445915a33d85195","4e62f76ae9544686b166f24493783dfe","e9667e23331a48cd83cd197bb2ec9db8","2a3299bf46ae44ec973732fc8bd33aa6","bef8027ac5694b819c1eb2e95f8e25a5","50b7c3f0c68343359174acbd2e256da7","b45b8a3049694e21903984bdaaed1b34","2cf3594ff9e34e3e8c9d3744c1845b3a","136e7f4b3ffc43e5a6d22407502fec38","5609894760754a999d40baf8a5157318","a98cbefbfa5e4b8fbcb0017f2f508583","bb41f5814bdd470e821954a561278297","d304e664b57240dc833f06b6dc55c5d4","09638b80c97949899b88253c2575c21f","941e9ef486ca4725be64315930371b31","237cf120d9b6486993cf19f8a64f985e","431b1c4498454d3a993c8002731a6c32","342a675926d14cc184917d0ab3074ad4","e67f476d217b485087454ad07e053a5e","59f9515d99e043d387d7548fed99c29b","9e170b0563734813b2cca07e30698ef0","83611a87a4b340e5afa9e34cab0df33c","b0c5b68eb43f48a189357a331b2afdf9","78cef5111af246bc9c580cc24b4f4291","5bc9f721e8fc469593108daa03cb6574","140b62fca0d344d094faba56f0f93a06","7e252a6428844436a9eedc0cd7bde7d5","a165b1d9d6d9411ebbfa19872942c2f3","e21c7f3c3b34424980d7cdddbd26f0e2","b7710d76d4ce43f78db7297f110c6bd5","fdde59fcba0a4734b697d6eb5b0c7084","7a4bc89930d346588b8b532c08dfe166","70569314bb03436d87a5cc466e4af9dc","c6ef1df59fd84a6d8e5fa8d59612c387","ccc9c9302ff849738d953afc3c528b7e","c09383fbe20345bfa3552beebc06c6cc","de1c52b1b72e43a296d495563cbbc69f","906b92e0dc2a42459530769df13081ac","6338aea8892f40048863ccba6d800c33","056101b4e28e43b5b257f9ef134203fd","44bb6daf2909444a8603b048544a7b14","e58c88f5046e4aabb2720cd189a41449","0f6315bc1e5e43f5bb65fb4a8ab74814","f6fb4431bb3d4ce88aaa987de311d74b","05bc929b21e24ee29077884eade39751","716cad98991248acb3f7e40b83811a4c","8f062c5fa3c54dbb8e7849fe04b764e0","101a83129c444fb68140afc15438ce7b","b2a06ca62e2f47d1b76d88e7e3f3153e","dc3bddd862f74488a3bb94de941b5253","a93bd244eb0f4e8a8cb778314b2a1e8f","b296f220dc5a4df881eb984e30b3c242","37084fc1cd32448dbed5fc80ac4794f2","c80f0aab39d447b5bff1b2a7225cdbfc","ec92d8aa4c804d1fbfd1b3f8d5a389a4","7aa7585d4690435ab4373397e79e0744"]},"executionInfo":{"elapsed":77827,"status":"ok","timestamp":1682022107181,"user":{"displayName":"Jeff Jiang","userId":"05345923776204115994"},"user_tz":240},"id":"czh0UbrvQZ7C","outputId":"188d5be9-c209-490b-c153-6d6f8b7408c3"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: /usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n","  warn(msg)\n","/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n","  warn(msg)\n","/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//172.28.0.1'), PosixPath('8013'), PosixPath('http')}\n","  warn(msg)\n","/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('--listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https'), PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-a100-s-8ij6j5mrm6pn --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true')}\n","  warn(msg)\n","/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n","  warn(msg)\n","/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//ipykernel.pylab.backend_inline')}\n","  warn(msg)\n","/usr/local/lib/python3.9/dist-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n","Either way, this might cause trouble in the future:\n","If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n","  warn(msg)\n"]},{"name":"stdout","output_type":"stream","text":["\n","===================================BUG REPORT===================================\n","Welcome to bitsandbytes. For bug reports, please run\n","\n","python -m bitsandbytes\n","\n"," and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n","================================================================================\n","bin /usr/local/lib/python3.9/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so\n","CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n","CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n","CUDA SETUP: Highest compute capability among GPUs detected: 8.0\n","CUDA SETUP: Detected CUDA version 118\n","CUDA SETUP: Loading binary /usr/local/lib/python3.9/dist-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"]},{"name":"stderr","output_type":"stream","text":["Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7a6bdd782f2843fb95c3df481b5e86a8","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/427 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2989d9a1d56d48d2acfbb7487633193d","version_major":2,"version_minor":0},"text/plain":["Downloading (…)model.bin.index.json:   0%|          | 0.00/25.5k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"03adfaa468ec4706ba014c391ebe4632","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/33 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6fd5c0b2b30e4a9baeaa1e7438684750","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00001-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e8b6b8d2382646ea9db91c6b381174ea","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00002-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"326a0370bbc94612ac8843cdbdcdc6f2","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00003-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8033f1942ec5422a8c71a3102211e8d2","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00004-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d3f34db45df34f67b8df3940e7707d50","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00005-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b2215ef477b641d486a65a049f138a4c","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00006-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b6b14dcfaf640e28123232d130af904","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00007-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bfebb4958fc848b0ab9f9a4fd9e8b0ba","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00008-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc8b877145d5422aa4abb1fa69d872b5","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00009-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ff5b01bd39f24d96aac95835fab709f2","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00010-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30564e66c93641018d0ea9080d6e9178","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00011-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6a633e4948f846a59a20ef06d87f0f1a","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00012-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aaf8d98ee15544aabc069ff4a5b99ec4","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00013-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"79c336da6677462abc0d43b0d75a8798","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00014-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eed3fd84f2ce47aeb7192d35071893c3","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00015-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3019805d5fd14a68ae12583aaa109edb","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00016-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8b1d07ac27944d079ba03cbfdc367019","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00017-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eba8f36a561b48f58b971ba849c1873e","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00018-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e2fe830fb644298b100999eb81170b3","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00019-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a664fadb5c84459eade67e52e9fa3841","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00020-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"70f301f0ac404fd2beb36bed90f5f87e","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00021-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f74e733ce2964fa79643b7ae2d7cb9dd","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00022-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"87852e152acb42ce9905812b314d04b7","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00023-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"904b2155d41b4a7d8cd95c1b8d885e04","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00024-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1a2760281254e7bb74af8e2909bba01","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00025-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"74b522861d6f4a12959fbb2801cb3a91","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00026-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2b9bd1d5afe14f95b64cd73868e8200c","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00027-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f20ddfa75a3f4439aa794c1048e4e6f4","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00028-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3eaf2830c25b4e108f7d8ff4f5e0d555","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00029-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf05d1ab847a4b7da15ca8e7c47c7066","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00030-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4e62f76ae9544686b166f24493783dfe","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00031-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d304e664b57240dc833f06b6dc55c5d4","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00032-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"78cef5111af246bc9c580cc24b4f4291","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00033-of-00033.bin:   0%|          | 0.00/524M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ccc9c9302ff849738d953afc3c528b7e","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"716cad98991248acb3f7e40b83811a4c","version_major":2,"version_minor":0},"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import sys\n","import torch\n","from peft import PeftModel\n","import transformers\n","\n","from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig\n","import bitsandbytes as bnb\n","load_8bit = True\n","\n","model = LlamaForCausalLM.from_pretrained(\n","            'decapoda-research/llama-7b-hf',\n","            # load_in_8bit=load_8bit,\n","            offload_folder=\"/content\",\n","            torch_dtype=torch.float32,\n","            device_map=\"auto\",\n","        )\n","# model = PeftModel.from_pretrained(\n","#     model,\n","#     \"tloen/alpaca-lora-7b\",\n","#     offload_folder=\"/content\",\n","#     torch_dtype=torch.float16,\n","# )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1681509223608,"user":{"displayName":"Jeff Jiang","userId":"05345923776204115994"},"user_tz":240},"id":"d-1qJ3I-gf0S","outputId":"c07293dc-83e8-4fce-a222-df5261131370"},"outputs":[{"data":{"text/plain":["LlamaForCausalLM(\n","  (model): LlamaModel(\n","    (embed_tokens): Embedding(32000, 4096, padding_idx=31999)\n","    (layers): ModuleList(\n","      (0-31): 32 x LlamaDecoderLayer(\n","        (self_attn): LlamaAttention(\n","          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n","          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n","          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n","          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n","          (rotary_emb): LlamaRotaryEmbedding()\n","        )\n","        (mlp): LlamaMLP(\n","          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n","          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n","          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n","          (act_fn): SiLUActivation()\n","        )\n","        (input_layernorm): LlamaRMSNorm()\n","        (post_attention_layernorm): LlamaRMSNorm()\n","      )\n","    )\n","    (norm): LlamaRMSNorm()\n","  )\n","  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",")"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["def generate_prompt(instruction, input):\n","  prompts = []\n","  for (i, item) in enumerate(input):\n","    if item:\n","            output =  f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n","\n","    ### Instruction:\n","    {instruction}\n","\n","    ### Input:\n","    {item}\n","\n","    ### Response:\n","    \"\"\"\n","    else:\n","            output = f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n","\n","    ### Instruction:\n","    {instruction}\n","\n","    ### Response:\n","    \"\"\"\n","    prompts.append(output)\n","  return prompts\n","\n","\n","model.eval()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yfIVMhHxi9Z8"},"outputs":[],"source":["generation_config = GenerationConfig(\n","        temperature=0.1,\n","        top_p=0.75,\n","        top_k=40,\n","        num_beams=4,\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V95nxdQyaql4"},"outputs":[],"source":["def evaluate(\n","        instruction,\n","        input=None,\n","        temperature=0.1,\n","        top_p=0.75,\n","        top_k=40,\n","        num_beams=4,\n","        **kwargs,\n","):\n","    prompt = generate_prompt(instruction, input)\n","    inputs = tokenizer(prompt, return_tensors=\"pt\",padding=True, truncation=True)\n","    input_ids = inputs[\"input_ids\"].to(device)\n","    generation_config = GenerationConfig(\n","        temperature=temperature,\n","        top_p=top_p,\n","        top_k=top_k,\n","        num_beams=num_beams,\n","        **kwargs,\n","    )\n","    with torch.no_grad():\n","        generation_output = model.generate(\n","            input_ids=input_ids,\n","            generation_config=generation_config,\n","            return_dict_in_generate=True,\n","            output_scores=True,\n","            max_new_tokens=2048,\n","        )\n","    s = generation_output.sequences[0]\n","    output = tokenizer.decode(s)\n","    return output.split(\"### Response:\")[1].strip()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X_7H_znxX7gb"},"outputs":[],"source":["# with torch.no_grad():\n","#   print(model(input_ids=input_ids)['logits'][-1].max(-1))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1119,"status":"ok","timestamp":1681509224719,"user":{"displayName":"Jeff Jiang","userId":"05345923776204115994"},"user_tz":240},"id":"4PMlrewXW-XZ","outputId":"5307ae00-8236-4142-fcfe-6b5af6a89149"},"outputs":[],"source":["# Testing\n","'''\n","with torch.no_grad():\n","  generate_ids = model.generate(input_ids=input_ids,max_new_tokens=1)\n","  for i in generate_ids:\n","    print(tokenizer.decode(i))\n","  # print(input_ids)\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mX-a28l1odh1"},"outputs":[],"source":["value_vec = torch.zeros(32000, dtype=torch.float).to(device)\n","correctnessvec1 = torch.zeros(32000, dtype=torch.float).to(device)\n","correctnessvec2 = torch.zeros(32000, dtype=torch.float).to(device)\n","correctnessvec3 = torch.zeros(32000, dtype=torch.float).to(device)\n","correctnessvec4 = torch.zeros(32000, dtype=torch.float).to(device)\n","correctnessvec5 = torch.zeros(32000, dtype=torch.float).to(device)\n","\n","# Define the indices and values to replace\n","# indices of tokens 0 to 9\n","indices = [29900, 29896, 29906, 29941, 29946, 29945, 29953, 29955, 29947, 29929]\n","# indices of 0\n","indices1 = [29900]\n","# indices of '.'\n","indices2 = [29889]\n","values = [0.01, 0.15, 0.3, 0.4, 0.45, 0.5, 0.6, 0.7, 0.85, 0.99]\n","\n","# indices of token A to C\n","indices_alpha2 = [319,350,315]\n","# indices of token 1 to 3\n","indices_numeric = [29896,29906,29941]\n","\n","correctness1 = torch.ones(1).to(device)\n","correctness2 = torch.ones(1).to(device)\n","correctness3 = torch.ones(10).to(device)\n","correctness4 = torch.ones(3).to(device)\n","correctness5 = torch.ones(3).to(device)\n","# Create a tensor of the same shape and data type as the destination tensor\n","source_tensor = torch.tensor(values, dtype=torch.float).to(device)\n","\n","\n","# Replace the values at the specified indices\n","value_vec[indices] = source_tensor\n","correctnessvec1[indices1] = correctness1\n","correctnessvec2[indices2] = correctness2\n","correctnessvec3[indices] = correctness3\n","correctnessvec4[indices_alpha2] = correctness4\n","correctnessvec5[indices_numeric] = correctness5"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vZU_69yq_6ES"},"outputs":[],"source":["from transformers import (\n","    AutoTokenizer,\n","    AutoModelForCausalLM,\n","    LogitsProcessorList,\n","    MinLengthLogitsProcessor,\n","    StoppingCriteriaList,\n","    MaxLengthCriteria,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aOCHpM3gmpxk"},"outputs":[],"source":["def get_value(board_string):\n","  prompt = \"\"\"I am the O player in a game tic-tac-toe, the other player is X and I'm supposed to play next. The board configuration is given in input. If I play optimally and the opponent play optimally, reply a single integer between 0 to 9 representing how likely it is for me of winning, with 0 being least likely and 9 being most likely. No explanations.\"\"\"\n","  inputs = generate_prompt(prompt, board_string)\n","  inputs = tokenizer(inputs, return_tensors=\"pt\", padding=True)\n","  input_ids = inputs[\"input_ids\"].to(device)\n","  scores = []\n","\n","  generate_ids = model(input_ids=input_ids).logits[:,-1,:]\n","\n","  tensor_softmax = torch.softmax(generate_ids, dim=-1)\n","\n","  tensor_sum = (tensor_softmax * value_vec).sum(-1)\n","\n","    \n","\n","  return tensor_sum"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kExtnzB3b3Ta"},"outputs":[],"source":["import torch.optim as optim\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tQ8z_n-1u8cM"},"outputs":[],"source":["# simplified version of policy estimate\n","def get_policy(board_string):\n","  prompt = \"\"\"I am the O player in a game tic-tac-toe, the other player is X and I'm supposed to play next. The board configuration is given in input. If I play optimally and the opponent play optimally, reply a single move between 1 to 9 representing what I should play next, with 1 representing A1, 2 representing A2, so on and so forth, and 9 representing C9. No explanations.\"\"\"\n","  inputs = generate_prompt(prompt, board_string)\n","  inputs = tokenizer(inputs, return_tensors=\"pt\", padding=True)\n","  input_ids = inputs[\"input_ids\"].to(device)\n","  generate_ids = model(input_ids=input_ids).logits[:,-1,:]\n","\n","  # Initialize the sum variable to 0\n","  # result = torch.zeros(1).to(device)\n","  # for item in scores:\n","  #   item.requires_grad = True\n","  # indices_alpha = [29909,29933,29907]\n","  # indices_alpha2 = [319,350,315]\n","  # indices_numeric = [29896,29906,29941]\n","  indices = [29896, 29906, 29941, 29946, 29945, 29953, 29955, 29947, 29929]\n","\n","  probs = torch.softmax(generate_ids, dim = -1)[:,indices]\n","\n","\n","  return probs\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3PeFgb1f4bPT"},"outputs":[],"source":["import torch.nn as nn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gn1X_iLslcXH"},"outputs":[],"source":["import torch.optim as optim\n","import tqdm\n","import time\n","from torch.autograd import Variable\n","import logging\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2hMzNoGq9W_N"},"outputs":[],"source":["from tictactoe.TicTacToeGame import TicTacToeGame as Game"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9XpAGYN5l57K"},"outputs":[],"source":["class AverageMeter(object):\n","    \"\"\"From https://github.com/pytorch/examples/blob/master/imagenet/main.py\"\"\"\n","\n","    def __init__(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def __repr__(self):\n","        return f'{self.avg:.2e}'\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","class dotdict(dict):\n","    def __getattr__(self, name):\n","        return self[name]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3SCrh4jFl_Pi"},"outputs":[],"source":["args = dotdict({\n","    'lr': 0.001,\n","    'dropout': 0.3,\n","    'epochs': 10,\n","    'batch_size': 1,\n","    'cuda': torch.cuda.is_available(),\n","    'num_channels': 512,\n","})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lVU_7VmaLEHT"},"outputs":[],"source":["import torch.nn.functional as F\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mxrSrIy8XZf8"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","mse = nn.MSELoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K6H8N16wmufg"},"outputs":[],"source":["def loss_pi(targets, outputs):\n","        # targets += 3\n","        return criterion(outputs, targets)\n","\n","def loss_v(targets, outputs):\n","    # print(targets, outputs, \"aaa\")\n","\n","    return mse(outputs.unsqueeze(0),targets.unsqueeze(0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nMj2CE2FBgzp"},"outputs":[],"source":["def print_board(board_list):\n","  if board_list.dim() == 3:\n","    lst = []\n","    for board in board_list:\n","          board = board.reshape(3,3)\n","          n = board.shape[0]\n","          letters = ['A', 'B', 'C']\n","          string = '   '\n","          for y in range(n):\n","              string += f'{y+1} '\n","          string += '\\n'\n","\n","          for x in range(n):\n","              string += f'  {letters[x]} '\n","              string += '|'\n","              for y in range(n):\n","                  string += 'X' * int(board[x, y] == -1)\n","                  string += 'O' * int(board[x, y] == 1)\n","                  string += ' ' * int(board[x, y] == 0)\n","                  string += '|'\n","              string += '''\\n'''\n","          lst.append(string)\n","  else:\n","        board = board_list.reshape(3,3)\n","        n = board.shape[0]\n","        letters = ['A', 'B', 'C']\n","        string = '   '\n","        for y in range(n):\n","            string += f'{y+1} '\n","        string += '\\n'\n","\n","        for x in range(n):\n","            string += f'  {letters[x]} '\n","            string += '|'\n","            for y in range(n):\n","                string += 'X' * int(board[x, y] == -1)\n","                string += 'O' * int(board[x, y] == 1)\n","                string += ' ' * int(board[x, y] == 0)\n","                string += '|'\n","            string += '''\\n'''\n","        lst = string\n","  return lst"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4bTpDqQFkQPf"},"outputs":[],"source":["def is_nan(x):\n","    return x != x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Dq1zcoxabaq"},"outputs":[],"source":["import torch\n","import bitsandbytes as bnb\n","from transformers import GPTNeoForCausalLM\n","from bitsandbytes.optim import GlobalOptimManager"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QARy_2Ros6ft"},"outputs":[],"source":["accum_iter = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gOADqUgtjzwr"},"outputs":[],"source":["def train(examples):\n","  optimizer = torch.optim.AdamW(model.parameters(), lr=0.00003, betas=(0.9, 0.995))\n","  optimizer.zero_grad()\n","  print(examples,\"examples\")\n","  for epoch in range(args.epochs):\n","      print('EPOCH ::: ' + str(epoch + 1))\n","      # Actual Training Part\n","\n","\n","      pi_losses = AverageMeter()\n","      v_losses = AverageMeter()\n","\n","      batch_count = int(len(examples) / args.batch_size)\n","\n","      t = tqdm(range(batch_count), desc='Training Net')\n","      for (i, _) in enumerate(t):\n","          \n","          sample_ids = np.random.randint(len(examples), size=args.batch_size)\n","          boards, pis, vs = list(zip(*[examples[i] for i in sample_ids]))\n","\n","\n","          boards = torch.FloatTensor(np.array(boards).astype(np.float64))\n","          target_pis = torch.FloatTensor(np.array(pis))\n","          target_vs = torch.FloatTensor(np.array(vs).astype(np.float64))\n","          target_vs.requires_grad = True\n","          target_pis.requires_grad = True\n","\n","          # predict\n","          if args.cuda:\n","              boards, target_pis, target_vs = boards.contiguous().cuda(), target_pis.contiguous().cuda(), target_vs.contiguous().cuda()\n","\n","          # TODO: Convert board to string\n","          board_string = print_board(boards)\n","\n","          # compute output\n","          out_v = get_value(board_string)\n","          out_pi = get_policy(board_string)\n","          l_pi = loss_pi(target_pis, out_pi)\n","          l_v = loss_v(target_vs, out_v)\n","          total_loss = (l_pi + l_v)\n","          # total_loss = Variable(total_loss,requires_grad=True)\n","          print(\"Target_pi: \", target_pis, \"predicted_pi\", out_pi, \"targetv\", target_vs, \"predicted_v\", out_v, \"policy_loss\", l_pi, \"value_loss\", l_v)\n","          if is_nan(l_pi) or is_nan(l_v):\n","            \"NANS DETECTED !!\"\n","            if is_nan(l_pi):\n","              l_pi = torch.tensor(0.0, requires_grad=True)\n","              pi_losses.update(0, boards.size(0))\n","            if is_nan(l_v):\n","              l_v = torch.tensor(0.0, requires_grad=True)\n","            # record loss\n","            pi_losses.update(l_pi.item(), boards.size(0))\n","            v_losses.update(l_v.item(), boards.size(0))\n","            t.set_postfix(Loss_pi=pi_losses, Loss_v=v_losses)\n","            optimizer.zero_grad()\n","\n","          else:\n","            \n","\n","            # record loss\n","            pi_losses.update(l_pi.item(), boards.size(0))\n","            v_losses.update(l_v.item(), boards.size(0))\n","            t.set_postfix(Loss_pi=pi_losses, Loss_v=v_losses)\n","\n","            total_loss.backward()\n","\n","            if (i % 1 == 0) or (i + 1 == len(t)):\n","              optimizer.step()\n","              optimizer.zero_grad()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xb1_LH1wDnnW"},"outputs":[],"source":["@torch.no_grad()\n","def predict(board):\n","  # timing\n","  start = time.time()\n","  #  preparing input\n","  board = torch.FloatTensor(board.astype(np.float64)).to(device)\n","  boardstr = print_board(board)\n","  v = get_value(boardstr)[0]\n","  pi = get_policy(boardstr)[0]\n","  return pi.data.cpu().numpy(), v.data.cpu().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GIMpaXOSCrTU"},"outputs":[],"source":["import logging\n","import math\n","\n","import numpy as np\n","\n","EPS = 5e-7\n","\n","log = logging.getLogger(__name__)\n","\n","\n","class MCTS():\n","    \"\"\"\n","    This class handles the MCTS tree.\n","    \"\"\"\n","\n","    def __init__(self, game, args):\n","        self.game = game\n","        self.args = args\n","        self.Qsa = {}  # stores Q values for s,a (as defined in the paper)\n","        self.Nsa = {}  # stores #times edge s,a was visited\n","        self.Ns = {}  # stores #times board s was visited\n","        self.Ps = {}  # stores initial policy (returned by neural net)\n","\n","        self.Es = {}  # stores game.getGameEnded ended for board s\n","        self.Vs = {}  # stores game.getValidMoves for board s\n","\n","    def getActionProb(self, canonicalBoard, temp=1):\n","        \"\"\"\n","        This function performs numMCTSSims simulations of MCTS starting from\n","        canonicalBoard.\n","\n","        Returns:\n","            probs: a policy vector where the probability of the ith action is\n","                   proportional to Nsa[(s,a)]**(1./temp)\n","        \"\"\"\n","        for i in range(self.args.numMCTSSims):\n","            self.search(canonicalBoard)\n","\n","        s = self.game.stringRepresentation(canonicalBoard)\n","        counts = [self.Nsa[(s, a)] if (s, a) in self.Nsa else 0 for a in range(self.game.getActionSize())]\n","\n","        if temp == 0:\n","            bestAs = np.array(np.argwhere(counts == np.max(counts))).flatten()\n","            bestA = np.random.choice(bestAs)\n","            probs = [0] * len(counts)\n","            probs[bestA] = 1\n","            return probs\n","\n","        counts = [x ** (1. / temp) for x in counts]\n","        counts_sum = float(sum(counts))\n","        probs = [x / counts_sum for x in counts]\n","        return probs\n","\n","    def search(self, canonicalBoard):\n","        \"\"\"\n","        This function performs one iteration of MCTS. It is recursively called\n","        till a leaf node is found. The action chosen at each node is one that\n","        has the maximum upper confidence bound as in the paper.\n","\n","        Once a leaf node is found, the neural network is called to return an\n","        initial policy P and a value v for the state. This value is propagated\n","        up the search path. In case the leaf node is a terminal state, the\n","        outcome is propagated up the search path. The values of Ns, Nsa, Qsa are\n","        updated.\n","\n","        NOTE: the return values are the negative of the value of the current\n","        state. This is done since v is in [-1,1] and if v is the value of a\n","        state for the current player, then its value is -v for the other player.\n","\n","        Returns:\n","            v: the negative of the value of the current canonicalBoard\n","        \"\"\"\n","\n","        s = self.game.stringRepresentation(canonicalBoard)\n","\n","        if s not in self.Es:\n","            self.Es[s] = self.game.getGameEnded(canonicalBoard, 1)\n","        if self.Es[s] != 0:\n","            # terminal node\n","            return -self.Es[s]\n","\n","        if s not in self.Ps:\n","            # leaf node\n","            self.Ps[s], v = predict(canonicalBoard)\n","            valids = self.game.getValidMoves(canonicalBoard, 1)\n","            # print(valids,len(valids),canonicalBoard)\n","            self.Ps[s] = self.Ps[s] * valids  # masking invalid moves\n","            sum_Ps_s = np.sum(self.Ps[s])\n","            if sum_Ps_s > 0:\n","                self.Ps[s] /= sum_Ps_s  # renormalize\n","            else:\n","                # if all valid moves were masked make all valid moves equally probable\n","\n","                # NB! All valid moves may be masked if either your NNet architecture is insufficient or you've get overfitting or something else.\n","                # If you have got dozens or hundreds of these messages you should pay attention to your NNet and/or training process.   \n","                log.error(\"All valid moves were masked, doing a workaround.\")\n","                self.Ps[s] = self.Ps[s] + valids\n","                self.Ps[s] /= np.sum(self.Ps[s])\n","\n","            self.Vs[s] = valids\n","            self.Ns[s] = 0\n","            return -v\n","\n","        valids = self.Vs[s]\n","        cur_best = -float('inf')\n","        best_act = -1\n","\n","        # pick the action with the highest upper confidence bound\n","        for a in range(self.game.getActionSize()):\n","            if valids[a]:\n","                if (s, a) in self.Qsa:\n","                    u = self.Qsa[(s, a)] + self.args.cpuct * self.Ps[s][a] * math.sqrt(self.Ns[s]) / (\n","                            1 + self.Nsa[(s, a)])\n","                else:\n","                    u = self.args.cpuct * self.Ps[s][a] * math.sqrt(self.Ns[s] + EPS)  # Q = 0 ?\n","\n","                if u > cur_best:\n","                    cur_best = u\n","                    best_act = a\n","\n","        a = best_act\n","        next_s, next_player = self.game.getNextState(canonicalBoard, 1, a)\n","        next_s = self.game.getCanonicalForm(next_s, next_player)\n","\n","        v = self.search(next_s)\n","\n","        if (s, a) in self.Qsa:\n","            self.Qsa[(s, a)] = (self.Nsa[(s, a)] * self.Qsa[(s, a)] + v) / (self.Nsa[(s, a)] + 1)\n","            self.Nsa[(s, a)] += 1\n","\n","        else:\n","            self.Qsa[(s, a)] = v\n","            self.Nsa[(s, a)] = 1\n","\n","        self.Ns[s] += 1\n","        return -v"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uS4gv0LJCj_0"},"outputs":[],"source":["import logging\n","import os\n","import sys\n","from collections import deque\n","from pickle import Pickler, Unpickler\n","from random import shuffle\n","\n","import numpy as np\n","from tqdm import tqdm\n","\n","\n","log = logging.getLogger(__name__)\n","\n","\n","class Coach():\n","    \"\"\"\n","    This class executes the self-play + learning. It uses the functions defined\n","    in Game and NeuralNet. args are specified in main.py.\n","    \"\"\"\n","\n","    def __init__(self, game, args):\n","        self.game = game\n","        # self.nnet = nnet\n","        # self.pnet = self.nnet.__class__(self.game)  # the competitor network\n","        self.args = args\n","        self.mcts = MCTS(self.game, self.args)\n","        self.trainExamplesHistory = []  # history of examples from args.numItersForTrainExamplesHistory latest iterations\n","        self.skipFirstSelfPlay = False  # can be overriden in loadTrainExamples()\n","\n","    def executeEpisode(self):\n","        \"\"\"\n","        This function executes one episode of self-play, starting with player 1.\n","        As the game is played, each turn is added as a training example to\n","        trainExamples. The game is played till the game ends. After the game\n","        ends, the outcome of the game is used to assign values to each example\n","        in trainExamples.\n","\n","        It uses a temp=1 if episodeStep < tempThreshold, and thereafter\n","        uses temp=0.\n","\n","        Returns:\n","            trainExamples: a list of examples of the form (canonicalBoard, currPlayer, pi,v)\n","                           pi is the MCTS informed policy vector, v is +1 if\n","                           the player eventually won the game, else -1.\n","        \"\"\"\n","        trainExamples = []\n","        board = self.game.getInitBoard()\n","        self.curPlayer = 1\n","        episodeStep = 0\n","\n","        while True:\n","            episodeStep += 1\n","            canonicalBoard = self.game.getCanonicalForm(board, self.curPlayer)\n","            temp = int(episodeStep < self.args.tempThreshold)\n","\n","            pi = self.mcts.getActionProb(canonicalBoard, temp=temp)\n","            sym = self.game.getSymmetries(canonicalBoard, pi)\n","            for b, p in sym:\n","                trainExamples.append([b, self.curPlayer, p, None])\n","\n","            action = np.random.choice(len(pi), p=pi)\n","            board, self.curPlayer = self.game.getNextState(board, self.curPlayer, action)\n","\n","            r = self.game.getGameEnded(board, self.curPlayer)\n","            result = []\n","\n","            if r != 0:\n","              for x in trainExamples:\n","                if x[1] != self.curPlayer:\n","                  win = 1-r\n","                else:\n","                  win = r\n","                result.append((x[0],x[2],win))\n","              return result\n","\n","    def learn(self):\n","        \"\"\"\n","        Performs numIters iterations with numEps episodes of self-play in each\n","        iteration. After every iteration, it retrains neural network with\n","        examples in trainExamples (which has a maximum length of maxlenofQueue).\n","        It then pits the new neural network against the old one and accepts it\n","        only if it wins >= updateThreshold fraction of games.\n","        \"\"\"\n","\n","        for i in range(1, self.args.numIters + 1):\n","            # bookkeeping\n","            log.info(f'Starting Iter #{i} ...')\n","            # examples of the iteration\n","            if not self.skipFirstSelfPlay or i > 1:\n","                iterationTrainExamples = deque([], maxlen=self.args.maxlenOfQueue)\n","\n","                for _ in tqdm(range(self.args.numEps), desc=\"Self Play\"):\n","                    self.mcts = MCTS(self.game, self.args)  # reset search tree\n","                    iterationTrainExamples += self.executeEpisode()\n","\n","                # save the iteration examples to the history \n","                self.trainExamplesHistory.append(iterationTrainExamples)\n","\n","            if len(self.trainExamplesHistory) > self.args.numItersForTrainExamplesHistory:\n","                log.warning(\n","                    f\"Removing the oldest entry in trainExamples. len(trainExamplesHistory) = {len(self.trainExamplesHistory)}\")\n","                self.trainExamplesHistory.pop(0)\n","            # backup history to a file\n","            # NB! the examples were collected using the model from the previous iteration, so (i-1)  \n","            self.saveTrainExamples(i - 1)\n","\n","            # shuffle examples before training\n","            trainExamples = []\n","            for e in self.trainExamplesHistory:\n","                trainExamples.extend(e)\n","            shuffle(trainExamples)\n","\n","            # # training new network, keeping a copy of the old one\n","            # self.nnet.save_checkpoint(folder=self.args.checkpoint, filename='temp.pth.tar')\n","            # self.pnet.load_checkpoint(folder=self.args.checkpoint, filename='temp.pth.tar')\n","\n","\n","            train(trainExamples)\n","\n","\n","\n","    def getCheckpointFile(self, iteration):\n","        return 'checkpoint_' + str(iteration) + '.pth.tar'\n","\n","    def saveTrainExamples(self, iteration):\n","        folder = self.args.checkpoint\n","        if not os.path.exists(folder):\n","            os.makedirs(folder)\n","        filename = os.path.join(folder, self.getCheckpointFile(iteration) + \".examples\")\n","        with open(filename, \"wb+\") as f:\n","            Pickler(f).dump(self.trainExamplesHistory)\n","        f.closed\n","\n","    def loadTrainExamples(self):\n","        modelFile = os.path.join(self.args.load_folder_file[0], self.args.load_folder_file[1])\n","        examplesFile = modelFile + \".examples\"\n","        if not os.path.isfile(examplesFile):\n","            log.warning(f'File \"{examplesFile}\" with trainExamples not found!')\n","            r = input(\"Continue? [y|n]\")\n","            if r != \"y\":\n","                sys.exit()\n","        else:\n","            log.info(\"File with trainExamples found. Loading it...\")\n","            with open(examplesFile, \"rb\") as f:\n","                self.trainExamplesHistory = Unpickler(f).load()\n","            log.info('Loading done!')\n","\n","            # examples based on the model were already collected (loaded)\n","            self.skipFirstSelfPlay = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sHH3b6Uj8W00"},"outputs":[],"source":["# Run training loop\n","log = logging.getLogger(__name__)\n","\n","\n","args = dotdict({\n","    'numIters': 1000,\n","    'numEps': 1,              # Number of complete self-play games to simulate during a new iteration.\n","    'tempThreshold': 15,        #\n","    'updateThreshold': 0.6,     # During arena playoff, new neural net will be accepted if threshold or more of games are won.\n","    'maxlenOfQueue': 200000,    # Number of game examples to train the neural networks.\n","    'numMCTSSims': 25,          # Number of games moves for MCTS to simulate.\n","    'arenaCompare': 40,         # Number of games to play during arena play to determine if new net will be accepted.\n","    'cpuct': 1,\n","    'epochs': 1,\n","     'lr': 0.001,\n","    'dropout': 0.3,\n","    'batch_size': 1,\n","    'cuda': torch.cuda.is_available(),\n","    'num_channels': 512,\n","\n","    'checkpoint': './temp/',\n","    'load_model': False,\n","    'load_folder_file': ('/dev/models/8x100x50','best.pth.tar'),\n","    'numItersForTrainExamplesHistory': 20,\n","\n","})\n","\n","\n","def main():\n","    log.info('Loading %s...', Game.__name__)\n","    g = Game(3)\n","\n","    # log.info('Loading %s...', nn.__name__)\n","\n","\n","    log.info('Loading the Coach...')\n","    c = Coach(g, args)\n","\n","    if args.load_model:\n","        log.info(\"Loading 'trainExamples' from file...\")\n","        c.loadTrainExamples()\n","\n","    log.info('Starting the learning process 🎉')\n","    c.learn()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FfO2Gv2KgY0M"},"outputs":[],"source":["tokenizer.pad_token = -1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1000714,"status":"error","timestamp":1681510227092,"user":{"displayName":"Jeff Jiang","userId":"05345923776204115994"},"user_tz":240},"id":"6Bp6byv-DGQ6","outputId":"042665d1-685f-4d8e-b35c-e872514f93eb"},"outputs":[{"name":"stderr","output_type":"stream","text":["Self Play: 100%|██████████| 1/1 [03:11<00:00, 191.52s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[(array([[ 1, -1,  1],\n","       [-1, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.2647058823529412, 0.08823529411764706, 0.38235294117647056, 0.2647058823529412], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.08333333333333333, 0.041666666666666664, 0.125, 0.08333333333333333, 0.041666666666666664, 0.25, 0.041666666666666664, 0.08333333333333333, 0.25], 0.999), (array([[-1,  0,  0],\n","       [ 1,  1,  0],\n","       [-1,  0,  0]]), [0.0, 0.29411764705882354, 0.08823529411764706, 0.0, 0.0, 0.23529411764705882, 0.0, 0.14705882352941177, 0.23529411764705882], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.08, 0.04, 0.16, 0.08, 0.0, 0.28, 0.04, 0.08, 0.24], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0, -1]]), [0.13333333333333333, 0.1, 0.03333333333333333, 0.06666666666666667, 0.0, 0.13333333333333333, 0.2, 0.3333333333333333, 0.0], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.08333333333333333, 0.08333333333333333, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.08333333333333333, 0.125, 0.25, 0.25], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.25, 0.08333333333333333, 0.041666666666666664, 0.25, 0.041666666666666664, 0.08333333333333333, 0.125, 0.041666666666666664, 0.08333333333333333], 0.999), (array([[ 0,  0, -1],\n","       [ 0,  1,  1],\n","       [ 0,  0, -1]]), [0.23529411764705882, 0.14705882352941177, 0.0, 0.23529411764705882, 0.0, 0.0, 0.08823529411764706, 0.29411764705882354, 0.0], 0.999), (array([[-1,  1, -1],\n","       [ 1,  1,  0],\n","       [ 0, -1,  0]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.6216216216216216, 0.1891891891891892, 0.0, 0.1891891891891892], 0.999), (array([[ 0, -1,  1],\n","       [ 0, -1, -1],\n","       [ 0,  0,  1]]), [0.08823529411764706, 0.0, 0.0, 0.38235294117647056, 0.0, 0.0, 0.2647058823529412, 0.2647058823529412, 0.0], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.125, 0.041666666666666664, 0.08333333333333333, 0.25, 0.041666666666666664, 0.08333333333333333, 0.25, 0.08333333333333333, 0.041666666666666664], 0.999), (array([[-1,  1, -1],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.14705882352941177, 0.0, 0.29411764705882354, 0.23529411764705882, 0.23529411764705882, 0.08823529411764706], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [-1,  0,  0]]), [0.2, 0.06666666666666667, 0.13333333333333333, 0.3333333333333333, 0.0, 0.1, 0.0, 0.13333333333333333, 0.03333333333333333], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.16, 0.28, 0.24, 0.04, 0.0, 0.08, 0.08, 0.08, 0.04], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0, -1]]), [0.13333333333333333, 0.06666666666666667, 0.2, 0.1, 0.0, 0.3333333333333333, 0.03333333333333333, 0.13333333333333333, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 1, -1,  0]]), [0.058823529411764705, 0.14705882352941177, 0.17647058823529413, 0.20588235294117646, 0.0, 0.11764705882352941, 0.0, 0.0, 0.29411764705882354], 0.001), (array([[ 1,  0,  0],\n","       [-1, -1,  0],\n","       [ 1, -1,  0]]), [0.0, 0.2647058823529412, 0.2647058823529412, 0.0, 0.0, 0.38235294117647056, 0.0, 0.0, 0.08823529411764706], 0.001), (array([[ 0,  0, -1],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.2, 0.3333333333333333, 0.0, 0.06666666666666667, 0.0, 0.13333333333333333, 0.13333333333333333, 0.1, 0.03333333333333333], 0.999), (array([[-1,  0,  0],\n","       [ 1,  1, -1],\n","       [-1,  1,  0]]), [0.0, 0.6216216216216216, 0.1891891891891892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1891891891891892], 0.999), (array([[ 0, -1,  0],\n","       [ 0,  1,  1],\n","       [-1,  1, -1]]), [0.1891891891891892, 0.0, 0.1891891891891892, 0.6216216216216216, 0.0, 0.0, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  0, -1],\n","       [ 0,  1,  1],\n","       [ 0,  0, -1]]), [0.08823529411764706, 0.29411764705882354, 0.0, 0.23529411764705882, 0.0, 0.0, 0.23529411764705882, 0.14705882352941177, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0, -1,  1]]), [0.17647058823529413, 0.14705882352941177, 0.058823529411764705, 0.11764705882352941, 0.0, 0.20588235294117646, 0.29411764705882354, 0.0, 0.0], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.25, 0.25, 0.125, 0.08333333333333333, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.08333333333333333, 0.08333333333333333], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.125, 0.25, 0.25, 0.041666666666666664, 0.041666666666666664, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.041666666666666664], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1, -1],\n","       [ 1, -1,  1]]), [0.2647058823529412, 0.38235294117647056, 0.08823529411764706, 0.2647058823529412, 0.0, 0.0, 0.0, 0.0, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.16, 0.04, 0.08, 0.28, 0.0, 0.08, 0.24, 0.08, 0.04], 0.001), (array([[ 0,  0,  1],\n","       [ 0, -1, -1],\n","       [ 0,  0,  0]]), [0.058823529411764705, 0.20588235294117646, 0.0, 0.14705882352941177, 0.0, 0.0, 0.17647058823529413, 0.11764705882352941, 0.29411764705882354], 0.001), (array([[-1,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.3333333333333333, 0.2, 0.13333333333333333, 0.0, 0.06666666666666667, 0.03333333333333333, 0.1, 0.13333333333333333], 0.999), (array([[ 0, -1,  1],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.29411764705882354, 0.0, 0.0, 0.11764705882352941, 0.0, 0.20588235294117646, 0.17647058823529413, 0.14705882352941177, 0.058823529411764705], 0.001), (array([[ 1,  0,  0],\n","       [-1, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.20588235294117646, 0.058823529411764705, 0.0, 0.0, 0.14705882352941177, 0.29411764705882354, 0.11764705882352941, 0.17647058823529413], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.24, 0.08, 0.04, 0.28, 0.0, 0.08, 0.16, 0.04, 0.08], 0.001), (array([[-1,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.13333333333333333, 0.03333333333333333, 0.3333333333333333, 0.0, 0.1, 0.2, 0.06666666666666667, 0.13333333333333333], 0.999), (array([[-1,  1,  0],\n","       [ 1,  1, -1],\n","       [-1,  0,  0]]), [0.0, 0.0, 0.1891891891891892, 0.0, 0.0, 0.0, 0.0, 0.6216216216216216, 0.1891891891891892], 0.999), (array([[ 0, -1,  0],\n","       [ 1,  1,  0],\n","       [-1,  1, -1]]), [0.1891891891891892, 0.0, 0.1891891891891892, 0.0, 0.0, 0.6216216216216216, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  0, -1],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.03333333333333333, 0.13333333333333333, 0.0, 0.1, 0.0, 0.3333333333333333, 0.13333333333333333, 0.06666666666666667, 0.2], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [-1,  1, -1]]), [0.23529411764705882, 0.23529411764705882, 0.08823529411764706, 0.14705882352941177, 0.0, 0.29411764705882354, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [-1, -1,  0],\n","       [ 1,  0,  0]]), [0.29411764705882354, 0.11764705882352941, 0.17647058823529413, 0.0, 0.0, 0.14705882352941177, 0.0, 0.20588235294117646, 0.058823529411764705], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.041666666666666664, 0.08333333333333333, 0.25, 0.08333333333333333, 0.041666666666666664, 0.25, 0.08333333333333333, 0.041666666666666664, 0.125], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.04, 0.08, 0.08, 0.08, 0.0, 0.04, 0.24, 0.28, 0.16], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [-1,  0,  0]]), [0.03333333333333333, 0.1, 0.13333333333333333, 0.13333333333333333, 0.0, 0.06666666666666667, 0.0, 0.3333333333333333, 0.2], 0.999), (array([[ 1, -1,  1],\n","       [ 0, -1, -1],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.2647058823529412, 0.0, 0.0, 0.2647058823529412, 0.38235294117647056, 0.08823529411764706], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1, -1],\n","       [ 0,  0,  1]]), [0.17647058823529413, 0.11764705882352941, 0.29411764705882354, 0.14705882352941177, 0.0, 0.0, 0.058823529411764705, 0.20588235294117646, 0.0], 0.001), (array([[ 1, -1,  0],\n","       [-1, -1,  0],\n","       [ 1,  0,  0]]), [0.0, 0.0, 0.08823529411764706, 0.0, 0.0, 0.38235294117647056, 0.0, 0.2647058823529412, 0.2647058823529412], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.08, 0.08, 0.04, 0.04, 0.0, 0.08, 0.16, 0.28, 0.24], 0.001), (array([[-1,  1, -1],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.29411764705882354, 0.0, 0.14705882352941177, 0.08823529411764706, 0.23529411764705882, 0.23529411764705882], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.24, 0.28, 0.16, 0.08, 0.0, 0.04, 0.04, 0.08, 0.08], 0.001), (array([[ 1, -1,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.29411764705882354, 0.20588235294117646, 0.0, 0.11764705882352941, 0.058823529411764705, 0.14705882352941177, 0.17647058823529413], 0.001), (array([[ 0,  0, -1],\n","       [-1,  1,  1],\n","       [ 0,  1, -1]]), [0.1891891891891892, 0.6216216216216216, 0.0, 0.0, 0.0, 0.0, 0.1891891891891892, 0.0, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [-1,  1, -1]]), [0.08823529411764706, 0.23529411764705882, 0.23529411764705882, 0.29411764705882354, 0.0, 0.14705882352941177, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.04, 0.08, 0.24, 0.08, 0.0, 0.28, 0.08, 0.04, 0.16], 0.001), (array([[ 0,  1, -1],\n","       [-1,  1,  1],\n","       [ 0,  0, -1]]), [0.1891891891891892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1891891891891892, 0.6216216216216216, 0.0], 0.999), (array([[ 0,  0,  1],\n","       [ 0, -1, -1],\n","       [ 0, -1,  1]]), [0.2647058823529412, 0.2647058823529412, 0.0, 0.38235294117647056, 0.0, 0.0, 0.08823529411764706, 0.0, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [-1, -1,  0],\n","       [ 1, -1,  1]]), [0.08823529411764706, 0.38235294117647056, 0.2647058823529412, 0.0, 0.0, 0.2647058823529412, 0.0, 0.0, 0.0], 0.001), (array([[-1,  0,  0],\n","       [ 1,  1,  0],\n","       [-1,  0,  0]]), [0.0, 0.14705882352941177, 0.23529411764705882, 0.0, 0.0, 0.23529411764705882, 0.0, 0.29411764705882354, 0.08823529411764706], 0.999), (array([[-1,  1, -1],\n","       [ 0,  1,  1],\n","       [ 0, -1,  0]]), [0.0, 0.0, 0.0, 0.6216216216216216, 0.0, 0.0, 0.1891891891891892, 0.0, 0.1891891891891892], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.041666666666666664, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.041666666666666664, 0.041666666666666664, 0.25, 0.25, 0.125], 0.999)] examples\n","EPOCH ::: 1\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   0%|          | 0/56 [00:00<?, ?it/s, Loss_pi=2.26e+00, Loss_v=5.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.1471, 0.0000, 0.2941, 0.2353, 0.2353, 0.0882]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.3889, 0.1224, 0.0815, 0.0616, 0.0404, 0.0247, 0.0257, 0.0269, 0.0417]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.2648], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2616, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.5390, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   2%|▏         | 1/56 [00:01<01:11,  1.30s/it, Loss_pi=2.27e+00, Loss_v=3.02e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0400, 0.0800, 0.0800, 0.0800, 0.0000, 0.0400, 0.2400, 0.2800, 0.1600]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.6729, 0.0552, 0.0312, 0.0223, 0.0117, 0.0066, 0.0068, 0.0087, 0.0343]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.2552], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2714, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.0646, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   4%|▎         | 2/56 [00:02<01:03,  1.17s/it, Loss_pi=2.26e+00, Loss_v=2.18e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0800, 0.0800, 0.0400, 0.0400, 0.0000, 0.0800, 0.1600, 0.2800, 0.2400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.6040, 0.0677, 0.0395, 0.0272, 0.0140, 0.0080, 0.0079, 0.0096, 0.0349]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.2226], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2372, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.0491, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   5%|▌         | 3/56 [00:03<00:57,  1.09s/it, Loss_pi=2.25e+00, Loss_v=1.77e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0882, 0.3824, 0.2647, 0.0000, 0.0000, 0.2647, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.5679, 0.0684, 0.0344, 0.0222, 0.0125, 0.0074, 0.0079, 0.0111, 0.0452]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.2360], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2131, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.0552, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   7%|▋         | 4/56 [00:04<00:55,  1.06s/it, Loss_pi=2.24e+00, Loss_v=1.46e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0882, 0.3824, 0.2647, 0.0000, 0.0000, 0.2647, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.5327, 0.0580, 0.0196, 0.0125, 0.0062, 0.0041, 0.0036, 0.0052, 0.0236]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.1421], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2115, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.0199, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   9%|▉         | 5/56 [00:06<00:52,  1.04s/it, Loss_pi=2.23e+00, Loss_v=2.43e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1250, 0.2500, 0.2500, 0.0417, 0.0417, 0.0833, 0.0833, 0.0833, 0.0417]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.4937, 0.0652, 0.0201, 0.0119, 0.0063, 0.0040, 0.0038, 0.0055, 0.0191]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.1436], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1942, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.7318, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  11%|█         | 6/56 [00:07<00:51,  1.03s/it, Loss_pi=2.23e+00, Loss_v=3.06e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1333, 0.1000, 0.0333, 0.0667, 0.0000, 0.1333, 0.2000, 0.3333, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.4700, 0.0798, 0.0273, 0.0182, 0.0084, 0.0066, 0.0059, 0.0087, 0.0282]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.1733], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2033, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.6817, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  12%|█▎        | 7/56 [00:08<00:50,  1.03s/it, Loss_pi=2.23e+00, Loss_v=3.24e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6216, 0.1892, 0.0000, 0.1892]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.1418, 0.1711, 0.1407, 0.1149, 0.0686, 0.0551, 0.0461, 0.0479, 0.0494]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.3270], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2389, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.4516, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  14%|█▍        | 8/56 [00:09<00:49,  1.02s/it, Loss_pi=2.23e+00, Loss_v=3.34e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1333, 0.1000, 0.0333, 0.0667, 0.0000, 0.1333, 0.2000, 0.3333, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.3293, 0.1682, 0.0853, 0.0577, 0.0342, 0.0264, 0.0258, 0.0370, 0.0758]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.3541], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2068, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.4159, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  16%|█▌        | 9/56 [00:10<00:47,  1.02s/it, Loss_pi=2.22e+00, Loss_v=3.13e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1600, 0.2800, 0.2400, 0.0400, 0.0000, 0.0800, 0.0800, 0.0800, 0.0400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.3101, 0.1465, 0.0991, 0.0703, 0.0450, 0.0397, 0.0416, 0.0543, 0.0797]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.3421], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1676, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1163, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  18%|█▊        | 10/56 [00:11<00:46,  1.02s/it, Loss_pi=2.21e+00, Loss_v=3.21e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2353, 0.2353, 0.0882, 0.1471, 0.0000, 0.2941, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.3110, 0.1447, 0.0934, 0.0540, 0.0315, 0.0278, 0.0289, 0.0421, 0.0733]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.3621], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1594, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.4057, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  20%|█▉        | 11/56 [00:12<00:45,  1.02s/it, Loss_pi=2.21e+00, Loss_v=3.10e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1765, 0.1176, 0.2941, 0.1471, 0.0000, 0.0000, 0.0588, 0.2059, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0801, 0.2045, 0.1920, 0.1103, 0.0669, 0.0638, 0.0563, 0.0559, 0.0563]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4310], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1719, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1849, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  21%|██▏       | 12/56 [00:13<00:45,  1.03s/it, Loss_pi=2.21e+00, Loss_v=3.12e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0833, 0.0833, 0.0417, 0.0417, 0.0417, 0.0833, 0.1250, 0.2500, 0.2500]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0475, 0.1881, 0.2098, 0.1398, 0.0822, 0.0834, 0.0640, 0.0630, 0.0514]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4202], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2205, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3350, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  23%|██▎       | 13/56 [00:14<00:44,  1.02s/it, Loss_pi=2.21e+00, Loss_v=3.11e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6216, 0.1892, 0.0000, 0.1892]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0402, 0.1890, 0.2075, 0.1404, 0.0757, 0.0819, 0.0658, 0.0668, 0.0554]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4488], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2272, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3027, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  25%|██▌       | 14/56 [00:15<00:42,  1.02s/it, Loss_pi=2.21e+00, Loss_v=3.05e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0400, 0.0800, 0.0800, 0.0800, 0.0000, 0.0400, 0.2400, 0.2800, 0.1600]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0385, 0.1921, 0.2144, 0.1362, 0.0718, 0.0840, 0.0654, 0.0696, 0.0564]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4686], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2095, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2187, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  27%|██▋       | 15/56 [00:16<00:41,  1.02s/it, Loss_pi=2.21e+00, Loss_v=3.05e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0882, 0.2353, 0.2353, 0.2941, 0.0000, 0.1471, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0371, 0.2008, 0.2206, 0.1447, 0.0775, 0.0891, 0.0705, 0.0673, 0.0516]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4493], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1478, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3022, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  29%|██▊       | 16/56 [00:17<00:40,  1.01s/it, Loss_pi=2.21e+00, Loss_v=3.10e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1250, 0.2500, 0.2500, 0.0417, 0.0417, 0.0833, 0.0833, 0.0833, 0.0417]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0957, 0.1517, 0.1517, 0.1627, 0.0333, 0.0285, 0.0238, 0.0316, 0.0580]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.3637], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1755, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.4036, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  30%|███       | 17/56 [00:18<00:39,  1.01s/it, Loss_pi=2.20e+00, Loss_v=3.17e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.6216, 0.1892, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1892]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0767, 0.2135, 0.2202, 0.1116, 0.0303, 0.0327, 0.0259, 0.0307, 0.0499]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.3474], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1041, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.4245, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  32%|███▏      | 18/56 [00:19<00:38,  1.01s/it, Loss_pi=2.20e+00, Loss_v=3.15e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2353, 0.2353, 0.0882, 0.1471, 0.0000, 0.2941, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0493, 0.2224, 0.2600, 0.1437, 0.0405, 0.0504, 0.0405, 0.0431, 0.0576]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4622], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1787, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2881, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  34%|███▍      | 19/56 [00:20<00:37,  1.01s/it, Loss_pi=2.20e+00, Loss_v=3.12e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1333, 0.1000, 0.0333, 0.0667, 0.0000, 0.1333, 0.2000, 0.3333, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0341, 0.2227, 0.2603, 0.1460, 0.0446, 0.0695, 0.0541, 0.0559, 0.0541]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5063], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2213, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2428, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  36%|███▌      | 20/56 [00:21<00:36,  1.01s/it, Loss_pi=2.20e+00, Loss_v=3.07e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6216, 0.1892, 0.0000, 0.1892]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0226, 0.2014, 0.2391, 0.1593, 0.0486, 0.0966, 0.0753, 0.0707, 0.0551]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5268], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2228, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2230, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  38%|███▊      | 21/56 [00:22<00:35,  1.01s/it, Loss_pi=2.20e+00, Loss_v=3.03e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.1333, 0.0333, 0.3333, 0.0000, 0.1000, 0.2000, 0.0667, 0.1333]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0224, 0.2042, 0.2208, 0.1448, 0.0449, 0.1043, 0.0800, 0.0763, 0.0728]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5428], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1829, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2081, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  39%|███▉      | 22/56 [00:23<00:34,  1.01s/it, Loss_pi=2.20e+00, Loss_v=2.97e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2500, 0.2500, 0.1250, 0.0833, 0.0417, 0.0417, 0.0417, 0.0833, 0.0833]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0149, 0.1658, 0.1969, 0.1487, 0.0461, 0.1213, 0.1006, 0.1006, 0.0783]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5793], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1983, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1762, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  41%|████      | 23/56 [00:24<00:33,  1.01s/it, Loss_pi=2.20e+00, Loss_v=2.94e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2353, 0.2353, 0.0882, 0.1471, 0.0000, 0.2941, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0228, 0.2249, 0.2000, 0.1271, 0.0295, 0.0814, 0.0681, 0.0713, 0.0938]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5376], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1831, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2129, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  43%|████▎     | 24/56 [00:25<00:32,  1.01s/it, Loss_pi=2.20e+00, Loss_v=2.90e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0833, 0.0417, 0.1250, 0.0833, 0.0417, 0.2500, 0.0417, 0.0833, 0.2500]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0146, 0.1854, 0.1812, 0.1501, 0.0305, 0.1032, 0.0842, 0.0883, 0.1024]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5698], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1956, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1842, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  45%|████▍     | 25/56 [00:26<00:31,  1.01s/it, Loss_pi=2.20e+00, Loss_v=2.93e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0882, 0.3824, 0.2647, 0.0000, 0.0000, 0.2647, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0070, 0.1595, 0.1453, 0.1262, 0.0297, 0.1545, 0.1223, 0.1185, 0.1079]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6161], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1651, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3783, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  46%|████▋     | 26/56 [00:27<00:30,  1.01s/it, Loss_pi=2.20e+00, Loss_v=2.87e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2000, 0.0667, 0.1333, 0.3333, 0.0000, 0.1000, 0.0000, 0.1333, 0.0333]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0041, 0.1409, 0.1262, 0.1132, 0.0277, 0.1809, 0.1409, 0.1323, 0.1168]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6450], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2038, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1253, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  48%|████▊     | 27/56 [00:28<00:29,  1.02s/it, Loss_pi=2.20e+00, Loss_v=2.81e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0833, 0.0833, 0.0417, 0.0417, 0.0417, 0.0833, 0.1250, 0.2500, 0.2500]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0027, 0.1283, 0.1132, 0.1047, 0.0234, 0.2114, 0.1409, 0.1344, 0.1224]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6476], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1877, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1235, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  50%|█████     | 28/56 [00:29<00:28,  1.02s/it, Loss_pi=2.20e+00, Loss_v=2.86e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0882, 0.0000, 0.0000, 0.3824, 0.0000, 0.2647, 0.2647]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0014, 0.1353, 0.1053, 0.0974, 0.0190, 0.2030, 0.1373, 0.1353, 0.1417]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6555], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1468, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.4283, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  52%|█████▏    | 29/56 [00:30<00:27,  1.01s/it, Loss_pi=2.20e+00, Loss_v=2.91e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2647, 0.3824, 0.0882, 0.2647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0007, 0.1357, 0.1008, 0.0918, 0.0155, 0.2168, 0.1315, 0.1422, 0.1444]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6629], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2225, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.4381, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  54%|█████▎    | 30/56 [00:31<00:26,  1.01s/it, Loss_pi=2.20e+00, Loss_v=2.96e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.2647, 0.0000, 0.0000, 0.2647, 0.3824, 0.0882]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0004, 0.1346, 0.0955, 0.0940, 0.0156, 0.2439, 0.1326, 0.1346, 0.1305]],\n","       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6577], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1855, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.4313, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  55%|█████▌    | 31/56 [00:32<00:25,  1.01s/it, Loss_pi=2.20e+00, Loss_v=2.90e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.1471, 0.0000, 0.2941, 0.2353, 0.2353, 0.0882]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.0027e-04, 1.3428e-01, 8.9478e-02, 9.6741e-02, 1.3611e-02, 2.5488e-01,\n","         1.2421e-01, 1.3635e-01, 1.3220e-01]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6611], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1470, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1141, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  57%|█████▋    | 32/56 [00:33<00:24,  1.01s/it, Loss_pi=2.19e+00, Loss_v=2.94e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0882, 0.3824, 0.2647, 0.0000, 0.0000, 0.2647, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1116e-04, 1.3074e-01, 8.5754e-02, 9.7168e-02, 1.1879e-02, 2.7686e-01,\n","         1.2286e-01, 1.3916e-01, 1.2097e-01]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6513], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1642, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.4229, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  59%|█████▉    | 33/56 [00:34<00:23,  1.01s/it, Loss_pi=2.19e+00, Loss_v=2.98e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.2647, 0.0000, 0.0000, 0.2647, 0.3824, 0.0882]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[4.0174e-05, 1.1432e-01, 7.2083e-02, 9.7778e-02, 1.0803e-02, 3.0127e-01,\n","         1.2170e-01, 1.4453e-01, 1.2170e-01]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6474], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1860, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.4178, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  61%|██████    | 34/56 [00:35<00:22,  1.01s/it, Loss_pi=2.19e+00, Loss_v=3.01e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1765, 0.1471, 0.0588, 0.1176, 0.0000, 0.2059, 0.2941, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.8610e-05, 1.2903e-01, 7.3486e-02, 1.0205e-01, 9.4910e-03, 2.9980e-01,\n","         1.1383e-01, 1.3098e-01, 1.2695e-01]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6352], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1800, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.4022, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  62%|██████▎   | 35/56 [00:36<00:22,  1.07s/it, Loss_pi=2.19e+00, Loss_v=3.03e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0882, 0.3824, 0.2647, 0.0000, 0.0000, 0.2647, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.4126e-05, 1.4661e-01, 7.5439e-02, 1.1328e-01, 8.6670e-03, 2.9370e-01,\n","         9.5337e-02, 1.1505e-01, 1.2939e-01]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6194], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1554, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3824, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  64%|██████▍   | 36/56 [00:37<00:20,  1.05s/it, Loss_pi=2.19e+00, Loss_v=2.99e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2000, 0.3333, 0.0000, 0.0667, 0.0000, 0.1333, 0.1333, 0.1000, 0.0333]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[7.0930e-06, 1.3196e-01, 6.7932e-02, 1.1829e-01, 7.9880e-03, 3.2642e-01,\n","         9.8816e-02, 1.1554e-01, 1.1639e-01]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6204], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1861, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1434, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  66%|██████▌   | 37/56 [00:38<00:19,  1.04s/it, Loss_pi=2.19e+00, Loss_v=2.95e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.2941, 0.0000, 0.1471, 0.0882, 0.2353, 0.2353]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[4.2319e-06, 1.4124e-01, 7.0496e-02, 1.2659e-01, 6.9771e-03, 3.6084e-01,\n","         9.1187e-02, 1.0016e-01, 8.6365e-02]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5940], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1693, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1640, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  68%|██████▊   | 38/56 [00:39<00:18,  1.02s/it, Loss_pi=2.19e+00, Loss_v=2.96e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.2647, 0.2647, 0.0000, 0.0000, 0.3824, 0.0000, 0.0000, 0.0882]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.5034e-06, 1.6821e-01, 7.1777e-02, 1.1926e-01, 5.4474e-03, 3.7915e-01,\n","         7.9468e-02, 8.7280e-02, 7.5195e-02]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5944], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0975, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3521, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  70%|██████▉   | 39/56 [00:40<00:17,  1.02s/it, Loss_pi=2.19e+00, Loss_v=2.93e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1250, 0.0417, 0.0833, 0.2500, 0.0417, 0.0833, 0.2500, 0.0833, 0.0417]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.2650e-06, 1.3843e-01, 6.1432e-02, 1.5088e-01, 5.2452e-03, 3.9746e-01,\n","         7.3547e-02, 7.8308e-02, 7.5867e-02]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5822], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2031, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1738, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  71%|███████▏  | 40/56 [00:41<00:16,  1.02s/it, Loss_pi=2.19e+00, Loss_v=2.95e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2941, 0.1176, 0.1765, 0.0000, 0.0000, 0.1471, 0.0000, 0.2059, 0.0588]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.0133e-06, 1.4331e-01, 5.7465e-02, 1.2067e-01, 3.7594e-03, 4.7729e-01,\n","         6.8787e-02, 6.8787e-02, 4.8004e-02]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5854], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2027, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3415, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  73%|███████▎  | 41/56 [00:42<00:15,  1.01s/it, Loss_pi=2.19e+00, Loss_v=2.92e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1333, 0.0667, 0.2000, 0.1000, 0.0000, 0.3333, 0.0333, 0.1333, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[6.5565e-07, 1.5186e-01, 5.3314e-02, 1.1115e-01, 2.7828e-03, 5.0586e-01,\n","         6.1371e-02, 6.3354e-02, 4.0253e-02]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5873], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1082, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1695, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  75%|███████▌  | 42/56 [00:43<00:14,  1.01s/it, Loss_pi=2.19e+00, Loss_v=2.93e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2400, 0.0800, 0.0400, 0.2800, 0.0000, 0.0800, 0.1600, 0.0400, 0.0800]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[4.1723e-07, 1.2781e-01, 5.1636e-02, 1.1633e-01, 2.4910e-03, 5.4639e-01,\n","         5.6702e-02, 5.8502e-02, 3.3325e-02]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5847], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2192, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3407, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  77%|███████▋  | 43/56 [00:44<00:13,  1.01s/it, Loss_pi=2.19e+00, Loss_v=2.94e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0882, 0.0000, 0.0000, 0.3824, 0.0000, 0.0000, 0.2647, 0.2647, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.9802e-07, 1.2671e-01, 4.6600e-02, 1.1536e-01, 2.2316e-03, 5.7666e-01,\n","         5.2002e-02, 4.8096e-02, 2.4948e-02]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5770], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2533, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3317, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  79%|███████▊  | 44/56 [00:45<00:12,  1.01s/it, Loss_pi=2.19e+00, Loss_v=2.94e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0400, 0.0800, 0.2400, 0.0800, 0.0000, 0.2800, 0.0800, 0.0400, 0.1600]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.3842e-07, 1.3098e-01, 5.1300e-02, 1.3513e-01, 1.9121e-03, 5.6006e-01,\n","         4.7058e-02, 4.4556e-02, 2.1378e-02]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5729], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1232, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3271, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  80%|████████  | 45/56 [00:46<00:11,  1.00s/it, Loss_pi=2.19e+00, Loss_v=2.92e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0333, 0.1333, 0.0000, 0.1000, 0.0000, 0.3333, 0.1333, 0.0667, 0.2000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.3842e-07, 1.7273e-01, 5.5206e-02, 1.3245e-01, 1.5545e-03, 5.4053e-01,\n","         3.9764e-02, 3.5095e-02, 1.6190e-02]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5686], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0951, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1852, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  82%|████████▏ | 46/56 [00:47<00:10,  1.00s/it, Loss_pi=2.19e+00, Loss_v=2.92e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1600, 0.2800, 0.2400, 0.0400, 0.0000, 0.0800, 0.0800, 0.0800, 0.0400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 1.4978e-01, 5.3406e-02, 1.5454e-01, 1.3800e-03, 5.4785e-01,\n","         3.6713e-02, 3.3173e-02, 1.4153e-02]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5559], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2113, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3079, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  84%|████████▍ | 47/56 [00:48<00:09,  1.02s/it, Loss_pi=2.18e+00, Loss_v=2.91e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1892, 0.0000, 0.1892, 0.0000, 0.0000, 0.6216, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 1.9324e-01, 5.8472e-02, 1.6272e-01, 1.2712e-03, 5.0098e-01,\n","         3.1525e-02, 2.7191e-02, 1.2947e-02]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5368], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(1.9978, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2136, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  86%|████████▌ | 48/56 [00:49<00:08,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.89e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2000, 0.0667, 0.1333, 0.3333, 0.0000, 0.1000, 0.0000, 0.1333, 0.0333]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 1.6541e-01, 5.2887e-02, 1.4148e-01, 1.0471e-03, 5.6836e-01,\n","         3.0136e-02, 2.4399e-02, 8.5678e-03]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5570], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1981, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1953, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  88%|████████▊ | 49/56 [00:50<00:07,  1.01s/it, Loss_pi=2.19e+00, Loss_v=2.87e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2500, 0.2500, 0.1250, 0.0833, 0.0417, 0.0417, 0.0417, 0.0833, 0.0833]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.2549e-01, 4.7607e-02, 1.4001e-01, 9.3555e-04, 6.2744e-01,\n","         2.7557e-02, 2.0477e-02, 5.1765e-03]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5574], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2499, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1950, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  89%|████████▉ | 50/56 [00:51<00:06,  1.01s/it, Loss_pi=2.19e+00, Loss_v=2.87e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2647, 0.3824, 0.0882, 0.2647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.3574e-01, 4.6936e-02, 1.2366e-01, 8.0729e-04, 6.4795e-01,\n","         2.3590e-02, 1.5472e-02, 2.2812e-03]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5580], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2418, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3103, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  91%|█████████ | 51/56 [00:52<00:05,  1.01s/it, Loss_pi=2.19e+00, Loss_v=2.88e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1600, 0.2800, 0.2400, 0.0400, 0.0000, 0.0800, 0.0800, 0.0800, 0.0400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.5198e-01, 5.5023e-02, 1.3831e-01, 7.1478e-04, 6.1035e-01,\n","         2.1225e-02, 1.5762e-02, 1.8396e-03]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5550], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2142, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3069, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  93%|█████████▎| 52/56 [00:53<00:04,  1.01s/it, Loss_pi=2.19e+00, Loss_v=2.86e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2000, 0.3333, 0.0000, 0.0667, 0.0000, 0.1333, 0.1333, 0.1000, 0.0333]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.6089e-01, 5.6488e-02, 1.4648e-01, 6.2752e-04, 5.9814e-01,\n","         1.8631e-02, 1.2802e-02, 9.6464e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5532], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1798, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1988, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  95%|█████████▍| 53/56 [00:54<00:03,  1.01s/it, Loss_pi=2.19e+00, Loss_v=2.85e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.6216, 0.0000, 0.0000, 0.1892, 0.0000, 0.1892]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.6882e-01, 5.8319e-02, 1.4893e-01, 5.5408e-04, 5.8887e-01,\n","         1.7517e-02, 1.1940e-02, 4.1175e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5465], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2306, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2047, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  96%|█████████▋| 54/56 [00:55<00:02,  1.01s/it, Loss_pi=2.19e+00, Loss_v=2.83e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.6216, 0.0000, 0.0000, 0.1892, 0.0000, 0.1892]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.8909e-01, 6.0425e-02, 1.6956e-01, 5.2309e-04, 5.4736e-01,\n","         1.6388e-02, 1.1093e-02, 2.1458e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5375], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2153, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2130, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  98%|█████████▊| 55/56 [00:56<00:01,  1.01s/it, Loss_pi=2.19e+00, Loss_v=2.82e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.2941, 0.0882, 0.0000, 0.0000, 0.2353, 0.0000, 0.1471, 0.2353]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.2461e-01, 6.6406e-02, 2.0764e-01, 5.0306e-04, 4.6802e-01,\n","         1.5160e-02, 9.5596e-03, 1.1945e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5231], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1367, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2265, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net: 100%|██████████| 56/56 [00:57<00:00,  1.02s/it, Loss_pi=2.19e+00, Loss_v=2.82e-01]\n","Self Play: 100%|██████████| 1/1 [02:31<00:00, 151.87s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[(array([[ 0, -1, -1],\n","       [ 0,  1,  1],\n","       [ 0,  0,  0]]), [0.12121212121212122, 0.0, 0.0, 0.21212121212121213, 0.0, 0.0, 0.12121212121212122, 0.5454545454545454, 0.0], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.0, 0.375, 0.25, 0.16666666666666666, 0.041666666666666664, 0.08333333333333333, 0.041666666666666664, 0.041666666666666664, 0.0], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.041666666666666664, 0.041666666666666664, 0.0, 0.16666666666666666, 0.041666666666666664, 0.08333333333333333, 0.0, 0.375, 0.25], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.04, 0.08, 0.24, 0.04, 0.0, 0.4, 0.04, 0.16, 0.0], 0.999), (array([[ 1, -1,  1],\n","       [-1, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.2647058823529412, 0.08823529411764706, 0.38235294117647056, 0.2647058823529412], 0.001), (array([[ 0, -1,  1],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.425, 0.0, 0.225, 0.1, 0.15, 0.1], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.041666666666666664, 0.16666666666666666, 0.0, 0.041666666666666664, 0.041666666666666664, 0.375, 0.0, 0.08333333333333333, 0.25], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1, -1],\n","       [ 0,  1, -1]]), [0.12121212121212122, 0.21212121212121213, 0.12121212121212122, 0.5454545454545454, 0.0, 0.0, 0.0, 0.0, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 1,  1,  0],\n","       [-1, -1,  0]]), [0.0, 0.5454545454545454, 0.12121212121212122, 0.0, 0.0, 0.21212121212121213, 0.0, 0.0, 0.12121212121212122], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 1, -1,  0]]), [0.058823529411764705, 0.14705882352941177, 0.17647058823529413, 0.20588235294117646, 0.0, 0.11764705882352941, 0.0, 0.0, 0.29411764705882354], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  1],\n","       [ 0, -1, -1]]), [0.12121212121212122, 0.5454545454545454, 0.0, 0.21212121212121213, 0.0, 0.0, 0.12121212121212122, 0.0, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [-1,  1, -1]]), [0.08823529411764706, 0.23529411764705882, 0.23529411764705882, 0.29411764705882354, 0.0, 0.14705882352941177, 0.0, 0.0, 0.0], 0.999), (array([[-1,  1, -1],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.14705882352941177, 0.0, 0.29411764705882354, 0.23529411764705882, 0.23529411764705882, 0.08823529411764706], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.4, 0.24, 0.16, 0.0, 0.08, 0.04, 0.04, 0.04], 0.999), (array([[-1,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.13333333333333333, 0.03333333333333333, 0.3333333333333333, 0.0, 0.1, 0.2, 0.06666666666666667, 0.13333333333333333], 0.999), (array([[ 0,  1, -1],\n","       [ 0,  1, -1],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.5454545454545454, 0.0, 0.0, 0.12121212121212122, 0.21212121212121213, 0.12121212121212122], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [-1,  0,  0]]), [0.03333333333333333, 0.1, 0.13333333333333333, 0.13333333333333333, 0.0, 0.06666666666666667, 0.0, 0.3333333333333333, 0.2], 0.999), (array([[-1,  0,  0],\n","       [ 1,  1, -1],\n","       [-1,  1,  0]]), [0.0, 0.6216216216216216, 0.1891891891891892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1891891891891892], 0.999), (array([[ 0,  0, -1],\n","       [-1,  1,  1],\n","       [ 0,  1, -1]]), [0.1891891891891892, 0.6216216216216216, 0.0, 0.0, 0.0, 0.0, 0.1891891891891892, 0.0, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.04, 0.04, 0.04, 0.08, 0.0, 0.16, 0.24, 0.4, 0.0], 0.999), (array([[ 0, -1,  0],\n","       [ 0, -1, -1],\n","       [ 0,  1,  1]]), [0.30952380952380953, 0.0, 0.0, 0.42857142857142855, 0.0, 0.0, 0.2619047619047619, 0.0, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0, -1]]), [0.03333333333333333, 0.23333333333333334, 0.0, 0.06666666666666667, 0.0, 0.5333333333333333, 0.03333333333333333, 0.1, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [-1,  1,  0],\n","       [-1,  1,  0]]), [0.12121212121212122, 0.21212121212121213, 0.12121212121212122, 0.0, 0.0, 0.5454545454545454, 0.0, 0.0, 0.0], 0.001), (array([[-1,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.5333333333333333, 0.0, 0.1, 0.0, 0.23333333333333334, 0.03333333333333333, 0.06666666666666667, 0.03333333333333333], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.04, 0.08, 0.08, 0.08, 0.0, 0.04, 0.24, 0.28, 0.16], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [-1,  0,  0]]), [0.0, 0.23333333333333334, 0.03333333333333333, 0.5333333333333333, 0.0, 0.06666666666666667, 0.0, 0.1, 0.03333333333333333], 0.001), (array([[ 0,  0,  0],\n","       [-1, -1,  0],\n","       [ 1,  0,  0]]), [0.29411764705882354, 0.11764705882352941, 0.17647058823529413, 0.0, 0.0, 0.14705882352941177, 0.0, 0.20588235294117646, 0.058823529411764705], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.08, 0.04, 0.16, 0.08, 0.0, 0.28, 0.04, 0.08, 0.24], 0.001), (array([[ 1, -1,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.225, 0.0, 0.425, 0.1, 0.15, 0.1], 0.999), (array([[ 1, -1,  0],\n","       [ 1, -1, -1],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2619047619047619, 0.42857142857142855, 0.30952380952380953], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [-1,  0,  0]]), [0.03333333333333333, 0.06666666666666667, 0.03333333333333333, 0.1, 0.0, 0.23333333333333334, 0.0, 0.5333333333333333, 0.0], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.25, 0.08333333333333333, 0.041666666666666664, 0.25, 0.041666666666666664, 0.08333333333333333, 0.125, 0.041666666666666664, 0.08333333333333333], 0.999), (array([[ 0,  0,  1],\n","       [ 0, -1, -1],\n","       [ 0,  0,  0]]), [0.058823529411764705, 0.20588235294117646, 0.0, 0.14705882352941177, 0.0, 0.0, 0.17647058823529413, 0.11764705882352941, 0.29411764705882354], 0.001), (array([[ 0,  0, -1],\n","       [ 0,  1,  1],\n","       [ 0,  0, -1]]), [0.08823529411764706, 0.29411764705882354, 0.0, 0.23529411764705882, 0.0, 0.0, 0.23529411764705882, 0.14705882352941177, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [-1, -1,  0],\n","       [ 1, -1,  1]]), [0.08823529411764706, 0.38235294117647056, 0.2647058823529412, 0.0, 0.0, 0.2647058823529412, 0.0, 0.0, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.24, 0.28, 0.16, 0.08, 0.0, 0.04, 0.04, 0.08, 0.08], 0.001), (array([[ 0,  0,  1],\n","       [ 0, -1, -1],\n","       [ 0,  0,  0]]), [0.1, 0.225, 0.0, 0.15, 0.0, 0.0, 0.1, 0.425, 0.0], 0.999), (array([[ 0, -1,  1],\n","       [ 0, -1, -1],\n","       [ 0,  0,  1]]), [0.08823529411764706, 0.0, 0.0, 0.38235294117647056, 0.0, 0.0, 0.2647058823529412, 0.2647058823529412, 0.0], 0.001), (array([[ 0, -1,  0],\n","       [ 0,  1,  1],\n","       [-1,  1, -1]]), [0.1891891891891892, 0.0, 0.1891891891891892, 0.6216216216216216, 0.0, 0.0, 0.0, 0.0, 0.0], 0.999), (array([[-1,  1,  0],\n","       [ 1,  1, -1],\n","       [-1,  0,  0]]), [0.0, 0.0, 0.1891891891891892, 0.0, 0.0, 0.0, 0.0, 0.6216216216216216, 0.1891891891891892], 0.999), (array([[ 1, -1,  0],\n","       [-1, -1,  0],\n","       [ 1,  0,  0]]), [0.0, 0.0, 0.08823529411764706, 0.0, 0.0, 0.38235294117647056, 0.0, 0.2647058823529412, 0.2647058823529412], 0.001), (array([[ 0, -1,  1],\n","       [-1, -1,  1],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30952380952380953, 0.42857142857142855, 0.2619047619047619], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.16, 0.04, 0.4, 0.0, 0.04, 0.24, 0.08, 0.04], 0.999), (array([[-1,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.3333333333333333, 0.2, 0.13333333333333333, 0.0, 0.06666666666666667, 0.03333333333333333, 0.1, 0.13333333333333333], 0.999), (array([[ 0,  0,  0],\n","       [-1, -1,  1],\n","       [ 0, -1,  1]]), [0.30952380952380953, 0.42857142857142855, 0.2619047619047619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.125, 0.041666666666666664, 0.08333333333333333, 0.25, 0.041666666666666664, 0.08333333333333333, 0.25, 0.08333333333333333, 0.041666666666666664], 0.999), (array([[ 0,  0,  0],\n","       [ 1, -1, -1],\n","       [ 1, -1,  0]]), [0.2619047619047619, 0.42857142857142855, 0.30952380952380953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  0,  1],\n","       [ 0, -1, -1],\n","       [ 0, -1,  1]]), [0.2647058823529412, 0.2647058823529412, 0.0, 0.38235294117647056, 0.0, 0.0, 0.08823529411764706, 0.0, 0.0], 0.001), (array([[-1,  0,  0],\n","       [ 1,  1,  0],\n","       [-1,  0,  0]]), [0.0, 0.29411764705882354, 0.08823529411764706, 0.0, 0.0, 0.23529411764705882, 0.0, 0.14705882352941177, 0.23529411764705882], 0.999), (array([[ 0,  1,  1],\n","       [ 0, -1, -1],\n","       [ 0, -1,  0]]), [0.2619047619047619, 0.0, 0.0, 0.42857142857142855, 0.0, 0.0, 0.30952380952380953, 0.0, 0.0], 0.999), (array([[ 1,  1,  0],\n","       [-1, -1,  0],\n","       [ 0, -1,  0]]), [0.0, 0.0, 0.2619047619047619, 0.0, 0.0, 0.42857142857142855, 0.0, 0.0, 0.30952380952380953], 0.999), (array([[-1,  1, -1],\n","       [ 0,  1,  1],\n","       [ 0, -1,  0]]), [0.0, 0.0, 0.0, 0.6216216216216216, 0.0, 0.0, 0.1891891891891892, 0.0, 0.1891891891891892], 0.999), (array([[ 1, -1,  1],\n","       [ 0, -1, -1],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.2647058823529412, 0.0, 0.0, 0.2647058823529412, 0.38235294117647056, 0.08823529411764706], 0.001), (array([[-1,  1, -1],\n","       [ 1,  1,  0],\n","       [ 0, -1,  0]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.6216216216216216, 0.1891891891891892, 0.0, 0.1891891891891892], 0.999), (array([[ 1,  0,  0],\n","       [-1, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.20588235294117646, 0.058823529411764705, 0.0, 0.0, 0.14705882352941177, 0.29411764705882354, 0.11764705882352941, 0.17647058823529413], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.08333333333333333, 0.041666666666666664, 0.125, 0.08333333333333333, 0.041666666666666664, 0.25, 0.041666666666666664, 0.08333333333333333, 0.25], 0.999), (array([[ 1, -1,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.29411764705882354, 0.20588235294117646, 0.0, 0.11764705882352941, 0.058823529411764705, 0.14705882352941177, 0.17647058823529413], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0, -1]]), [0.13333333333333333, 0.1, 0.03333333333333333, 0.06666666666666667, 0.0, 0.13333333333333333, 0.2, 0.3333333333333333, 0.0], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.25, 0.08333333333333333, 0.0, 0.375, 0.041666666666666664, 0.041666666666666664, 0.0, 0.16666666666666666, 0.041666666666666664], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.24, 0.08, 0.04, 0.4, 0.0, 0.04, 0.0, 0.16, 0.04], 0.999), (array([[-1,  0,  0],\n","       [ 1,  1,  0],\n","       [-1,  0,  0]]), [0.0, 0.14705882352941177, 0.23529411764705882, 0.0, 0.0, 0.23529411764705882, 0.0, 0.29411764705882354, 0.08823529411764706], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.04, 0.08, 0.24, 0.08, 0.0, 0.28, 0.08, 0.04, 0.16], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.08333333333333333, 0.08333333333333333, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.08333333333333333, 0.125, 0.25, 0.25], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.24, 0.4, 0.0, 0.08, 0.0, 0.16, 0.04, 0.04, 0.04], 0.999), (array([[ 1,  0,  0],\n","       [-1, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.225, 0.1, 0.0, 0.0, 0.15, 0.0, 0.425, 0.1], 0.999), (array([[-1, -1,  0],\n","       [ 1,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.12121212121212122, 0.0, 0.0, 0.21212121212121213, 0.0, 0.5454545454545454, 0.12121212121212122], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.041666666666666664, 0.08333333333333333, 0.25, 0.08333333333333333, 0.041666666666666664, 0.25, 0.08333333333333333, 0.041666666666666664, 0.125], 0.999), (array([[ 0, -1,  1],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.29411764705882354, 0.0, 0.0, 0.11764705882352941, 0.0, 0.20588235294117646, 0.17647058823529413, 0.14705882352941177, 0.058823529411764705], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0, -1]]), [0.03333333333333333, 0.06666666666666667, 0.03333333333333333, 0.23333333333333334, 0.0, 0.1, 0.0, 0.5333333333333333, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.04, 0.16, 0.0, 0.04, 0.0, 0.4, 0.04, 0.08, 0.24], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1, -1],\n","       [ 1, -1,  1]]), [0.2647058823529412, 0.38235294117647056, 0.08823529411764706, 0.2647058823529412, 0.0, 0.0, 0.0, 0.0, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [-1, -1,  0],\n","       [ 1,  0,  0]]), [0.0, 0.425, 0.1, 0.0, 0.0, 0.15, 0.0, 0.225, 0.1], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.125, 0.25, 0.25, 0.041666666666666664, 0.041666666666666664, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.041666666666666664], 0.999), (array([[ 0,  0, -1],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.2, 0.3333333333333333, 0.0, 0.06666666666666667, 0.0, 0.13333333333333333, 0.13333333333333333, 0.1, 0.03333333333333333], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0, -1,  1]]), [0.1, 0.15, 0.1, 0.425, 0.0, 0.225, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  0, -1],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.5333333333333333, 0.0, 0.23333333333333334, 0.0, 0.1, 0.03333333333333333, 0.06666666666666667, 0.03333333333333333], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.16, 0.04, 0.08, 0.28, 0.0, 0.08, 0.24, 0.08, 0.04], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.0, 0.16666666666666666, 0.041666666666666664, 0.375, 0.041666666666666664, 0.041666666666666664, 0.25, 0.08333333333333333, 0.0], 0.001), (array([[-1,  1, -1],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.29411764705882354, 0.0, 0.14705882352941177, 0.08823529411764706, 0.23529411764705882, 0.23529411764705882], 0.999), (array([[ 0,  0, -1],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.03333333333333333, 0.13333333333333333, 0.0, 0.1, 0.0, 0.3333333333333333, 0.13333333333333333, 0.06666666666666667, 0.2], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1, -1],\n","       [ 0,  0,  1]]), [0.1, 0.425, 0.0, 0.15, 0.0, 0.0, 0.1, 0.225, 0.0], 0.999), (array([[ 0, -1,  0],\n","       [-1, -1,  0],\n","       [ 1,  1,  0]]), [0.0, 0.0, 0.30952380952380953, 0.0, 0.0, 0.42857142857142855, 0.0, 0.0, 0.2619047619047619], 0.999), (array([[ 0,  0, -1],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.03333333333333333, 0.1, 0.0, 0.06666666666666667, 0.0, 0.5333333333333333, 0.03333333333333333, 0.23333333333333334, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [-1,  1, -1]]), [0.23529411764705882, 0.23529411764705882, 0.08823529411764706, 0.14705882352941177, 0.0, 0.29411764705882354, 0.0, 0.0, 0.0], 0.999), (array([[-1,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.1, 0.03333333333333333, 0.5333333333333333, 0.0, 0.06666666666666667, 0.0, 0.23333333333333334, 0.03333333333333333], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.25, 0.25, 0.125, 0.08333333333333333, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.08333333333333333, 0.08333333333333333], 0.999), (array([[-1,  1,  0],\n","       [-1,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.5454545454545454, 0.12121212121212122, 0.21212121212121213, 0.12121212121212122], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.25, 0.375, 0.0, 0.08333333333333333, 0.041666666666666664, 0.16666666666666666, 0.0, 0.041666666666666664, 0.041666666666666664], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.04, 0.04, 0.04, 0.16, 0.0, 0.08, 0.0, 0.4, 0.24], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0, -1]]), [0.13333333333333333, 0.06666666666666667, 0.2, 0.1, 0.0, 0.3333333333333333, 0.03333333333333333, 0.13333333333333333, 0.0], 0.999), (array([[ 0,  1, -1],\n","       [-1,  1,  1],\n","       [ 0,  0, -1]]), [0.1891891891891892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1891891891891892, 0.6216216216216216, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1, -1],\n","       [ 0,  0,  1]]), [0.17647058823529413, 0.11764705882352941, 0.29411764705882354, 0.14705882352941177, 0.0, 0.0, 0.058823529411764705, 0.20588235294117646, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [-1,  0,  0]]), [0.2, 0.06666666666666667, 0.13333333333333333, 0.3333333333333333, 0.0, 0.1, 0.0, 0.13333333333333333, 0.03333333333333333], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.08, 0.08, 0.04, 0.04, 0.0, 0.08, 0.16, 0.28, 0.24], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.041666666666666664, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.041666666666666664, 0.041666666666666664, 0.25, 0.25, 0.125], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.0, 0.041666666666666664, 0.041666666666666664, 0.08333333333333333, 0.041666666666666664, 0.16666666666666666, 0.25, 0.375, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.16, 0.28, 0.24, 0.04, 0.0, 0.08, 0.08, 0.08, 0.04], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.0, 0.08333333333333333, 0.25, 0.041666666666666664, 0.041666666666666664, 0.375, 0.041666666666666664, 0.16666666666666666, 0.0], 0.001), (array([[ 0,  0, -1],\n","       [ 0,  1,  1],\n","       [ 0,  0, -1]]), [0.23529411764705882, 0.14705882352941177, 0.0, 0.23529411764705882, 0.0, 0.0, 0.08823529411764706, 0.29411764705882354, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 1, -1,  0]]), [0.1, 0.15, 0.1, 0.225, 0.0, 0.425, 0.0, 0.0, 0.0], 0.999), (array([[ 1,  0,  0],\n","       [-1, -1,  0],\n","       [ 1, -1,  0]]), [0.0, 0.2647058823529412, 0.2647058823529412, 0.0, 0.0, 0.38235294117647056, 0.0, 0.0, 0.08823529411764706], 0.001), (array([[ 0, -1,  0],\n","       [ 1,  1,  0],\n","       [-1,  1, -1]]), [0.1891891891891892, 0.0, 0.1891891891891892, 0.0, 0.0, 0.6216216216216216, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.24, 0.08, 0.04, 0.28, 0.0, 0.08, 0.16, 0.04, 0.08], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0, -1,  1]]), [0.17647058823529413, 0.14705882352941177, 0.058823529411764705, 0.11764705882352941, 0.0, 0.20588235294117646, 0.29411764705882354, 0.0, 0.0], 0.001)] examples\n","EPOCH ::: 1\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   0%|          | 0/104 [00:00<?, ?it/s, Loss_pi=2.23e+00, Loss_v=2.82e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0417, 0.0417, 0.0000, 0.1667, 0.0417, 0.0833, 0.0000, 0.3750, 0.2500]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.8860e-01, 5.5756e-02, 2.3108e-01, 4.5323e-04, 4.8926e-01,\n","         1.6479e-02, 9.6893e-03, 4.6670e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5324], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2297, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2824, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   1%|          | 1/104 [00:01<01:42,  1.00it/s, Loss_pi=2.17e+00, Loss_v=2.74e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0417, 0.1667, 0.0000, 0.0417, 0.0417, 0.3750, 0.0000, 0.0833, 0.2500]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.2876e-01, 6.6589e-02, 2.5537e-01, 4.6301e-04, 4.1431e-01,\n","         1.4175e-02, 1.0292e-02, 5.1916e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5155], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1132, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2647, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   2%|▏         | 2/104 [00:02<01:41,  1.01it/s, Loss_pi=2.13e+00, Loss_v=2.62e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1212, 0.2121, 0.1212, 0.0000, 0.0000, 0.5455, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.6929e-01, 6.5979e-02, 2.4902e-01, 4.7326e-04, 3.8574e-01,\n","         1.2497e-02, 8.7891e-03, 5.2691e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4902], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0422, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2394, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   3%|▎         | 3/104 [00:03<01:40,  1.00it/s, Loss_pi=2.13e+00, Loss_v=2.62e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0333, 0.1333, 0.0000, 0.1000, 0.0000, 0.3333, 0.1333, 0.0667, 0.2000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.8467e-01, 5.8746e-02, 2.4341e-01, 4.8876e-04, 3.8306e-01,\n","         1.1124e-02, 8.1406e-03, 6.4611e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4884], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1258, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2607, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   4%|▍         | 4/104 [00:04<01:39,  1.01it/s, Loss_pi=2.13e+00, Loss_v=2.60e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.4000, 0.2400, 0.1600, 0.0000, 0.0800, 0.0400, 0.0400, 0.0400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.7441e-01, 5.7068e-02, 2.1704e-01, 4.7851e-04, 4.2505e-01,\n","         1.0391e-02, 7.7209e-03, 5.5373e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4949], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1260, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2542, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   5%|▍         | 5/104 [00:05<01:40,  1.02s/it, Loss_pi=2.15e+00, Loss_v=2.58e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0800, 0.0800, 0.0400, 0.0400, 0.0000, 0.0800, 0.1600, 0.2800, 0.2400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.8101e-01, 5.0385e-02, 1.9324e-01, 4.2248e-04, 4.4922e-01,\n","         9.2468e-03, 7.1487e-03, 4.5598e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4967], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2483, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2457, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   6%|▌         | 6/104 [00:06<01:39,  1.01s/it, Loss_pi=2.14e+00, Loss_v=2.60e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.6216, 0.1892, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1892]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 3.4033e-01, 5.3436e-02, 1.6333e-01, 4.1127e-04, 4.1699e-01,\n","         8.1940e-03, 6.9542e-03, 5.2273e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4751], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0981, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2744, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   7%|▋         | 7/104 [00:07<01:37,  1.00s/it, Loss_pi=2.14e+00, Loss_v=2.60e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.4250, 0.0000, 0.2250, 0.1000, 0.1500, 0.1000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 3.3545e-01, 4.8309e-02, 1.6089e-01, 4.3797e-04, 4.3066e-01,\n","         8.2626e-03, 7.4692e-03, 5.8830e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4931], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1534, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2560, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   8%|▊         | 8/104 [00:08<01:35,  1.00it/s, Loss_pi=2.15e+00, Loss_v=2.59e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0333, 0.0667, 0.0333, 0.2333, 0.0000, 0.1000, 0.0000, 0.5333, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 3.3545e-01, 4.4342e-02, 1.4429e-01, 4.3464e-04, 4.5117e-01,\n","         8.2626e-03, 7.7629e-03, 5.8353e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5002], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2136, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2492, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   9%|▊         | 9/104 [00:09<01:35,  1.00s/it, Loss_pi=2.15e+00, Loss_v=2.58e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0833, 0.0417, 0.1250, 0.0833, 0.0417, 0.2500, 0.0417, 0.0833, 0.2500]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 3.3105e-01, 4.2755e-02, 1.5405e-01, 4.4632e-04, 4.4556e-01,\n","         7.6065e-03, 7.7286e-03, 6.0380e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4997], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1760, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2493, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  10%|▉         | 10/104 [00:10<01:34,  1.00s/it, Loss_pi=2.15e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0417, 0.0833, 0.2500, 0.0833, 0.0417, 0.2500, 0.0833, 0.0417, 0.1250]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.9810e-01, 3.6163e-02, 1.4990e-01, 4.3106e-04, 4.9146e-01,\n","         7.0648e-03, 7.7591e-03, 5.7399e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5033], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1515, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2457, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  11%|█         | 11/104 [00:11<01:33,  1.00s/it, Loss_pi=2.15e+00, Loss_v=2.56e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.1471, 0.2353, 0.0000, 0.0000, 0.2353, 0.0000, 0.2941, 0.0882]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 3.3008e-01, 3.9124e-02, 1.3550e-01, 4.4489e-04, 4.7290e-01,\n","         7.3509e-03, 8.1329e-03, 4.9889e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4974], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1510, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2516, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  12%|█▏        | 12/104 [00:12<01:32,  1.00s/it, Loss_pi=2.15e+00, Loss_v=2.55e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2000, 0.3333, 0.0000, 0.0667, 0.0000, 0.1333, 0.1333, 0.1000, 0.0333]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 3.1470e-01, 2.9739e-02, 1.2915e-01, 3.7432e-04, 5.0293e-01,\n","         6.4316e-03, 7.8812e-03, 5.1856e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5069], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1404, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2421, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  12%|█▎        | 13/104 [00:13<01:30,  1.00it/s, Loss_pi=2.15e+00, Loss_v=2.56e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0800, 0.0400, 0.1600, 0.0800, 0.0000, 0.2800, 0.0400, 0.0800, 0.2400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.8369e-01, 2.6810e-02, 1.2201e-01, 3.4809e-04, 5.4688e-01,\n","         6.4659e-03, 8.3008e-03, 3.9041e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5238], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1454, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2733, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  13%|█▎        | 14/104 [00:14<01:30,  1.00s/it, Loss_pi=2.16e+00, Loss_v=2.53e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2619, 0.4286, 0.3095, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.3450e-01, 2.4338e-02, 1.0406e-01, 3.7813e-04, 6.1768e-01,\n","         6.6528e-03, 7.7782e-03, 3.5465e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5381], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2204, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2124, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  14%|█▍        | 15/104 [00:15<01:29,  1.01s/it, Loss_pi=2.15e+00, Loss_v=2.56e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0400, 0.0800, 0.2400, 0.0800, 0.0000, 0.2800, 0.0800, 0.0400, 0.1600]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.0020e-01, 2.0447e-02, 9.3079e-02, 3.4356e-04, 6.6650e-01,\n","         6.4850e-03, 8.7280e-03, 3.3498e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5484], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1168, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2996, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  15%|█▌        | 16/104 [00:16<01:28,  1.01s/it, Loss_pi=2.16e+00, Loss_v=2.59e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2647, 0.2647, 0.0000, 0.3824, 0.0000, 0.0000, 0.0882, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.0593e-01, 2.1042e-02, 7.8186e-02, 3.5095e-04, 6.7529e-01,\n","         6.1722e-03, 8.5678e-03, 3.1888e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5517], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2486, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3033, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  16%|█▋        | 17/104 [00:17<01:27,  1.01s/it, Loss_pi=2.16e+00, Loss_v=2.56e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.4250, 0.1000, 0.0000, 0.0000, 0.1500, 0.0000, 0.2250, 0.1000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.1399e-01, 2.1515e-02, 7.6294e-02, 3.5334e-04, 6.6943e-01,\n","         6.0692e-03, 8.3008e-03, 3.1590e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5501], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1373, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2015, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  17%|█▋        | 18/104 [00:18<01:33,  1.09s/it, Loss_pi=2.16e+00, Loss_v=2.53e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1250, 0.2500, 0.2500, 0.0417, 0.0417, 0.0833, 0.0833, 0.0833, 0.0417]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.8542e-01, 1.8066e-02, 7.7271e-02, 3.5238e-04, 6.9971e-01,\n","         5.6419e-03, 9.0866e-03, 3.5465e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5550], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2217, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1971, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  18%|█▊        | 19/104 [00:19<01:30,  1.07s/it, Loss_pi=2.16e+00, Loss_v=2.50e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.2941, 0.0000, 0.1471, 0.0882, 0.2353, 0.2353]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.3474e-01, 2.2522e-02, 7.6172e-02, 3.8457e-04, 6.4795e-01,\n","         5.8746e-03, 8.6823e-03, 3.2306e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5489], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2115, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2026, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  19%|█▉        | 20/104 [00:20<01:27,  1.05s/it, Loss_pi=2.17e+00, Loss_v=2.53e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1212, 0.2121, 0.1212, 0.5455, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.2156e-01, 2.0599e-02, 6.7566e-02, 3.8934e-04, 6.7188e-01,\n","         6.2370e-03, 9.1476e-03, 3.1471e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5508], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2469, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3022, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  20%|██        | 21/104 [00:21<01:25,  1.03s/it, Loss_pi=2.16e+00, Loss_v=2.50e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2353, 0.2353, 0.0882, 0.1471, 0.0000, 0.2941, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.4036e-01, 2.0355e-02, 6.6711e-02, 3.8147e-04, 6.5332e-01,\n","         6.2065e-03, 9.8419e-03, 3.3081e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5496], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0719, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2020, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  21%|██        | 22/104 [00:22<01:23,  1.02s/it, Loss_pi=2.17e+00, Loss_v=2.48e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3095, 0.4286, 0.2619]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.6611e-01, 2.1851e-02, 7.2754e-02, 4.0340e-04, 6.1914e-01,\n","         6.2103e-03, 1.0239e-02, 3.5822e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5476], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3241, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2037, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  22%|██▏       | 23/104 [00:23<01:22,  1.02s/it, Loss_pi=2.17e+00, Loss_v=2.46e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.1471, 0.2353, 0.0000, 0.0000, 0.2353, 0.0000, 0.2941, 0.0882]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 3.0200e-01, 2.2568e-02, 7.3975e-02, 3.5906e-04, 5.8203e-01,\n","         5.4893e-03, 9.7046e-03, 3.5822e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5503], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1383, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2013, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  23%|██▎       | 24/104 [00:24<01:21,  1.02s/it, Loss_pi=2.17e+00, Loss_v=2.45e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1892, 0.6216, 0.0000, 0.0000, 0.0000, 0.0000, 0.1892, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.7490e-01, 2.1210e-02, 7.4036e-02, 4.1008e-04, 6.0986e-01,\n","         6.2180e-03, 1.0414e-02, 3.2902e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5525], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1574, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1993, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  24%|██▍       | 25/104 [00:25<01:20,  1.02s/it, Loss_pi=2.17e+00, Loss_v=2.43e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0833, 0.0417, 0.1250, 0.0833, 0.0417, 0.2500, 0.0417, 0.0833, 0.2500]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.4609e-01, 1.8982e-02, 7.1655e-02, 4.3273e-04, 6.3867e-01,\n","         7.3166e-03, 1.3885e-02, 4.1187e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5541], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1510, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1979, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  25%|██▌       | 26/104 [00:27<01:18,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.41e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1333, 0.0667, 0.2000, 0.1000, 0.0000, 0.3333, 0.0333, 0.1333, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.9126e-01, 1.9211e-02, 6.7078e-02, 4.2129e-04, 5.9766e-01,\n","         7.0686e-03, 1.4061e-02, 3.7968e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5475], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0977, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2039, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  26%|██▌       | 27/104 [00:28<01:18,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.44e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2500, 0.0833, 0.0000, 0.3750, 0.0417, 0.0417, 0.0000, 0.1667, 0.0417]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.6489e-01, 1.8311e-02, 6.5918e-02, 4.1723e-04, 6.2549e-01,\n","         7.2823e-03, 1.4709e-02, 3.7313e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5579], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2549, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3102, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  27%|██▋       | 28/104 [00:29<01:17,  1.02s/it, Loss_pi=2.16e+00, Loss_v=2.46e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0333, 0.2333, 0.0000, 0.0667, 0.0000, 0.5333, 0.0333, 0.1000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.7637e-01, 1.6586e-02, 5.7892e-02, 3.8409e-04, 6.2256e-01,\n","         7.5951e-03, 1.6083e-02, 3.7134e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5630], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(1.9285, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3158, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  28%|██▊       | 29/104 [00:30<01:15,  1.01s/it, Loss_pi=2.15e+00, Loss_v=2.45e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1892, 0.0000, 0.1892, 0.0000, 0.0000, 0.6216, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.8857e-01, 1.7059e-02, 6.8542e-02, 4.3058e-04, 6.0156e-01,\n","         7.2823e-03, 1.3924e-02, 3.1412e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5580], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(1.9522, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1945, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  29%|██▉       | 30/104 [00:31<01:14,  1.00s/it, Loss_pi=2.15e+00, Loss_v=2.47e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0882, 0.0000, 0.0000, 0.3824, 0.0000, 0.2647, 0.2647]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.7344e-01, 1.4954e-02, 6.1035e-02, 3.8028e-04, 6.2598e-01,\n","         6.6376e-03, 1.4496e-02, 3.2961e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5629], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0863, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3157, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  30%|██▉       | 31/104 [00:32<01:13,  1.00s/it, Loss_pi=2.15e+00, Loss_v=2.45e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2353, 0.2353, 0.0882, 0.1471, 0.0000, 0.2941, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.2559e-01, 1.2726e-02, 5.2765e-02, 3.6955e-04, 6.8408e-01,\n","         6.9199e-03, 1.5350e-02, 3.3319e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5675], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0713, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1862, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  31%|███       | 32/104 [00:33<01:11,  1.00it/s, Loss_pi=2.15e+00, Loss_v=2.47e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2400, 0.0800, 0.0400, 0.2800, 0.0000, 0.0800, 0.1600, 0.0400, 0.0800]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.0007e-01, 1.1284e-02, 4.6051e-02, 3.6836e-04, 7.2021e-01,\n","         6.2332e-03, 1.4046e-02, 3.0696e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5741], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2491, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3284, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  32%|███▏      | 33/104 [00:34<01:10,  1.00it/s, Loss_pi=2.15e+00, Loss_v=2.45e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2353, 0.2353, 0.0882, 0.1471, 0.0000, 0.2941, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.9043e-01, 1.1436e-02, 4.6661e-02, 3.9124e-04, 7.2998e-01,\n","         6.2180e-03, 1.3161e-02, 3.4451e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5780], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0708, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1772, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  33%|███▎      | 34/104 [00:35<01:09,  1.00it/s, Loss_pi=2.15e+00, Loss_v=2.43e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1000, 0.1500, 0.1000, 0.4250, 0.0000, 0.2250, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.4954e-01, 8.7051e-03, 3.8391e-02, 3.3998e-04, 7.8320e-01,\n","         5.3596e-03, 1.2665e-02, 2.9266e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5801], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1274, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1755, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  34%|███▎      | 35/104 [00:36<01:08,  1.00it/s, Loss_pi=2.14e+00, Loss_v=2.46e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0417, 0.1667, 0.0000, 0.0417, 0.0417, 0.3750, 0.0000, 0.0833, 0.2500]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.3501e-01, 8.3618e-03, 3.6346e-02, 3.3212e-04, 8.0176e-01,\n","         4.6196e-03, 1.2360e-02, 3.1114e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5851], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0199, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3412, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  35%|███▍      | 36/104 [00:37<01:08,  1.00s/it, Loss_pi=2.15e+00, Loss_v=2.44e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1250, 0.2500, 0.2500, 0.0417, 0.0417, 0.0833, 0.0833, 0.0833, 0.0417]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 6.4514e-02, 4.4594e-03, 2.4887e-02, 2.3091e-04, 8.9111e-01,\n","         3.6411e-03, 1.0208e-02, 2.4319e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5902], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2620, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1671, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  36%|███▌      | 37/104 [00:38<01:07,  1.00s/it, Loss_pi=2.15e+00, Loss_v=2.47e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0417, 0.0417, 0.0833, 0.0417, 0.1667, 0.2500, 0.3750, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 4.5074e-02, 3.3684e-03, 1.9394e-02, 1.9765e-04, 9.1943e-01,\n","         3.0193e-03, 8.3389e-03, 1.8656e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5919], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1991, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3491, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  37%|███▋      | 38/104 [00:39<01:05,  1.00it/s, Loss_pi=2.15e+00, Loss_v=2.45e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.1892, 0.0000, 0.0000, 0.0000, 0.0000, 0.6216, 0.1892]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 4.1260e-02, 3.5496e-03, 1.8890e-02, 2.2519e-04, 9.2480e-01,\n","         2.9888e-03, 7.7553e-03, 1.8477e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5938], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3557, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1642, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  38%|███▊      | 39/104 [00:40<01:04,  1.00it/s, Loss_pi=2.16e+00, Loss_v=2.43e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.2250, 0.1000, 0.0000, 0.0000, 0.1500, 0.0000, 0.4250, 0.1000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 2.7206e-02, 2.5311e-03, 1.4793e-02, 1.8775e-04, 9.4434e-01,\n","         2.6112e-03, 7.6752e-03, 1.7166e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5956], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2120, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1627, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  38%|███▊      | 40/104 [00:41<01:04,  1.00s/it, Loss_pi=2.16e+00, Loss_v=2.45e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0333, 0.0667, 0.0333, 0.2333, 0.0000, 0.1000, 0.0000, 0.5333, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 2.0157e-02, 2.0275e-03, 1.2039e-02, 1.5271e-04, 9.5605e-01,\n","         2.1572e-03, 6.7520e-03, 1.4663e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5962], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2614, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3543, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  39%|███▉      | 41/104 [00:42<01:03,  1.01s/it, Loss_pi=2.16e+00, Loss_v=2.43e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.3095, 0.0000, 0.0000, 0.4286, 0.0000, 0.0000, 0.2619, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 1.7303e-02, 1.7414e-03, 1.1353e-02, 1.4973e-04, 9.5996e-01,\n","         2.0351e-03, 6.8855e-03, 1.3530e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5974], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3597, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1613, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  40%|████      | 42/104 [00:43<01:02,  1.01s/it, Loss_pi=2.16e+00, Loss_v=2.46e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.1212, 0.0000, 0.0000, 0.2121, 0.0000, 0.5455, 0.1212]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 1.3336e-02, 1.4505e-03, 1.0551e-02, 1.4031e-04, 9.6484e-01,\n","         1.9522e-03, 7.1411e-03, 1.2279e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5980], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1578, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3565, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  41%|████▏     | 43/104 [00:44<01:01,  1.01s/it, Loss_pi=2.16e+00, Loss_v=2.48e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1765, 0.1471, 0.0588, 0.1176, 0.0000, 0.2059, 0.2941, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 1.1780e-02, 1.4067e-03, 1.0559e-02, 1.3506e-04, 9.6582e-01,\n","         1.8930e-03, 8.0948e-03, 1.2159e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5982], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1643, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3567, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  42%|████▏     | 44/104 [00:45<01:00,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.51e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1765, 0.1176, 0.2941, 0.1471, 0.0000, 0.0000, 0.0588, 0.2059, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 8.5220e-03, 1.1005e-03, 1.0124e-02, 1.2636e-04, 9.6973e-01,\n","         1.8435e-03, 8.0032e-03, 9.5963e-06]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5989], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3625, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3575, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  43%|████▎     | 45/104 [00:46<00:59,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.49e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2400, 0.4000, 0.0000, 0.0800, 0.0000, 0.1600, 0.0400, 0.0400, 0.0400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 8.7738e-03, 1.2245e-03, 1.1444e-02, 1.3423e-04, 9.6729e-01,\n","         1.7824e-03, 8.6365e-03, 1.0610e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5985], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2070, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1604, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  44%|████▍     | 46/104 [00:47<00:58,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.47e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.6216, 0.1892, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1892]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 9.3002e-03, 1.2980e-03, 1.3115e-02, 1.4913e-04, 9.6338e-01,\n","         1.9493e-03, 1.0368e-02, 1.3471e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5987], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3604, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1602, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  45%|████▌     | 47/104 [00:48<00:57,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.45e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1892, 0.6216, 0.0000, 0.0000, 0.0000, 0.0000, 0.1892, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 9.7122e-03, 1.2732e-03, 1.3908e-02, 1.5092e-04, 9.5996e-01,\n","         2.0676e-03, 1.2466e-02, 1.3471e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5989], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3588, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1601, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  46%|████▌     | 48/104 [00:49<00:55,  1.00it/s, Loss_pi=2.18e+00, Loss_v=2.47e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1765, 0.1176, 0.2941, 0.1471, 0.0000, 0.0000, 0.0588, 0.2059, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 1.1810e-02, 1.3256e-03, 1.6922e-02, 1.4877e-04, 9.5312e-01,\n","         2.1191e-03, 1.3809e-02, 1.4067e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5986], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3578, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3571, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  47%|████▋     | 49/104 [00:50<00:54,  1.00it/s, Loss_pi=2.18e+00, Loss_v=2.50e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1212, 0.0000, 0.0000, 0.2121, 0.0000, 0.0000, 0.1212, 0.5455, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 1.0857e-02, 1.4248e-03, 2.0935e-02, 1.8108e-04, 9.4727e-01,\n","         2.4605e-03, 1.6052e-02, 1.5080e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5984], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3504, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3569, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  48%|████▊     | 50/104 [00:51<00:53,  1.00it/s, Loss_pi=2.18e+00, Loss_v=2.48e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.4250, 0.1000, 0.0000, 0.0000, 0.1500, 0.0000, 0.2250, 0.1000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 1.2978e-02, 1.4334e-03, 2.3132e-02, 1.6725e-04, 9.3896e-01,\n","         2.5959e-03, 2.0096e-02, 1.7464e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5981], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2115, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1607, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  49%|████▉     | 51/104 [00:52<00:52,  1.00it/s, Loss_pi=2.18e+00, Loss_v=2.50e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2500, 0.3750, 0.0000, 0.0833, 0.0417, 0.1667, 0.0000, 0.0417, 0.0417]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 1.3908e-02, 1.4210e-03, 2.5986e-02, 1.6963e-04, 9.3018e-01,\n","         2.6951e-03, 2.4796e-02, 1.5914e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5984], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1979, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3568, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  50%|█████     | 52/104 [00:53<00:51,  1.00it/s, Loss_pi=2.19e+00, Loss_v=2.52e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0588, 0.1471, 0.1765, 0.2059, 0.0000, 0.1176, 0.0000, 0.0000, 0.2941]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 2.1225e-02, 2.0695e-03, 3.7842e-02, 2.3222e-04, 9.0283e-01,\n","         3.5210e-03, 3.1372e-02, 2.2829e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5967], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2401, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3548, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  51%|█████     | 53/104 [00:54<00:50,  1.00it/s, Loss_pi=2.19e+00, Loss_v=2.54e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2400, 0.2800, 0.1600, 0.0800, 0.0000, 0.0400, 0.0400, 0.0800, 0.0800]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 2.3331e-02, 2.1362e-03, 4.4983e-02, 2.3973e-04, 8.8916e-01,\n","         3.5782e-03, 3.5583e-02, 2.1935e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5959], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3065, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3539, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  52%|█████▏    | 54/104 [00:55<00:49,  1.00it/s, Loss_pi=2.19e+00, Loss_v=2.56e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.1212, 0.0000, 0.0000, 0.2121, 0.0000, 0.5455, 0.1212]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 3.2593e-02, 2.8038e-03, 6.0883e-02, 3.0971e-04, 8.5352e-01,\n","         4.6959e-03, 4.3854e-02, 3.2663e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5957], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1453, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3536, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  53%|█████▎    | 55/104 [00:56<00:52,  1.06s/it, Loss_pi=2.18e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0333, 0.1000, 0.0000, 0.0667, 0.0000, 0.5333, 0.0333, 0.2333, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 3.8177e-02, 2.8973e-03, 7.4707e-02, 2.9135e-04, 8.2910e-01,\n","         4.4899e-03, 4.9011e-02, 3.1948e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5923], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(1.8853, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3497, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  54%|█████▍    | 56/104 [00:57<00:49,  1.04s/it, Loss_pi=2.18e+00, Loss_v=2.56e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0400, 0.1600, 0.0000, 0.0400, 0.0000, 0.4000, 0.0400, 0.0800, 0.2400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 4.4739e-02, 3.0441e-03, 7.9773e-02, 2.8992e-04, 8.1836e-01,\n","         4.2267e-03, 4.8370e-02, 2.6345e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5894], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0054, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1678, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  55%|█████▍    | 57/104 [00:58<00:48,  1.03s/it, Loss_pi=2.18e+00, Loss_v=2.54e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2000, 0.3333, 0.0000, 0.0667, 0.0000, 0.1333, 0.1333, 0.1000, 0.0333]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 5.8350e-02, 3.8490e-03, 8.4900e-02, 3.6645e-04, 7.9297e-01,\n","         4.7913e-03, 5.3131e-02, 3.8028e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5890], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2071, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1681, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  56%|█████▌    | 58/104 [00:59<00:46,  1.02s/it, Loss_pi=2.17e+00, Loss_v=2.56e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0333, 0.1000, 0.0000, 0.0667, 0.0000, 0.5333, 0.0333, 0.2333, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 5.8502e-02, 3.6812e-03, 8.5083e-02, 3.5596e-04, 7.9492e-01,\n","         4.5090e-03, 5.1605e-02, 3.6359e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5873], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(1.8964, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3438, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  57%|█████▋    | 59/104 [01:00<00:45,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.54e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.2941, 0.0882, 0.0000, 0.0000, 0.2353, 0.0000, 0.1471, 0.2353]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 6.0486e-02, 3.7479e-03, 8.0139e-02, 3.8290e-04, 7.9688e-01,\n","         4.6654e-03, 5.2551e-02, 4.4644e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5869], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1306, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1698, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  58%|█████▊    | 60/104 [01:01<00:44,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.53e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1892, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1892, 0.6216, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 6.2256e-02, 3.5114e-03, 7.2754e-02, 3.6716e-04, 8.0713e-01,\n","         4.1695e-03, 4.8462e-02, 3.6359e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5874], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3146, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1694, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  59%|█████▊    | 61/104 [01:02<00:43,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.52e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1250, 0.0417, 0.0833, 0.2500, 0.0417, 0.0833, 0.2500, 0.0833, 0.0417]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 5.9174e-02, 3.0880e-03, 6.2988e-02, 3.4380e-04, 8.1689e-01,\n","         3.9043e-03, 5.2246e-02, 3.5405e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5862], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2542, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1704, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  60%|█████▉    | 62/104 [01:03<00:42,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.50e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.4000, 0.2400, 0.1600, 0.0000, 0.0800, 0.0400, 0.0400, 0.0400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 6.8787e-02, 3.2692e-03, 6.2622e-02, 3.5262e-04, 7.9980e-01,\n","         4.1313e-03, 5.9784e-02, 3.6597e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5856], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2395, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1709, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  61%|██████    | 63/104 [01:04<00:41,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.52e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1212, 0.5455, 0.0000, 0.2121, 0.0000, 0.0000, 0.1212, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[0.0000e+00, 7.3792e-02, 3.3455e-03, 6.0211e-02, 3.8123e-04, 7.9346e-01,\n","         4.5013e-03, 6.3110e-02, 3.4630e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5885], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2900, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3452, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  62%|██████▏   | 64/104 [01:05<00:40,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.53e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.1667, 0.0417, 0.3750, 0.0417, 0.0417, 0.2500, 0.0833, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 8.3008e-02, 3.4790e-03, 6.4636e-02, 4.0269e-04, 7.6318e-01,\n","         4.7569e-03, 7.9163e-02, 4.2140e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5888], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2627, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3455, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  62%|██████▎   | 65/104 [01:06<00:39,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.55e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.5455, 0.0000, 0.0000, 0.1212, 0.2121, 0.1212]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.1157e-01, 4.0016e-03, 7.5500e-02, 4.4203e-04, 7.2754e-01,\n","         4.8256e-03, 7.4341e-02, 4.0770e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5851], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2799, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3412, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  63%|██████▎   | 66/104 [01:07<00:38,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.56e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1600, 0.0400, 0.0800, 0.2800, 0.0000, 0.0800, 0.2400, 0.0800, 0.0400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.4136e-01, 4.5433e-03, 8.4412e-02, 4.3941e-04, 6.6357e-01,\n","         5.3940e-03, 9.8633e-02, 5.3704e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5794], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2400, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3345, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  64%|██████▍   | 67/104 [01:08<00:37,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1600, 0.2800, 0.2400, 0.0400, 0.0000, 0.0800, 0.0800, 0.0800, 0.0400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.6931e-01, 5.3596e-03, 1.1102e-01, 5.6028e-04, 6.0986e-01,\n","         6.0730e-03, 9.6497e-02, 4.8935e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5709], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2176, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3248, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  65%|██████▌   | 68/104 [01:09<00:36,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.56e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2500, 0.0833, 0.0417, 0.2500, 0.0417, 0.0833, 0.1250, 0.0417, 0.0833]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.0129e-01, 5.6190e-03, 1.2793e-01, 5.2691e-04, 5.4688e-01,\n","         6.4697e-03, 1.0944e-01, 5.8651e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5627], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2241, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1904, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  66%|██████▋   | 69/104 [01:10<00:35,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.56e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1765, 0.1471, 0.0588, 0.1176, 0.0000, 0.2059, 0.2941, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.4219e-01, 6.3515e-03, 1.5881e-01, 6.0987e-04, 4.7412e-01,\n","         7.3128e-03, 1.0913e-01, 6.8963e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5452], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1659, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2961, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  67%|██████▋   | 70/104 [01:11<00:34,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2500, 0.0833, 0.0000, 0.3750, 0.0417, 0.0417, 0.0000, 0.1667, 0.0417]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 3.1641e-01, 6.4621e-03, 1.9189e-01, 5.2214e-04, 3.7573e-01,\n","         6.3629e-03, 1.0107e-01, 5.6803e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5243], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1876, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2739, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  68%|██████▊   | 71/104 [01:12<00:33,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1000, 0.1500, 0.1000, 0.2250, 0.0000, 0.4250, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 3.6792e-01, 7.6370e-03, 2.2327e-01, 6.2227e-04, 2.9565e-01,\n","         7.0648e-03, 9.6008e-02, 6.8724e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5032], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0856, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2458, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  69%|██████▉   | 72/104 [01:13<00:32,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.3333, 0.2000, 0.1333, 0.0000, 0.0667, 0.0333, 0.1000, 0.1333]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 3.9185e-01, 6.8474e-03, 2.5684e-01, 4.8065e-04, 2.5684e-01,\n","         5.6763e-03, 7.9590e-02, 5.3942e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4918], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1273, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2572, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  70%|███████   | 73/104 [01:14<00:31,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.4000, 0.2400, 0.1600, 0.0000, 0.0800, 0.0400, 0.0400, 0.0400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.8550e-01, 8.5144e-03, 2.8198e-01, 6.9904e-04, 2.3376e-01,\n","         7.1716e-03, 8.0811e-02, 7.5996e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4874], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0949, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2617, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  71%|███████   | 74/104 [01:15<00:30,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.1892, 0.0000, 0.0000, 0.0000, 0.0000, 0.6216, 0.1892]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 4.0137e-01, 7.7057e-03, 2.9834e-01, 5.8508e-04, 2.0825e-01,\n","         6.7978e-03, 7.5439e-02, 6.0201e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4768], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2707, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2727, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  72%|███████▏  | 75/104 [01:16<00:29,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0588, 0.2059, 0.0000, 0.1471, 0.0000, 0.0000, 0.1765, 0.1176, 0.2941]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 4.1772e-01, 7.5302e-03, 3.0078e-01, 5.6267e-04, 1.8530e-01,\n","         6.8588e-03, 7.9712e-02, 6.2644e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4847], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1790, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2340, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  73%|███████▎  | 76/104 [01:17<00:28,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0400, 0.0800, 0.2400, 0.0400, 0.0000, 0.4000, 0.0400, 0.1600, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 4.2700e-01, 8.1940e-03, 3.0273e-01, 6.3181e-04, 1.6467e-01,\n","         7.2327e-03, 8.8135e-02, 7.0333e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4728], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1913, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2769, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  74%|███████▍  | 77/104 [01:18<00:27,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.56e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1212, 0.2121, 0.1212, 0.5455, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 4.2651e-01, 7.8125e-03, 3.0249e-01, 5.9748e-04, 1.6443e-01,\n","         7.4539e-03, 8.9417e-02, 7.9036e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4774], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0637, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2270, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  75%|███████▌  | 78/104 [01:19<00:26,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.4000, 0.2400, 0.1600, 0.0000, 0.0800, 0.0400, 0.0400, 0.0400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 4.1528e-01, 8.2245e-03, 3.3374e-01, 5.9605e-04, 1.4807e-01,\n","         6.9275e-03, 8.5693e-02, 7.0035e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4777], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0830, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2718, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  76%|███████▌  | 79/104 [01:20<00:25,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0333, 0.1000, 0.1333, 0.1333, 0.0000, 0.0667, 0.0000, 0.3333, 0.2000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 4.2236e-01, 8.4991e-03, 3.2373e-01, 6.3992e-04, 1.4600e-01,\n","         7.3814e-03, 8.9905e-02, 7.5221e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4810], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1938, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2683, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  77%|███████▋  | 80/104 [01:21<00:24,  1.02s/it, Loss_pi=2.18e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0882, 0.2353, 0.2353, 0.2941, 0.0000, 0.1471, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 4.3799e-01, 8.2779e-03, 3.4106e-01, 5.8126e-04, 1.2549e-01,\n","         6.5460e-03, 7.8552e-02, 6.5684e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4791], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0972, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2703, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  78%|███████▊  | 81/104 [01:22<00:23,  1.02s/it, Loss_pi=2.18e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2619, 0.4286, 0.3095, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 4.0308e-01, 8.1100e-03, 3.6719e-01, 5.3930e-04, 1.2683e-01,\n","         6.8283e-03, 8.5815e-02, 6.0976e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4806], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1450, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2688, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  79%|███████▉  | 82/104 [01:23<00:22,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.2941, 0.2059, 0.0000, 0.1176, 0.0588, 0.1471, 0.1765]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.8257e-01, 8.1940e-03, 3.6499e-01, 5.7507e-04, 1.3013e-01,\n","         7.5760e-03, 1.0455e-01, 7.3671e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4963], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2109, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2453, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  80%|███████▉  | 83/104 [01:24<00:21,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.6216, 0.0000, 0.0000, 0.1892, 0.0000, 0.1892]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.8794e-01, 9.4147e-03, 3.5889e-01, 6.4564e-04, 1.2402e-01,\n","         8.1787e-03, 1.0944e-01, 7.7724e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.4988], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0951, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2502, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  81%|████████  | 84/104 [01:25<00:20,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2500, 0.2500, 0.1250, 0.0833, 0.0417, 0.0417, 0.0417, 0.0833, 0.0833]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.4912e-01, 8.4686e-03, 3.8330e-01, 5.4979e-04, 1.1694e-01,\n","         7.7133e-03, 1.3245e-01, 7.8619e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5061], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1823, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2429, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  82%|████████▏ | 85/104 [01:26<00:19,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0882, 0.3824, 0.2647, 0.0000, 0.0000, 0.2647, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.2446e-01, 9.6436e-03, 4.0381e-01, 6.6137e-04, 1.1749e-01,\n","         9.4986e-03, 1.3318e-01, 8.3447e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5147], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1617, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2638, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  83%|████████▎ | 86/104 [01:27<00:18,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1600, 0.2800, 0.2400, 0.0400, 0.0000, 0.0800, 0.0800, 0.0800, 0.0400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 3.3105e-01, 8.8272e-03, 4.0576e-01, 5.4264e-04, 1.0583e-01,\n","         8.5526e-03, 1.3806e-01, 7.7546e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5188], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1883, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2681, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  84%|████████▎ | 87/104 [01:28<00:17,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1892, 0.0000, 0.1892, 0.6216, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.4375e-01, 1.0063e-02, 4.1479e-01, 6.4850e-04, 1.0004e-01,\n","         8.7433e-03, 1.2067e-01, 8.5711e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5095], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0605, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2396, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  85%|████████▍ | 88/104 [01:29<00:16,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2000, 0.3333, 0.0000, 0.0667, 0.0000, 0.1333, 0.1333, 0.1000, 0.0333]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.5352e-01, 9.1324e-03, 4.1333e-01, 5.0354e-04, 8.8013e-02,\n","         7.8125e-03, 1.2610e-01, 7.9036e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5105], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1495, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2386, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  86%|████████▌ | 89/104 [01:30<00:15,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.56e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.1471, 0.0000, 0.2941, 0.2353, 0.2353, 0.0882]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 3.6426e-01, 1.0826e-02, 4.2578e-01, 6.0129e-04, 8.0017e-02,\n","         7.9193e-03, 1.0938e-01, 9.5129e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5050], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2073, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2440, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  87%|████████▋ | 90/104 [01:31<00:14,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.56e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0333, 0.1333, 0.0000, 0.1000, 0.0000, 0.3333, 0.1333, 0.0667, 0.2000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.1885e-01, 9.0485e-03, 4.4287e-01, 5.4312e-04, 8.5815e-02,\n","         8.7662e-03, 1.3293e-01, 7.4685e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5136], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1951, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2356, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  88%|████████▊ | 91/104 [01:32<00:12,  1.00it/s, Loss_pi=2.18e+00, Loss_v=2.56e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1250, 0.0417, 0.0833, 0.2500, 0.0417, 0.0833, 0.2500, 0.0833, 0.0417]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.2568e-01, 8.8120e-03, 4.3140e-01, 5.0497e-04, 8.6243e-02,\n","         8.2779e-03, 1.3782e-01, 7.5042e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5262], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1775, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2235, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  88%|████████▊ | 92/104 [01:33<00:12,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.55e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.4250, 0.1000, 0.0000, 0.0000, 0.1500, 0.0000, 0.2250, 0.1000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.7710e-01, 9.0485e-03, 4.4995e-01, 5.8746e-04, 9.8816e-02,\n","         1.0254e-02, 1.5308e-01, 8.2016e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5326], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1522, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2175, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  89%|████████▉ | 93/104 [01:34<00:11,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.56e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0333, 0.0667, 0.0333, 0.1000, 0.0000, 0.2333, 0.0000, 0.5333, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.7466e-01, 8.8272e-03, 4.1211e-01, 5.6887e-04, 1.1096e-01,\n","         1.1513e-02, 1.8005e-01, 9.0659e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5527], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1368, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3043, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  90%|█████████ | 94/104 [01:35<00:10,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0882, 0.3824, 0.2647, 0.0000, 0.0000, 0.2647, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.7148e-01, 8.0643e-03, 3.9478e-01, 4.9210e-04, 1.2042e-01,\n","         1.0857e-02, 1.9238e-01, 7.3731e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5645], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1804, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3176, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  91%|█████████▏| 95/104 [01:36<00:09,  1.08s/it, Loss_pi=2.18e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0588, 0.1471, 0.1765, 0.2059, 0.0000, 0.1176, 0.0000, 0.0000, 0.2941]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.6929e-01, 8.6594e-03, 3.5132e-01, 6.1274e-04, 1.4648e-01,\n","         1.2405e-02, 2.0984e-01, 8.8990e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5726], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1860, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3267, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  92%|█████████▏| 96/104 [01:37<00:08,  1.05s/it, Loss_pi=2.18e+00, Loss_v=2.56e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6216, 0.1892, 0.0000, 0.1892]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 2.5562e-01, 8.7433e-03, 3.4399e-01, 6.2370e-04, 1.6504e-01,\n","         1.3130e-02, 2.1191e-01, 9.8646e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5736], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2118, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1810, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  93%|█████████▎| 97/104 [01:38<00:07,  1.04s/it, Loss_pi=2.18e+00, Loss_v=2.56e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2000, 0.0667, 0.1333, 0.3333, 0.0000, 0.1000, 0.0000, 0.1333, 0.0333]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.0518e-01, 8.3923e-03, 3.0518e-01, 5.4502e-04, 1.7126e-01,\n","         1.0948e-02, 1.9702e-01, 9.2506e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5768], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1500, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1783, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  94%|█████████▍| 98/104 [01:39<00:06,  1.03s/it, Loss_pi=2.18e+00, Loss_v=2.55e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1333, 0.0667, 0.2000, 0.1000, 0.0000, 0.3333, 0.0333, 0.1333, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.7197e-01, 7.4806e-03, 3.1323e-01, 4.7088e-04, 1.9592e-01,\n","         1.0384e-02, 1.9910e-01, 7.2777e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5804], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1733, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1752, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  95%|█████████▌| 99/104 [01:40<00:05,  1.02s/it, Loss_pi=2.18e+00, Loss_v=2.54e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2000, 0.0667, 0.1333, 0.3333, 0.0000, 0.1000, 0.0000, 0.1333, 0.0333]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.5195e-01, 7.9727e-03, 2.8125e-01, 5.6458e-04, 2.2949e-01,\n","         1.1971e-02, 2.1558e-01, 8.6546e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5899], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1526, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1673, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  96%|█████████▌| 100/104 [01:41<00:04,  1.02s/it, Loss_pi=2.18e+00, Loss_v=2.53e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1892, 0.6216, 0.0000, 0.0000, 0.0000, 0.0000, 0.1892, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.1313e-01, 7.6408e-03, 2.6099e-01, 5.9843e-04, 2.6514e-01,\n","         1.3412e-02, 2.3767e-01, 9.9242e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6012], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1803, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1582, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  97%|█████████▋| 101/104 [01:42<00:03,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.54e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0333, 0.0667, 0.0333, 0.1000, 0.0000, 0.2333, 0.0000, 0.5333, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 2.1545e-01, 7.6103e-03, 2.3303e-01, 6.0511e-04, 2.6831e-01,\n","         1.3779e-02, 2.6001e-01, 1.1110e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6122], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0758, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3735, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  98%|█████████▊| 102/104 [01:43<00:02,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.55e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0417, 0.0417, 0.0833, 0.0417, 0.1667, 0.2500, 0.3750, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 1.9434e-01, 6.8588e-03, 2.1008e-01, 5.5408e-04, 2.8271e-01,\n","         1.2619e-02, 2.9175e-01, 1.1086e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6181], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1298, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3808, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  99%|█████████▉| 103/104 [01:44<00:01,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1600, 0.2800, 0.2400, 0.0400, 0.0000, 0.0800, 0.0800, 0.0800, 0.0400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 1.8896e-01, 6.3629e-03, 1.7749e-01, 5.4312e-04, 3.1641e-01,\n","         1.2077e-02, 2.9712e-01, 9.2208e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6251], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2048, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3895, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net: 100%|██████████| 104/104 [01:45<00:00,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.57e-01]\n","Self Play: 100%|██████████| 1/1 [02:37<00:00, 157.84s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[(array([[-1,  0,  0],\n","       [ 1,  1, -1],\n","       [-1,  1,  0]]), [0.0, 0.6216216216216216, 0.1891891891891892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1891891891891892], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [-1,  0,  0]]), [0.2, 0.06666666666666667, 0.13333333333333333, 0.3333333333333333, 0.0, 0.1, 0.0, 0.13333333333333333, 0.03333333333333333], 0.999), (array([[ 1,  1,  0],\n","       [-1, -1,  0],\n","       [ 0, -1,  0]]), [0.0, 0.0, 0.2619047619047619, 0.0, 0.0, 0.42857142857142855, 0.0, 0.0, 0.30952380952380953], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.25, 0.08333333333333333, 0.0, 0.375, 0.041666666666666664, 0.041666666666666664, 0.0, 0.16666666666666666, 0.041666666666666664], 0.001), (array([[ 0,  1,  1],\n","       [ 0, -1, -1],\n","       [ 0, -1,  0]]), [0.2619047619047619, 0.0, 0.0, 0.42857142857142855, 0.0, 0.0, 0.30952380952380953, 0.0, 0.0], 0.999), (array([[ 0,  0, -1],\n","       [ 0,  0,  1],\n","       [ 0,  0,  0]]), [0.20689655172413793, 0.13793103448275862, 0.0, 0.3448275862068966, 0.034482758620689655, 0.0, 0.06896551724137931, 0.20689655172413793, 0.0], 0.999), (array([[ 0, -1,  0],\n","       [ 0,  0,  0],\n","       [ 0,  0,  0]]), [0.14705882352941177, 0.0, 0.0, 0.11764705882352941, 0.029411764705882353, 0.17647058823529413, 0.20588235294117646, 0.2647058823529412, 0.058823529411764705], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.08333333333333333, 0.4166666666666667, 0.0, 0.08333333333333333, 0.0, 0.08333333333333333, 0.125, 0.16666666666666666, 0.041666666666666664], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.4, 0.24, 0.16, 0.0, 0.08, 0.04, 0.04, 0.04], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  1, -1],\n","       [ 0,  1, -1]]), [0.12121212121212122, 0.21212121212121213, 0.12121212121212122, 0.5454545454545454, 0.0, 0.0, 0.0, 0.0, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [-1,  0,  0],\n","       [ 0,  0,  0]]), [0.14705882352941177, 0.11764705882352941, 0.20588235294117646, 0.0, 0.029411764705882353, 0.2647058823529412, 0.0, 0.17647058823529413, 0.058823529411764705], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.04, 0.04, 0.04, 0.08, 0.0, 0.16, 0.24, 0.4, 0.0], 0.999), (array([[ 0, -1,  0],\n","       [ 1,  1,  0],\n","       [-1,  1, -1]]), [0.1891891891891892, 0.0, 0.1891891891891892, 0.0, 0.0, 0.6216216216216216, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [-1,  0, -1],\n","       [ 0,  0,  1]]), [0.11764705882352941, 0.29411764705882354, 0.0, 0.0, 0.058823529411764705, 0.0, 0.3235294117647059, 0.20588235294117646, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.08, 0.04, 0.16, 0.08, 0.0, 0.28, 0.04, 0.08, 0.24], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.04, 0.08, 0.08, 0.08, 0.0, 0.04, 0.24, 0.28, 0.16], 0.001), (array([[-1,  1, -1],\n","       [ 1,  1,  0],\n","       [ 0, -1,  0]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.6216216216216216, 0.1891891891891892, 0.0, 0.1891891891891892], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.04, 0.08, 0.24, 0.04, 0.0, 0.4, 0.04, 0.16, 0.0], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.0, 0.041666666666666664, 0.041666666666666664, 0.08333333333333333, 0.041666666666666664, 0.16666666666666666, 0.25, 0.375, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [-1,  0,  0],\n","       [ 0,  0,  0]]), [0.0, 0.17647058823529413, 0.058823529411764705, 0.0, 0.029411764705882353, 0.2647058823529412, 0.14705882352941177, 0.11764705882352941, 0.20588235294117646], 0.001), (array([[-1,  1, -1],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.14705882352941177, 0.0, 0.29411764705882354, 0.23529411764705882, 0.23529411764705882, 0.08823529411764706], 0.999), (array([[-1,  1,  0],\n","       [ 1,  1, -1],\n","       [-1,  0,  0]]), [0.0, 0.0, 0.1891891891891892, 0.0, 0.0, 0.0, 0.0, 0.6216216216216216, 0.1891891891891892], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.0, 0.4166666666666667, 0.08333333333333333, 0.08333333333333333, 0.0, 0.08333333333333333, 0.041666666666666664, 0.16666666666666666, 0.125], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.0, 0.16666666666666666, 0.041666666666666664, 0.375, 0.041666666666666664, 0.041666666666666664, 0.25, 0.08333333333333333, 0.0], 0.001), (array([[ 1, -1,  0],\n","       [ 1, -1, -1],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2619047619047619, 0.42857142857142855, 0.30952380952380953], 0.999), (array([[ 0,  1,  0],\n","       [-1,  0,  0],\n","       [-1,  1,  0]]), [0.3870967741935484, 0.0, 0.16129032258064516, 0.0, 0.06451612903225806, 0.3870967741935484, 0.0, 0.0, 0.0], 0.999), (array([[ 0, -1,  1],\n","       [-1, -1,  1],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30952380952380953, 0.42857142857142855, 0.2619047619047619], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.125, 0.08333333333333333, 0.08333333333333333, 0.16666666666666666, 0.0, 0.4166666666666667, 0.041666666666666664, 0.08333333333333333, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 1,  0,  1],\n","       [-1, -1,  0]]), [0.0, 0.3870967741935484, 0.16129032258064516, 0.0, 0.06451612903225806, 0.0, 0.0, 0.0, 0.3870967741935484], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.08333333333333333, 0.08333333333333333, 0.125, 0.4166666666666667, 0.0, 0.16666666666666666, 0.0, 0.08333333333333333, 0.041666666666666664], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  0,  0],\n","       [ 0,  1, -1]]), [0.06896551724137931, 0.3448275862068966, 0.20689655172413793, 0.20689655172413793, 0.034482758620689655, 0.13793103448275862, 0.0, 0.0, 0.0], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.125, 0.16666666666666666, 0.041666666666666664, 0.08333333333333333, 0.0, 0.08333333333333333, 0.08333333333333333, 0.4166666666666667, 0.0], 0.999), (array([[-1, -1,  0],\n","       [ 1,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.12121212121212122, 0.0, 0.0, 0.21212121212121213, 0.0, 0.5454545454545454, 0.12121212121212122], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0, -1]]), [0.13333333333333333, 0.06666666666666667, 0.2, 0.1, 0.0, 0.3333333333333333, 0.03333333333333333, 0.13333333333333333, 0.0], 0.999), (array([[ 0,  0, -1],\n","       [-1,  1,  1],\n","       [ 0,  1, -1]]), [0.1891891891891892, 0.6216216216216216, 0.0, 0.0, 0.0, 0.0, 0.1891891891891892, 0.0, 0.0], 0.999), (array([[ 0,  1, -1],\n","       [ 0,  0, -1],\n","       [ 0,  1,  0]]), [0.0, 0.0, 0.0, 0.3870967741935484, 0.06451612903225806, 0.0, 0.16129032258064516, 0.0, 0.3870967741935484], 0.999), (array([[-1,  1,  0],\n","       [-1,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.5454545454545454, 0.12121212121212122, 0.21212121212121213, 0.12121212121212122], 0.001), (array([[ 0,  0,  0],\n","       [-1,  0, -1],\n","       [ 1,  0,  0]]), [0.0, 0.29411764705882354, 0.11764705882352941, 0.0, 0.058823529411764705, 0.0, 0.0, 0.20588235294117646, 0.3235294117647059], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.08333333333333333, 0.041666666666666664, 0.125, 0.08333333333333333, 0.041666666666666664, 0.25, 0.041666666666666664, 0.08333333333333333, 0.25], 0.999), (array([[ 0,  0,  1],\n","       [ 0, -1, -1],\n","       [ 0,  0,  0]]), [0.058823529411764705, 0.20588235294117646, 0.0, 0.14705882352941177, 0.0, 0.0, 0.17647058823529413, 0.11764705882352941, 0.29411764705882354], 0.001), (array([[-1,  0,  0],\n","       [ 1,  1,  0],\n","       [-1,  0,  0]]), [0.0, 0.14705882352941177, 0.23529411764705882, 0.0, 0.0, 0.23529411764705882, 0.0, 0.29411764705882354, 0.08823529411764706], 0.999), (array([[ 1, -1,  0],\n","       [-1, -1,  0],\n","       [ 1,  0,  0]]), [0.0, 0.0, 0.08823529411764706, 0.0, 0.0, 0.38235294117647056, 0.0, 0.2647058823529412, 0.2647058823529412], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.08333333333333333, 0.08333333333333333, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.08333333333333333, 0.125, 0.25, 0.25], 0.999), (array([[ 0, -1, -1],\n","       [ 0,  1,  1],\n","       [ 0,  0,  0]]), [0.12121212121212122, 0.0, 0.0, 0.21212121212121213, 0.0, 0.0, 0.12121212121212122, 0.5454545454545454, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.24, 0.08, 0.04, 0.28, 0.0, 0.08, 0.16, 0.04, 0.08], 0.001), (array([[ 1,  0,  0],\n","       [-1,  0, -1],\n","       [ 0,  0,  0]]), [0.0, 0.20588235294117646, 0.3235294117647059, 0.0, 0.058823529411764705, 0.0, 0.0, 0.29411764705882354, 0.11764705882352941], 0.001), (array([[ 0,  0, -1],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.5333333333333333, 0.0, 0.23333333333333334, 0.0, 0.1, 0.03333333333333333, 0.06666666666666667, 0.03333333333333333], 0.001), (array([[ 0, -1,  1],\n","       [ 0, -1, -1],\n","       [ 0,  0,  1]]), [0.08823529411764706, 0.0, 0.0, 0.38235294117647056, 0.0, 0.0, 0.2647058823529412, 0.2647058823529412, 0.0], 0.001), (array([[-1,  1, -1],\n","       [ 0,  1,  1],\n","       [ 0, -1,  0]]), [0.0, 0.0, 0.0, 0.6216216216216216, 0.0, 0.0, 0.1891891891891892, 0.0, 0.1891891891891892], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.041666666666666664, 0.041666666666666664, 0.0, 0.16666666666666666, 0.041666666666666664, 0.08333333333333333, 0.0, 0.375, 0.25], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1, -1],\n","       [ 0,  0,  1]]), [0.17647058823529413, 0.11764705882352941, 0.29411764705882354, 0.14705882352941177, 0.0, 0.0, 0.058823529411764705, 0.20588235294117646, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [-1, -1,  1],\n","       [ 0, -1,  1]]), [0.30952380952380953, 0.42857142857142855, 0.2619047619047619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  0,  0],\n","       [-1,  1,  0]]), [0.20689655172413793, 0.3448275862068966, 0.06896551724137931, 0.13793103448275862, 0.034482758620689655, 0.20689655172413793, 0.0, 0.0, 0.0], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.0, 0.375, 0.25, 0.16666666666666666, 0.041666666666666664, 0.08333333333333333, 0.041666666666666664, 0.041666666666666664, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0, -1]]), [0.03333333333333333, 0.23333333333333334, 0.0, 0.06666666666666667, 0.0, 0.5333333333333333, 0.03333333333333333, 0.1, 0.0], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.0, 0.08333333333333333, 0.041666666666666664, 0.4166666666666667, 0.0, 0.16666666666666666, 0.08333333333333333, 0.08333333333333333, 0.125], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [-1,  0,  0]]), [0.03333333333333333, 0.1, 0.13333333333333333, 0.13333333333333333, 0.0, 0.06666666666666667, 0.0, 0.3333333333333333, 0.2], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.16, 0.04, 0.08, 0.28, 0.0, 0.08, 0.24, 0.08, 0.04], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.04, 0.04, 0.04, 0.16, 0.0, 0.08, 0.0, 0.4, 0.24], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  0, -1],\n","       [ 0,  0,  0]]), [0.058823529411764705, 0.17647058823529413, 0.0, 0.2647058823529412, 0.029411764705882353, 0.0, 0.20588235294117646, 0.11764705882352941, 0.14705882352941177], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1, -1],\n","       [ 0,  0,  1]]), [0.1, 0.425, 0.0, 0.15, 0.0, 0.0, 0.1, 0.225, 0.0], 0.999), (array([[ 0, -1,  0],\n","       [ 0,  1,  1],\n","       [-1,  1, -1]]), [0.1891891891891892, 0.0, 0.1891891891891892, 0.6216216216216216, 0.0, 0.0, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  0,  0],\n","       [ 0, -1,  0]]), [0.058823529411764705, 0.2647058823529412, 0.20588235294117646, 0.17647058823529413, 0.029411764705882353, 0.11764705882352941, 0.0, 0.0, 0.14705882352941177], 0.001), (array([[ 1, -1,  1],\n","       [ 0, -1, -1],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.2647058823529412, 0.0, 0.0, 0.2647058823529412, 0.38235294117647056, 0.08823529411764706], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.041666666666666664, 0.16666666666666666, 0.125, 0.08333333333333333, 0.0, 0.08333333333333333, 0.0, 0.4166666666666667, 0.08333333333333333], 0.999), (array([[ 0,  0,  0],\n","       [ 1,  0,  0],\n","       [-1,  0,  0]]), [0.0, 0.20689655172413793, 0.06896551724137931, 0.0, 0.034482758620689655, 0.3448275862068966, 0.0, 0.13793103448275862, 0.20689655172413793], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.25, 0.08333333333333333, 0.041666666666666664, 0.25, 0.041666666666666664, 0.08333333333333333, 0.125, 0.041666666666666664, 0.08333333333333333], 0.999), (array([[ 0,  0,  0],\n","       [ 1,  1,  0],\n","       [-1, -1,  0]]), [0.0, 0.5454545454545454, 0.12121212121212122, 0.0, 0.0, 0.21212121212121213, 0.0, 0.0, 0.12121212121212122], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [-1,  0,  0]]), [0.0, 0.23333333333333334, 0.03333333333333333, 0.5333333333333333, 0.0, 0.06666666666666667, 0.0, 0.1, 0.03333333333333333], 0.001), (array([[-1,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.13333333333333333, 0.03333333333333333, 0.3333333333333333, 0.0, 0.1, 0.2, 0.06666666666666667, 0.13333333333333333], 0.999), (array([[ 0,  0,  1],\n","       [-1,  0, -1],\n","       [ 0,  0,  0]]), [0.3235294117647059, 0.20588235294117646, 0.0, 0.0, 0.058823529411764705, 0.0, 0.11764705882352941, 0.29411764705882354, 0.0], 0.001), (array([[ 1, -1,  1],\n","       [-1, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.2647058823529412, 0.08823529411764706, 0.38235294117647056, 0.2647058823529412], 0.001), (array([[ 0,  0,  0],\n","       [-1, -1,  0],\n","       [ 1, -1,  1]]), [0.08823529411764706, 0.38235294117647056, 0.2647058823529412, 0.0, 0.0, 0.2647058823529412, 0.0, 0.0, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1, -1],\n","       [ 1, -1,  1]]), [0.2647058823529412, 0.38235294117647056, 0.08823529411764706, 0.2647058823529412, 0.0, 0.0, 0.0, 0.0, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0, -1]]), [0.03333333333333333, 0.06666666666666667, 0.03333333333333333, 0.23333333333333334, 0.0, 0.1, 0.0, 0.5333333333333333, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  0,  1],\n","       [ 0,  0, -1]]), [0.06896551724137931, 0.20689655172413793, 0.0, 0.3448275862068966, 0.034482758620689655, 0.0, 0.20689655172413793, 0.13793103448275862, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.16, 0.04, 0.4, 0.0, 0.04, 0.24, 0.08, 0.04], 0.999), (array([[ 0, -1,  0],\n","       [ 0,  0,  0],\n","       [ 0, -1,  1]]), [0.11764705882352941, 0.0, 0.3235294117647059, 0.29411764705882354, 0.058823529411764705, 0.20588235294117646, 0.0, 0.0, 0.0], 0.001), (array([[ 0, -1,  0],\n","       [ 0,  0,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.14705882352941177, 0.17647058823529413, 0.029411764705882353, 0.11764705882352941, 0.058823529411764705, 0.2647058823529412, 0.20588235294117646], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.125, 0.041666666666666664, 0.08333333333333333, 0.25, 0.041666666666666664, 0.08333333333333333, 0.25, 0.08333333333333333, 0.041666666666666664], 0.999), (array([[-1,  1,  0],\n","       [-1,  0,  0],\n","       [ 0,  1,  0]]), [0.0, 0.0, 0.0, 0.0, 0.06451612903225806, 0.3870967741935484, 0.3870967741935484, 0.0, 0.16129032258064516], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  1,  1],\n","       [ 0, -1, -1]]), [0.12121212121212122, 0.5454545454545454, 0.0, 0.21212121212121213, 0.0, 0.0, 0.12121212121212122, 0.0, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [-1,  0,  0]]), [0.03333333333333333, 0.06666666666666667, 0.03333333333333333, 0.1, 0.0, 0.23333333333333334, 0.0, 0.5333333333333333, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.04, 0.08, 0.24, 0.08, 0.0, 0.28, 0.08, 0.04, 0.16], 0.001), (array([[ 0,  0, -1],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.03333333333333333, 0.1, 0.0, 0.06666666666666667, 0.0, 0.5333333333333333, 0.03333333333333333, 0.23333333333333334, 0.0], 0.001), (array([[-1,  1, -1],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.29411764705882354, 0.0, 0.14705882352941177, 0.08823529411764706, 0.23529411764705882, 0.23529411764705882], 0.999), (array([[-1,  0,  0],\n","       [ 1,  0,  0],\n","       [ 0,  0,  0]]), [0.0, 0.13793103448275862, 0.20689655172413793, 0.0, 0.034482758620689655, 0.3448275862068966, 0.0, 0.20689655172413793, 0.06896551724137931], 0.999), (array([[ 1, -1,  0],\n","       [ 0,  0,  0],\n","       [ 0, -1,  0]]), [0.0, 0.0, 0.0, 0.20588235294117646, 0.058823529411764705, 0.29411764705882354, 0.3235294117647059, 0.0, 0.11764705882352941], 0.001), (array([[ 0,  0,  0],\n","       [ 1, -1, -1],\n","       [ 1, -1,  0]]), [0.2619047619047619, 0.42857142857142855, 0.30952380952380953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.999), (array([[ 0, -1,  1],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.29411764705882354, 0.0, 0.0, 0.11764705882352941, 0.0, 0.20588235294117646, 0.17647058823529413, 0.14705882352941177, 0.058823529411764705], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.0, 0.08333333333333333, 0.25, 0.041666666666666664, 0.041666666666666664, 0.375, 0.041666666666666664, 0.16666666666666666, 0.0], 0.001), (array([[ 1, -1,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.29411764705882354, 0.20588235294117646, 0.0, 0.11764705882352941, 0.058823529411764705, 0.14705882352941177, 0.17647058823529413], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.04, 0.16, 0.0, 0.04, 0.0, 0.4, 0.04, 0.08, 0.24], 0.999), (array([[-1,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.3333333333333333, 0.2, 0.13333333333333333, 0.0, 0.06666666666666667, 0.03333333333333333, 0.1, 0.13333333333333333], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  0, -1],\n","       [ 0,  0,  0]]), [0.20588235294117646, 0.11764705882352941, 0.14705882352941177, 0.2647058823529412, 0.029411764705882353, 0.0, 0.058823529411764705, 0.17647058823529413, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.16, 0.28, 0.24, 0.04, 0.0, 0.08, 0.08, 0.08, 0.04], 0.001), (array([[ 0,  1,  0],\n","       [ 0,  0, -1],\n","       [ 0,  1, -1]]), [0.16129032258064516, 0.0, 0.3870967741935484, 0.3870967741935484, 0.06451612903225806, 0.0, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0, -1]]), [0.13333333333333333, 0.1, 0.03333333333333333, 0.06666666666666667, 0.0, 0.13333333333333333, 0.2, 0.3333333333333333, 0.0], 0.999), (array([[ 0,  0,  1],\n","       [ 0, -1, -1],\n","       [ 0,  0,  0]]), [0.1, 0.225, 0.0, 0.15, 0.0, 0.0, 0.1, 0.425, 0.0], 0.999), (array([[-1,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.5333333333333333, 0.0, 0.1, 0.0, 0.23333333333333334, 0.03333333333333333, 0.06666666666666667, 0.03333333333333333], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.125, 0.25, 0.25, 0.041666666666666664, 0.041666666666666664, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.041666666666666664], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 1, -1,  0]]), [0.1, 0.15, 0.1, 0.225, 0.0, 0.425, 0.0, 0.0, 0.0], 0.999), (array([[ 0, -1,  0],\n","       [ 0,  0,  0],\n","       [ 1, -1,  0]]), [0.3235294117647059, 0.0, 0.11764705882352941, 0.20588235294117646, 0.058823529411764705, 0.29411764705882354, 0.0, 0.0, 0.0], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.041666666666666664, 0.08333333333333333, 0.0, 0.16666666666666666, 0.0, 0.4166666666666667, 0.125, 0.08333333333333333, 0.08333333333333333], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.041666666666666664, 0.16666666666666666, 0.0, 0.041666666666666664, 0.041666666666666664, 0.375, 0.0, 0.08333333333333333, 0.25], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 1, -1,  0]]), [0.058823529411764705, 0.14705882352941177, 0.17647058823529413, 0.20588235294117646, 0.0, 0.11764705882352941, 0.0, 0.0, 0.29411764705882354], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.041666666666666664, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.041666666666666664, 0.041666666666666664, 0.25, 0.25, 0.125], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.24, 0.4, 0.0, 0.08, 0.0, 0.16, 0.04, 0.04, 0.04], 0.999), (array([[ 0,  0,  1],\n","       [ 0, -1, -1],\n","       [ 0, -1,  1]]), [0.2647058823529412, 0.2647058823529412, 0.0, 0.38235294117647056, 0.0, 0.0, 0.08823529411764706, 0.0, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  0,  0],\n","       [ 0, -1,  0]]), [0.20588235294117646, 0.2647058823529412, 0.058823529411764705, 0.11764705882352941, 0.029411764705882353, 0.17647058823529413, 0.14705882352941177, 0.0, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [-1,  1,  0],\n","       [-1,  1,  0]]), [0.12121212121212122, 0.21212121212121213, 0.12121212121212122, 0.0, 0.0, 0.5454545454545454, 0.0, 0.0, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.08, 0.08, 0.04, 0.04, 0.0, 0.08, 0.16, 0.28, 0.24], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [-1,  1, -1]]), [0.23529411764705882, 0.23529411764705882, 0.08823529411764706, 0.14705882352941177, 0.0, 0.29411764705882354, 0.0, 0.0, 0.0], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.25, 0.375, 0.0, 0.08333333333333333, 0.041666666666666664, 0.16666666666666666, 0.0, 0.041666666666666664, 0.041666666666666664], 0.001), (array([[ 0, -1, -1],\n","       [ 1,  0,  1],\n","       [ 0,  0,  0]]), [0.3870967741935484, 0.0, 0.0, 0.0, 0.06451612903225806, 0.0, 0.16129032258064516, 0.3870967741935484, 0.0], 0.999), (array([[ 0, -1,  1],\n","       [ 0,  0,  0],\n","       [ 0, -1,  0]]), [0.0, 0.0, 0.0, 0.29411764705882354, 0.058823529411764705, 0.20588235294117646, 0.11764705882352941, 0.0, 0.3235294117647059], 0.001), (array([[-1, -1,  0],\n","       [ 1,  0,  1],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.3870967741935484, 0.0, 0.06451612903225806, 0.0, 0.0, 0.3870967741935484, 0.16129032258064516], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [-1,  1, -1]]), [0.08823529411764706, 0.23529411764705882, 0.23529411764705882, 0.29411764705882354, 0.0, 0.14705882352941177, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0, -1,  1]]), [0.17647058823529413, 0.14705882352941177, 0.058823529411764705, 0.11764705882352941, 0.0, 0.20588235294117646, 0.29411764705882354, 0.0, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 1,  0,  1],\n","       [ 0, -1, -1]]), [0.16129032258064516, 0.3870967741935484, 0.0, 0.0, 0.06451612903225806, 0.0, 0.3870967741935484, 0.0, 0.0], 0.999), (array([[-1,  1,  0],\n","       [ 0,  0,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.13793103448275862, 0.034482758620689655, 0.20689655172413793, 0.20689655172413793, 0.3448275862068966, 0.06896551724137931], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.25, 0.25, 0.125, 0.08333333333333333, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.08333333333333333, 0.08333333333333333], 0.999), (array([[ 0,  0, -1],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.2, 0.3333333333333333, 0.0, 0.06666666666666667, 0.0, 0.13333333333333333, 0.13333333333333333, 0.1, 0.03333333333333333], 0.999), (array([[ 0,  0,  0],\n","       [-1, -1,  0],\n","       [ 1,  0,  0]]), [0.29411764705882354, 0.11764705882352941, 0.17647058823529413, 0.0, 0.0, 0.14705882352941177, 0.0, 0.20588235294117646, 0.058823529411764705], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.24, 0.08, 0.04, 0.4, 0.0, 0.04, 0.0, 0.16, 0.04], 0.999), (array([[ 0, -1,  1],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.425, 0.0, 0.225, 0.1, 0.15, 0.1], 0.999), (array([[ 1, -1,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.225, 0.0, 0.425, 0.1, 0.15, 0.1], 0.999), (array([[ 0, -1,  0],\n","       [-1, -1,  0],\n","       [ 1,  1,  0]]), [0.0, 0.0, 0.30952380952380953, 0.0, 0.0, 0.42857142857142855, 0.0, 0.0, 0.2619047619047619], 0.999), (array([[ 1,  0,  0],\n","       [-1, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.20588235294117646, 0.058823529411764705, 0.0, 0.0, 0.14705882352941177, 0.29411764705882354, 0.11764705882352941, 0.17647058823529413], 0.001), (array([[ 0,  0,  0],\n","       [-1, -1,  0],\n","       [ 1,  0,  0]]), [0.0, 0.425, 0.1, 0.0, 0.0, 0.15, 0.0, 0.225, 0.1], 0.999), (array([[ 1,  0,  0],\n","       [-1, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.225, 0.1, 0.0, 0.0, 0.15, 0.0, 0.425, 0.1], 0.999), (array([[ 0,  1, -1],\n","       [-1,  1,  1],\n","       [ 0,  0, -1]]), [0.1891891891891892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1891891891891892, 0.6216216216216216, 0.0], 0.999), (array([[ 0,  0, -1],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.03333333333333333, 0.13333333333333333, 0.0, 0.1, 0.0, 0.3333333333333333, 0.13333333333333333, 0.06666666666666667, 0.2], 0.999), (array([[-1,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.1, 0.03333333333333333, 0.5333333333333333, 0.0, 0.06666666666666667, 0.0, 0.23333333333333334, 0.03333333333333333], 0.001), (array([[ 0,  1, -1],\n","       [ 0,  1, -1],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.5454545454545454, 0.0, 0.0, 0.12121212121212122, 0.21212121212121213, 0.12121212121212122], 0.001), (array([[ 0,  0, -1],\n","       [ 0,  1,  1],\n","       [ 0,  0, -1]]), [0.08823529411764706, 0.29411764705882354, 0.0, 0.23529411764705882, 0.0, 0.0, 0.23529411764705882, 0.14705882352941177, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.24, 0.28, 0.16, 0.08, 0.0, 0.04, 0.04, 0.08, 0.08], 0.001), (array([[ 1,  0,  0],\n","       [-1, -1,  0],\n","       [ 1, -1,  0]]), [0.0, 0.2647058823529412, 0.2647058823529412, 0.0, 0.0, 0.38235294117647056, 0.0, 0.0, 0.08823529411764706], 0.001), (array([[ 0,  1, -1],\n","       [ 0,  0,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.20689655172413793, 0.034482758620689655, 0.13793103448275862, 0.06896551724137931, 0.3448275862068966, 0.20689655172413793], 0.999), (array([[ 0, -1,  0],\n","       [ 0, -1, -1],\n","       [ 0,  1,  1]]), [0.30952380952380953, 0.0, 0.0, 0.42857142857142855, 0.0, 0.0, 0.2619047619047619, 0.0, 0.0], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.041666666666666664, 0.08333333333333333, 0.25, 0.08333333333333333, 0.041666666666666664, 0.25, 0.08333333333333333, 0.041666666666666664, 0.125], 0.999), (array([[-1,  0,  0],\n","       [ 1,  1,  0],\n","       [-1,  0,  0]]), [0.0, 0.29411764705882354, 0.08823529411764706, 0.0, 0.0, 0.23529411764705882, 0.0, 0.14705882352941177, 0.23529411764705882], 0.999), (array([[ 0,  0, -1],\n","       [ 0,  1,  1],\n","       [ 0,  0, -1]]), [0.23529411764705882, 0.14705882352941177, 0.0, 0.23529411764705882, 0.0, 0.0, 0.08823529411764706, 0.29411764705882354, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0, -1,  1]]), [0.1, 0.15, 0.1, 0.425, 0.0, 0.225, 0.0, 0.0, 0.0], 0.999)] examples\n","EPOCH ::: 1\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   0%|          | 0/144 [00:00<?, ?it/s, Loss_pi=2.13e+00, Loss_v=3.95e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.5333, 0.0000, 0.2333, 0.0000, 0.1000, 0.0333, 0.0667, 0.0333]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 1.8481e-01, 5.8479e-03, 1.5076e-01, 4.4727e-04, 3.5620e-01,\n","         1.0262e-02, 2.9077e-01, 9.5248e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6295], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1283, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3951, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   1%|          | 1/144 [00:01<02:20,  1.02it/s, Loss_pi=2.15e+00, Loss_v=2.70e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.3871, 0.0000, 0.1613, 0.0000, 0.0645, 0.3871, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 1.9495e-01, 5.2795e-03, 1.6418e-01, 4.3321e-04, 3.5303e-01,\n","         1.0178e-02, 2.7075e-01, 8.3327e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6185], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1793, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1448, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   1%|▏         | 2/144 [00:02<02:19,  1.02it/s, Loss_pi=2.13e+00, Loss_v=3.04e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0333, 0.0667, 0.0333, 0.1000, 0.0000, 0.2333, 0.0000, 0.5333, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.2961e-01, 6.1188e-03, 1.6797e-01, 4.9448e-04, 3.5547e-01,\n","         9.6283e-03, 2.2961e-01, 9.2924e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6112], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0794, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3723, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   2%|▏         | 3/144 [00:03<02:19,  1.01it/s, Loss_pi=2.13e+00, Loss_v=3.20e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0417, 0.0417, 0.0833, 0.0417, 0.1667, 0.2500, 0.3750, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.2144e-01, 5.2071e-03, 1.6455e-01, 4.0174e-04, 3.7085e-01,\n","         7.5798e-03, 2.2852e-01, 8.3566e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6065], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1440, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3667, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   3%|▎         | 4/144 [00:04<02:18,  1.01it/s, Loss_pi=2.13e+00, Loss_v=3.28e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.2647, 0.2647, 0.0000, 0.0000, 0.3824, 0.0000, 0.0000, 0.0882]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.0801e-01, 5.6305e-03, 1.6455e-01, 4.5490e-04, 4.0723e-01,\n","         8.1940e-03, 2.0471e-01, 8.8871e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6012], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1058, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3603, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   3%|▎         | 5/144 [00:05<02:18,  1.01it/s, Loss_pi=2.13e+00, Loss_v=3.33e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0800, 0.0400, 0.1600, 0.0800, 0.0000, 0.2800, 0.0400, 0.0800, 0.2400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.4060e-01, 5.3177e-03, 1.5784e-01, 3.9411e-04, 4.0918e-01,\n","         6.5117e-03, 1.7883e-01, 7.1228e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5984], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1660, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3569, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   4%|▍         | 6/144 [00:06<02:16,  1.01it/s, Loss_pi=2.12e+00, Loss_v=3.09e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0417, 0.0833, 0.0000, 0.1667, 0.0000, 0.4167, 0.1250, 0.0833, 0.0833]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.1631e-01, 4.6310e-03, 1.5344e-01, 3.3832e-04, 4.5801e-01,\n","         5.3329e-03, 1.6077e-01, 5.5671e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5900], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0710, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1673, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   5%|▍         | 7/144 [00:07<02:15,  1.01it/s, Loss_pi=2.13e+00, Loss_v=2.91e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.3333, 0.2000, 0.1333, 0.0000, 0.0667, 0.0333, 0.1000, 0.1333]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 1.9983e-01, 5.0011e-03, 1.5088e-01, 3.5954e-04, 5.0244e-01,\n","         5.1613e-03, 1.3525e-01, 5.9128e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5907], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1863, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1667, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   6%|▌         | 8/144 [00:08<02:14,  1.01it/s, Loss_pi=2.14e+00, Loss_v=2.77e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2619, 0.4286, 0.3095, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.0886e-01, 5.2299e-03, 1.4355e-01, 3.5596e-04, 5.1709e-01,\n","         4.6158e-03, 1.1902e-01, 5.5015e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5898], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2309, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1675, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   6%|▋         | 9/144 [00:09<02:14,  1.01it/s, Loss_pi=2.14e+00, Loss_v=2.67e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.2250, 0.1000, 0.0000, 0.0000, 0.1500, 0.0000, 0.4250, 0.1000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.1204e-01, 4.9095e-03, 1.3269e-01, 3.3665e-04, 5.3320e-01,\n","         3.8834e-03, 1.1176e-01, 5.4538e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5890], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1475, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1681, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   7%|▋         | 10/144 [00:10<02:13,  1.01it/s, Loss_pi=2.16e+00, Loss_v=2.58e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.3095, 0.0000, 0.0000, 0.4286, 0.0000, 0.0000, 0.2619, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.0618e-01, 4.9248e-03, 1.2317e-01, 3.5405e-04, 5.5176e-01,\n","         3.6888e-03, 1.0864e-01, 5.6922e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5853], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2705, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1711, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   8%|▊         | 11/144 [00:11<02:11,  1.01it/s, Loss_pi=2.16e+00, Loss_v=2.50e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0417, 0.1667, 0.1250, 0.0833, 0.0000, 0.0833, 0.0000, 0.4167, 0.0833]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.1887e-01, 4.7607e-03, 1.2671e-01, 3.2139e-04, 5.3320e-01,\n","         3.1967e-03, 1.1176e-01, 5.7638e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5884], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1847, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1686, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   8%|▊         | 12/144 [00:12<02:10,  1.01it/s, Loss_pi=2.15e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.2647, 0.2647, 0.0000, 0.0000, 0.3824, 0.0000, 0.0000, 0.0882]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.4902e-01, 5.5885e-03, 1.2140e-01, 3.4642e-04, 5.0293e-01,\n","         3.3379e-03, 1.1584e-01, 6.6102e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5850], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0622, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3410, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   9%|▉         | 13/144 [00:13<02:09,  1.01it/s, Loss_pi=2.15e+00, Loss_v=2.63e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0800, 0.0400, 0.1600, 0.0800, 0.0000, 0.2800, 0.0400, 0.0800, 0.2400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.4695e-01, 4.8904e-03, 1.0956e-01, 3.2258e-04, 5.2295e-01,\n","         3.0613e-03, 1.1133e-01, 5.5611e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5839], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1484, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3398, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  10%|▉         | 14/144 [00:14<02:08,  1.01it/s, Loss_pi=2.15e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.3871, 0.1613, 0.0000, 0.0645, 0.0000, 0.0000, 0.0000, 0.3871]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.6440e-01, 4.7684e-03, 1.0522e-01, 3.0255e-04, 5.1758e-01,\n","         2.7390e-03, 1.0358e-01, 5.5492e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5853], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2196, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1712, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  10%|█         | 15/144 [00:15<02:08,  1.01it/s, Loss_pi=2.15e+00, Loss_v=2.62e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.5333, 0.0000, 0.1000, 0.0000, 0.2333, 0.0333, 0.0667, 0.0333]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.9272e-01, 5.4474e-03, 1.0443e-01, 3.4833e-04, 4.9023e-01,\n","         2.7180e-03, 1.0278e-01, 6.2406e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5805], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0343, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3358, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  11%|█         | 16/144 [00:16<02:07,  1.01it/s, Loss_pi=2.15e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0882, 0.2941, 0.0000, 0.2353, 0.0000, 0.0000, 0.2353, 0.1471, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.9614e-01, 5.4245e-03, 9.7656e-02, 3.3855e-04, 4.9585e-01,\n","         2.7275e-03, 1.0077e-01, 5.9307e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5837], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1974, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1725, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  12%|█▏        | 17/144 [00:17<02:06,  1.01it/s, Loss_pi=2.15e+00, Loss_v=2.52e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.4250, 0.0000, 0.2250, 0.1000, 0.1500, 0.1000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.3765e-01, 5.2872e-03, 9.2285e-02, 3.1519e-04, 4.6875e-01,\n","         2.3651e-03, 9.2285e-02, 6.1095e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5786], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1638, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1768, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  12%|█▎        | 18/144 [00:18<02:05,  1.01it/s, Loss_pi=2.15e+00, Loss_v=2.48e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2353, 0.1471, 0.0000, 0.2353, 0.0000, 0.0000, 0.0882, 0.2941, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 3.5913e-01, 5.3291e-03, 8.8013e-02, 3.1257e-04, 4.4702e-01,\n","         2.3270e-03, 9.6680e-02, 6.2525e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5790], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2198, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1764, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  13%|█▎        | 19/144 [00:19<02:04,  1.01it/s, Loss_pi=2.16e+00, Loss_v=2.45e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2500, 0.2500, 0.1250, 0.0833, 0.0417, 0.0417, 0.0417, 0.0833, 0.0833]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 3.4717e-01, 4.7264e-03, 8.9172e-02, 3.0208e-04, 4.5264e-01,\n","         2.1801e-03, 1.0260e-01, 6.3837e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5786], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1995, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1767, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  14%|█▍        | 20/144 [00:20<02:03,  1.01it/s, Loss_pi=2.16e+00, Loss_v=2.42e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.3871, 0.0645, 0.0000, 0.1613, 0.0000, 0.3871]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.6865e-01, 4.8637e-03, 8.7585e-02, 3.1829e-04, 4.3091e-01,\n","         2.4643e-03, 1.0400e-01, 6.5684e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5724], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2876, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1820, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  15%|█▍        | 21/144 [00:21<02:02,  1.01it/s, Loss_pi=2.16e+00, Loss_v=2.46e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.1667, 0.0417, 0.3750, 0.0417, 0.0417, 0.2500, 0.0833, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 3.7500e-01, 4.5395e-03, 9.0454e-02, 3.1376e-04, 4.1187e-01,\n","         2.3365e-03, 1.1438e-01, 7.0035e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5714], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1971, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3253, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  15%|█▌        | 22/144 [00:22<02:01,  1.00it/s, Loss_pi=2.17e+00, Loss_v=2.43e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0400, 0.0400, 0.0400, 0.1600, 0.0000, 0.0800, 0.0000, 0.4000, 0.2400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 4.4507e-01, 4.8294e-03, 9.7778e-02, 3.1614e-04, 3.5229e-01,\n","         2.1954e-03, 9.6252e-02, 6.6817e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5647], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2213, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1886, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  16%|█▌        | 23/144 [00:23<02:01,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.46e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.2333, 0.0333, 0.5333, 0.0000, 0.0667, 0.0000, 0.1000, 0.0333]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 4.5630e-01, 4.6883e-03, 9.7168e-02, 3.2663e-04, 3.1860e-01,\n","         2.4509e-03, 1.1908e-01, 7.8201e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5668], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1300, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3201, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  17%|█▋        | 24/144 [00:24<02:00,  1.01s/it, Loss_pi=2.16e+00, Loss_v=2.44e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0833, 0.4167, 0.0000, 0.0833, 0.0000, 0.0833, 0.1250, 0.1667, 0.0417]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 4.4751e-01, 4.8180e-03, 1.0968e-01, 3.6883e-04, 3.0762e-01,\n","         2.5387e-03, 1.2622e-01, 8.2254e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5645], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0782, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1888, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  17%|█▋        | 25/144 [00:25<01:59,  1.01s/it, Loss_pi=2.16e+00, Loss_v=2.42e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1000, 0.4250, 0.0000, 0.1500, 0.0000, 0.0000, 0.1000, 0.2250, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 4.9365e-01, 4.6158e-03, 1.1188e-01, 3.3188e-04, 2.7246e-01,\n","         2.3956e-03, 1.1365e-01, 7.1228e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5575], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0699, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1949, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  18%|█▊        | 26/144 [00:26<01:59,  1.01s/it, Loss_pi=2.16e+00, Loss_v=2.45e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.3235, 0.2059, 0.0000, 0.0000, 0.0588, 0.0000, 0.1176, 0.2941, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 5.2539e-01, 4.7989e-03, 1.1359e-01, 3.5596e-04, 2.2949e-01,\n","         2.5692e-03, 1.2280e-01, 8.8632e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5645], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1785, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3175, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  19%|█▉        | 27/144 [00:27<01:57,  1.01s/it, Loss_pi=2.16e+00, Loss_v=2.43e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1333, 0.1000, 0.0333, 0.0667, 0.0000, 0.1333, 0.2000, 0.3333, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 5.7080e-01, 4.1885e-03, 1.1066e-01, 3.0112e-04, 2.0032e-01,\n","         2.1915e-03, 1.1066e-01, 6.7711e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5558], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1972, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1964, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  19%|█▉        | 28/144 [00:28<01:56,  1.00s/it, Loss_pi=2.16e+00, Loss_v=2.45e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0417, 0.0417, 0.0833, 0.0417, 0.1667, 0.2500, 0.3750, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 5.7275e-01, 3.5686e-03, 1.1816e-01, 2.7728e-04, 1.8018e-01,\n","         2.0008e-03, 1.2195e-01, 7.2360e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5522], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2153, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3038, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  20%|██        | 29/144 [00:29<02:02,  1.07s/it, Loss_pi=2.17e+00, Loss_v=2.44e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2619, 0.0000, 0.0000, 0.4286, 0.0000, 0.0000, 0.3095, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 5.8838e-01, 4.0894e-03, 1.1951e-01, 3.3045e-04, 1.6333e-01,\n","         2.2755e-03, 1.2140e-01, 6.8724e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5484], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2745, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2031, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  21%|██        | 30/144 [00:30<01:59,  1.05s/it, Loss_pi=2.17e+00, Loss_v=2.43e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.2941, 0.0000, 0.1471, 0.0882, 0.2353, 0.2353]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 5.8691e-01, 3.8643e-03, 1.3306e-01, 3.4022e-04, 1.3721e-01,\n","         2.2888e-03, 1.3513e-01, 8.6725e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5500], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2351, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2016, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  22%|██▏       | 31/144 [00:31<01:56,  1.03s/it, Loss_pi=2.17e+00, Loss_v=2.41e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0833, 0.0833, 0.0417, 0.0417, 0.0417, 0.0833, 0.1250, 0.2500, 0.2500]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 5.3516e-01, 3.7518e-03, 1.4636e-01, 3.7718e-04, 1.4185e-01,\n","         2.5978e-03, 1.6846e-01, 9.5367e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5455], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2177, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2057, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  22%|██▏       | 32/144 [00:32<01:54,  1.03s/it, Loss_pi=2.17e+00, Loss_v=2.40e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.3871, 0.0645, 0.0000, 0.1613, 0.0000, 0.3871]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 5.2930e-01, 3.5667e-03, 1.4697e-01, 3.5310e-04, 1.3599e-01,\n","         2.6722e-03, 1.8005e-01, 9.0003e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5613], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2652, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1916, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  23%|██▎       | 33/144 [00:33<01:52,  1.02s/it, Loss_pi=2.17e+00, Loss_v=2.38e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0400, 0.0800, 0.2400, 0.0400, 0.0000, 0.4000, 0.0400, 0.1600, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 5.4004e-01, 3.8433e-03, 1.5710e-01, 3.6311e-04, 1.1682e-01,\n","         2.6207e-03, 1.7810e-01, 8.6904e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5679], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1979, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1859, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  24%|██▎       | 34/144 [00:34<01:51,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.41e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0800, 0.0800, 0.0400, 0.0400, 0.0000, 0.0800, 0.1600, 0.2800, 0.2400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 5.1172e-01, 3.3436e-03, 1.6113e-01, 3.2592e-04, 1.1603e-01,\n","         2.6455e-03, 2.0361e-01, 8.3685e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5760], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2083, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3306, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  24%|██▍       | 35/144 [00:35<01:50,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.44e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5455, 0.1212, 0.2121, 0.1212]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 4.3872e-01, 3.1452e-03, 1.8567e-01, 3.3164e-04, 1.2964e-01,\n","         2.8210e-03, 2.3853e-01, 7.6354e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5977], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1973, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3561, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  25%|██▌       | 36/144 [00:36<01:48,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.47e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.1765, 0.0588, 0.0000, 0.0294, 0.2647, 0.1471, 0.1176, 0.2059]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 3.7891e-01, 3.3817e-03, 1.8457e-01, 4.1676e-04, 1.3293e-01,\n","         3.5172e-03, 2.9492e-01, 1.1843e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5945], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1808, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3523, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  26%|██▌       | 37/144 [00:37<01:47,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.45e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.3095, 0.0000, 0.0000, 0.4286, 0.0000, 0.0000, 0.2619, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.5522e-01, 2.9793e-03, 2.0557e-01, 3.5310e-04, 1.4136e-01,\n","         3.2463e-03, 2.9004e-01, 9.4295e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5957], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2286, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1626, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  26%|██▋       | 38/144 [00:38<01:46,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.43e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2400, 0.0800, 0.0400, 0.4000, 0.0000, 0.0400, 0.0000, 0.1600, 0.0400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.0688e-01, 2.8477e-03, 2.1423e-01, 3.5381e-04, 1.4954e-01,\n","         3.4084e-03, 3.2153e-01, 8.7380e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6045], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1493, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1557, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  27%|██▋       | 39/144 [00:39<01:46,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.40e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.1379, 0.2069, 0.0000, 0.0345, 0.3448, 0.0000, 0.2069, 0.0690]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.6343e-01, 2.7924e-03, 2.4353e-01, 3.7193e-04, 1.5723e-01,\n","         3.6125e-03, 3.2764e-01, 9.3281e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6113], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1581, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1503, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  28%|██▊       | 40/144 [00:40<01:45,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.43e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.2941, 0.2059, 0.0000, 0.1176, 0.0588, 0.1471, 0.1765]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.5366e-01, 2.8191e-03, 2.6587e-01, 3.8743e-04, 1.6125e-01,\n","         3.6182e-03, 3.1079e-01, 8.7142e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6098], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1962, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3706, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  28%|██▊       | 41/144 [00:41<01:44,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.41e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1892, 0.6216, 0.0000, 0.0000, 0.0000, 0.0000, 0.1892, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 1.9763e-01, 2.8191e-03, 2.7002e-01, 4.1246e-04, 1.7163e-01,\n","         4.1008e-03, 3.5229e-01, 9.3460e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6134], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1930, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1487, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  29%|██▉       | 42/144 [00:42<01:43,  1.02s/it, Loss_pi=2.18e+00, Loss_v=2.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1613, 0.0000, 0.3871, 0.3871, 0.0645, 0.0000, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 1.9678e-01, 2.8515e-03, 2.7319e-01, 3.9816e-04, 1.7639e-01,\n","         3.9253e-03, 3.4521e-01, 8.8155e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6142], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2098, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1481, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  30%|██▉       | 43/144 [00:43<01:42,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.37e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.1600, 0.0400, 0.4000, 0.0000, 0.0400, 0.2400, 0.0800, 0.0400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 1.5381e-01, 2.3346e-03, 2.6172e-01, 3.4976e-04, 1.7163e-01,\n","         3.9406e-03, 4.0527e-01, 8.9169e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6231], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1487, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1413, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  31%|███       | 44/144 [00:44<01:40,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.40e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0800, 0.0800, 0.0400, 0.0400, 0.0000, 0.0800, 0.1600, 0.2800, 0.2400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 1.5308e-01, 2.5921e-03, 2.8589e-01, 3.7932e-04, 1.6809e-01,\n","         3.9215e-03, 3.8477e-01, 8.4639e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6195], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1727, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3826, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  31%|███▏      | 45/144 [00:45<01:39,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.38e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0882, 0.2941, 0.0000, 0.2353, 0.0000, 0.0000, 0.2353, 0.1471, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 1.4099e-01, 2.9488e-03, 3.1274e-01, 4.8137e-04, 1.5979e-01,\n","         4.6043e-03, 3.7720e-01, 1.0997e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6328], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1471, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1341, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  32%|███▏      | 46/144 [00:46<01:38,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.36e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.3871, 0.0000, 0.1613, 0.0000, 0.0645, 0.3871, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 1.2292e-01, 2.5501e-03, 3.2373e-01, 3.7026e-04, 1.4832e-01,\n","         4.1389e-03, 3.9673e-01, 9.5844e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6286], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2606, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1372, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  33%|███▎      | 47/144 [00:47<01:37,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.2647, 0.0000, 0.0000, 0.2647, 0.3824, 0.0882]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 9.9487e-02, 2.6932e-03, 3.5840e-01, 4.6086e-04, 1.5173e-01,\n","         4.6539e-03, 3.8135e-01, 9.0718e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6307], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0776, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3965, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  33%|███▎      | 48/144 [00:48<01:36,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.42e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0333, 0.1000, 0.0000, 0.0667, 0.0000, 0.5333, 0.0333, 0.2333, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 8.4717e-02, 2.2926e-03, 3.3496e-01, 3.6836e-04, 1.4185e-01,\n","         4.4174e-03, 4.3018e-01, 9.1016e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6409], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1142, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.4094, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  34%|███▍      | 49/144 [00:49<01:35,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.40e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1892, 0.0000, 0.1892, 0.0000, 0.0000, 0.6216, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 8.1726e-02, 2.5673e-03, 3.8379e-01, 3.8743e-04, 1.4795e-01,\n","         4.2305e-03, 3.7793e-01, 8.1837e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6312], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2277, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1353, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  35%|███▍      | 50/144 [00:50<01:34,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.38e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2069, 0.3448, 0.0690, 0.1379, 0.0345, 0.2069, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 6.5369e-02, 2.1172e-03, 3.6475e-01, 3.1233e-04, 1.6174e-01,\n","         3.9864e-03, 4.0039e-01, 7.4208e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6328], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2142, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1341, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  35%|███▌      | 51/144 [00:51<01:33,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.36e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.3095, 0.0000, 0.0000, 0.4286, 0.0000, 0.0000, 0.2619, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 5.3833e-02, 2.0714e-03, 3.7964e-01, 3.3283e-04, 1.7932e-01,\n","         4.1847e-03, 3.7964e-01, 7.5459e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6312], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1569, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1353, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  36%|███▌      | 52/144 [00:52<01:32,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.34e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2069, 0.1379, 0.0000, 0.3448, 0.0345, 0.0000, 0.0690, 0.2069, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 4.6783e-02, 2.2049e-03, 3.9185e-01, 3.7432e-04, 1.7932e-01,\n","         4.5242e-03, 3.7378e-01, 8.3566e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6330], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1014, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1340, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  37%|███▋      | 53/144 [00:53<01:32,  1.02s/it, Loss_pi=2.17e+00, Loss_v=2.32e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.4250, 0.1000, 0.0000, 0.0000, 0.1500, 0.0000, 0.2250, 0.1000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 4.4495e-02, 1.9703e-03, 3.9038e-01, 3.0684e-04, 1.7322e-01,\n","         4.0741e-03, 3.8428e-01, 6.6340e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6282], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1897, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1375, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  38%|███▊      | 54/144 [00:54<01:31,  1.02s/it, Loss_pi=2.17e+00, Loss_v=2.31e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.2250, 0.0000, 0.4250, 0.1000, 0.1500, 0.1000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.5736e-02, 2.0809e-03, 3.9038e-01, 3.7885e-04, 1.8152e-01,\n","         4.5776e-03, 3.8428e-01, 8.2552e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6339], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0983, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1333, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  38%|███▊      | 55/144 [00:55<01:30,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.29e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1250, 0.0833, 0.0833, 0.1667, 0.0000, 0.4167, 0.0417, 0.0833, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.9739e-02, 1.7862e-03, 3.7964e-01, 3.3045e-04, 1.8506e-01,\n","         4.2191e-03, 3.9795e-01, 6.7651e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6391], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1453, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1295, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  39%|███▉      | 56/144 [00:56<01:29,  1.02s/it, Loss_pi=2.17e+00, Loss_v=2.32e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.3750, 0.2500, 0.1667, 0.0417, 0.0833, 0.0417, 0.0417, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.9602e-02, 1.6184e-03, 3.5498e-01, 2.8348e-04, 1.8701e-01,\n","         3.7918e-03, 4.2163e-01, 6.8367e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6467], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2182, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.4169, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  40%|███▉      | 57/144 [00:57<01:28,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.30e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0882, 0.2353, 0.2353, 0.2941, 0.0000, 0.1471, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.9663e-02, 1.7681e-03, 3.5034e-01, 3.1686e-04, 2.0923e-01,\n","         4.2725e-03, 4.0332e-01, 7.1287e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6440], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1794, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1260, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  40%|████      | 58/144 [00:58<01:26,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.29e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.3095, 0.0000, 0.0000, 0.4286, 0.0000, 0.0000, 0.2619, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.9495e-02, 1.8711e-03, 3.7646e-01, 3.2520e-04, 2.2131e-01,\n","         4.1847e-03, 3.6499e-01, 7.0333e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6443], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1582, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1258, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  41%|████      | 59/144 [00:59<01:25,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.27e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.1892, 0.0000, 0.0000, 0.0000, 0.0000, 0.6216, 0.1892]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.4414e-02, 1.8673e-03, 3.9404e-01, 3.4547e-04, 2.2095e-01,\n","         4.2419e-03, 3.5303e-01, 6.4433e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6467], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1008, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1241, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  42%|████▏     | 60/144 [01:00<01:24,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.25e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2069, 0.1379, 0.0000, 0.3448, 0.0345, 0.0000, 0.0690, 0.2069, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.1606e-02, 1.4706e-03, 3.7720e-01, 2.7204e-04, 2.1155e-01,\n","         3.7556e-03, 3.8306e-01, 6.0201e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6520], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1086, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1204, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  42%|████▏     | 61/144 [01:01<01:23,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.23e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.3095, 0.0000, 0.0000, 0.4286, 0.0000, 0.0000, 0.2619]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 1.9424e-02, 1.4744e-03, 3.7793e-01, 2.8133e-04, 2.0557e-01,\n","         4.0092e-03, 3.9014e-01, 6.1810e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6544], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2329, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1187, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  43%|████▎     | 62/144 [01:02<01:22,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.22e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.3871, 0.0000, 0.0000, 0.0000, 0.0645, 0.0000, 0.1613, 0.3871, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 1.8234e-02, 1.6184e-03, 3.6060e-01, 3.1137e-04, 1.9910e-01,\n","         4.0054e-03, 4.1504e-01, 6.8903e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6689], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1606, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1090, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  44%|████▍     | 63/144 [01:03<01:21,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.20e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0400, 0.0800, 0.2400, 0.0400, 0.0000, 0.4000, 0.0400, 0.1600, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 1.4626e-02, 1.4038e-03, 3.3276e-01, 2.6584e-04, 1.8384e-01,\n","         3.7556e-03, 4.6216e-01, 5.7042e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6827], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1604, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1000, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  44%|████▍     | 64/144 [01:04<01:20,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.24e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0882, 0.0000, 0.0000, 0.3824, 0.0000, 0.0000, 0.2647, 0.2647, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 1.4259e-02, 1.6632e-03, 3.2446e-01, 3.2759e-04, 1.8201e-01,\n","         4.0855e-03, 4.7217e-01, 7.9632e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7006], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0728, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.4895, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  45%|████▌     | 65/144 [01:05<01:19,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.22e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.2941, 0.0882, 0.0000, 0.0000, 0.2353, 0.0000, 0.1471, 0.2353]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 1.0071e-02, 1.3952e-03, 2.8540e-01, 2.7061e-04, 1.7310e-01,\n","         3.8242e-03, 5.2490e-01, 7.2837e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7065], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2038, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.0856, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  46%|████▌     | 66/144 [01:06<01:18,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.26e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0588, 0.2647, 0.2059, 0.1765, 0.0294, 0.1176, 0.0000, 0.0000, 0.1471]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 8.1635e-03, 1.3018e-03, 2.7026e-01, 2.6870e-04, 1.6919e-01,\n","         3.6793e-03, 5.4590e-01, 6.2346e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7124], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2558, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.5061, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  47%|████▋     | 67/144 [01:08<01:17,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.30e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1471, 0.1176, 0.2059, 0.0000, 0.0294, 0.2647, 0.0000, 0.1765, 0.0588]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 7.1602e-03, 1.4668e-03, 2.8613e-01, 3.2473e-04, 1.8188e-01,\n","         4.0817e-03, 5.1807e-01, 7.0751e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7089], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1837, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.5011, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  47%|████▋     | 68/144 [01:09<01:16,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.34e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.3235, 0.2059, 0.0000, 0.0000, 0.0588, 0.0000, 0.1176, 0.2941, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 6.4583e-03, 1.3647e-03, 2.5806e-01, 2.7943e-04, 1.8298e-01,\n","         3.9177e-03, 5.4590e-01, 7.8797e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7114], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1633, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.5047, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  48%|████▊     | 69/144 [01:10<01:19,  1.07s/it, Loss_pi=2.17e+00, Loss_v=2.32e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0833, 0.0833, 0.0417, 0.0417, 0.0417, 0.0833, 0.1250, 0.2500, 0.2500]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 5.1804e-03, 1.1930e-03, 2.7417e-01, 2.6822e-04, 2.1021e-01,\n","         3.5610e-03, 5.0439e-01, 6.5744e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7006], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1679, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.0891, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  49%|████▊     | 70/144 [01:11<01:17,  1.04s/it, Loss_pi=2.17e+00, Loss_v=2.30e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.2250, 0.1000, 0.0000, 0.0000, 0.1500, 0.0000, 0.4250, 0.1000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 5.1689e-03, 1.3914e-03, 2.7368e-01, 3.0565e-04, 2.2681e-01,\n","         3.8414e-03, 4.8779e-01, 7.7307e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6931], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0807, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.0936, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  49%|████▉     | 71/144 [01:12<01:15,  1.03s/it, Loss_pi=2.17e+00, Loss_v=2.34e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1212, 0.2121, 0.1212, 0.5455, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 4.6272e-03, 1.2846e-03, 2.3730e-01, 2.6917e-04, 2.3364e-01,\n","         3.7174e-03, 5.1807e-01, 6.9678e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7042], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1942, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.4944, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  50%|█████     | 72/144 [01:13<01:13,  1.02s/it, Loss_pi=2.17e+00, Loss_v=2.37e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2400, 0.2800, 0.1600, 0.0800, 0.0000, 0.0400, 0.0400, 0.0800, 0.0800]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 3.5133e-03, 1.1587e-03, 2.3877e-01, 2.5654e-04, 2.4634e-01,\n","         3.4599e-03, 5.0537e-01, 5.5075e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6955], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2533, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.4824, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  51%|█████     | 73/144 [01:14<01:11,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.40e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2647, 0.0882, 0.3824, 0.2647]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.6583e-03, 1.3561e-03, 2.6245e-01, 3.0971e-04, 2.6660e-01,\n","         3.7441e-03, 4.6069e-01, 6.6996e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6838], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0754, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.4663, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  51%|█████▏    | 74/144 [01:15<01:10,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.38e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0417, 0.1667, 0.1250, 0.0833, 0.0000, 0.0833, 0.0000, 0.4167, 0.0833]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.9793e-03, 1.2035e-03, 2.4036e-01, 2.7490e-04, 2.7246e-01,\n","         3.5381e-03, 4.7803e-01, 6.7413e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6765], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0803, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1040, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  52%|█████▏    | 75/144 [01:16<01:09,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.41e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2400, 0.2800, 0.1600, 0.0800, 0.0000, 0.0400, 0.0400, 0.0800, 0.0800]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.1147e-03, 1.2980e-03, 2.5122e-01, 2.7847e-04, 2.8467e-01,\n","         3.3665e-03, 4.5508e-01, 6.1691e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6685], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2527, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.4455, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  53%|█████▎    | 76/144 [01:17<01:07,  1.00it/s, Loss_pi=2.17e+00, Loss_v=2.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1250, 0.2500, 0.2500, 0.0417, 0.0417, 0.0833, 0.0833, 0.0833, 0.0417]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.7828e-03, 1.2836e-03, 2.5439e-01, 2.7347e-04, 2.9736e-01,\n","         3.1528e-03, 4.3970e-01, 6.6996e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6617], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2485, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1138, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  53%|█████▎    | 77/144 [01:18<01:07,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.38e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1000, 0.1500, 0.1000, 0.4250, 0.0000, 0.2250, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.7180e-03, 1.2150e-03, 2.4841e-01, 2.5868e-04, 3.1421e-01,\n","         2.9621e-03, 4.2920e-01, 5.8651e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6595], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1453, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1152, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  54%|█████▍    | 78/144 [01:19<01:06,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.36e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0400, 0.1600, 0.0000, 0.0400, 0.0000, 0.4000, 0.0400, 0.0800, 0.2400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.3308e-03, 1.1272e-03, 2.4719e-01, 2.3806e-04, 3.3789e-01,\n","         2.7885e-03, 4.0747e-01, 5.4777e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6528], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1434, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1198, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  55%|█████▍    | 79/144 [01:20<01:05,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.35e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.1379, 0.0345, 0.2069, 0.2069, 0.3448, 0.0690]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.9464e-03, 1.0176e-03, 2.3389e-01, 2.1660e-04, 3.8574e-01,\n","         2.5978e-03, 3.7378e-01, 5.2273e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6443], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0801, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1258, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  56%|█████▌    | 80/144 [01:21<01:04,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.34e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.2250, 0.1000, 0.0000, 0.0000, 0.1500, 0.0000, 0.4250, 0.1000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.8101e-03, 1.0147e-03, 2.2974e-01, 2.0301e-04, 3.9697e-01,\n","         2.3232e-03, 3.6719e-01, 5.0545e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6421], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1060, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1274, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  56%|█████▋    | 81/144 [01:22<01:03,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.36e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.2941, 0.1176, 0.0000, 0.0588, 0.0000, 0.0000, 0.2059, 0.3235]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.8129e-03, 1.0824e-03, 2.1631e-01, 2.3782e-04, 3.9160e-01,\n","         2.6188e-03, 3.8550e-01, 5.5611e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6459], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2420, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.4160, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  57%|█████▋    | 82/144 [01:23<01:02,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.34e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.2069, 0.0345, 0.1379, 0.0690, 0.3448, 0.2069]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 1.9722e-03, 1.3037e-03, 2.1082e-01, 3.0494e-04, 3.9380e-01,\n","         2.8915e-03, 3.8770e-01, 7.7069e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6476], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0904, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1235, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  58%|█████▊    | 83/144 [01:24<01:01,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.33e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0417, 0.0833, 0.2500, 0.0833, 0.0417, 0.2500, 0.0833, 0.0417, 0.1250]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.7910e-03, 1.0948e-03, 1.9446e-01, 2.2078e-04, 3.8086e-01,\n","         2.2640e-03, 4.1821e-01, 6.1274e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6509], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1932, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1211, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  58%|█████▊    | 84/144 [01:25<00:59,  1.00it/s, Loss_pi=2.17e+00, Loss_v=2.32e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0400, 0.0400, 0.0400, 0.1600, 0.0000, 0.0800, 0.0000, 0.4000, 0.2400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.5774e-03, 9.8705e-04, 1.6223e-01, 2.0373e-04, 3.7720e-01,\n","         2.1057e-03, 4.5483e-01, 5.2333e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6550], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0859, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1183, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  59%|█████▉    | 85/144 [01:26<00:59,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.34e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0417, 0.0417, 0.0000, 0.1667, 0.0417, 0.0833, 0.0000, 0.3750, 0.2500]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.4830e-03, 9.6512e-04, 1.4551e-01, 1.9920e-04, 3.4912e-01,\n","         1.9341e-03, 5.0000e-01, 5.1141e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6618], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0839, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.4367, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  60%|█████▉    | 86/144 [01:27<00:58,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.33e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.4000, 0.2400, 0.1600, 0.0000, 0.0800, 0.0400, 0.0400, 0.0400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 1.6680e-03, 1.1377e-03, 1.3879e-01, 2.4402e-04, 3.2275e-01,\n","         2.1248e-03, 5.3223e-01, 6.6221e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6696], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2556, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1085, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  60%|██████    | 87/144 [01:28<00:56,  1.00it/s, Loss_pi=2.17e+00, Loss_v=2.31e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.6216, 0.1892, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1892]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 1.7548e-03, 1.1692e-03, 1.2793e-01, 2.1958e-04, 2.9272e-01,\n","         1.9274e-03, 5.7324e-01, 6.1929e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6895], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3265, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.0958, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  61%|██████    | 88/144 [01:29<00:56,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.30e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.3871, 0.0000, 0.0000, 0.0000, 0.0645, 0.0000, 0.1613, 0.3871, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.5354e-03, 1.0548e-03, 1.0114e-01, 2.2471e-04, 2.5415e-01,\n","         1.9569e-03, 6.3916e-01, 6.2406e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7032], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0841, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.0875, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  62%|██████▏   | 89/144 [01:30<00:55,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.28e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.3333, 0.2000, 0.1333, 0.0000, 0.0667, 0.0333, 0.1000, 0.1333]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.3819e-03, 9.4986e-04, 8.2214e-02, 1.9610e-04, 2.1338e-01,\n","         1.6289e-03, 6.9922e-01, 6.2644e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7173], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2402, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.0794, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  62%|██████▎   | 90/144 [01:31<00:54,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.31e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1765, 0.1471, 0.0588, 0.1176, 0.0000, 0.2059, 0.2941, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.5392e-03, 9.5558e-04, 6.4453e-02, 1.8239e-04, 1.6980e-01,\n","         1.5516e-03, 7.6074e-01, 5.6922e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7339], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2983, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.5371, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  63%|██████▎   | 91/144 [01:32<00:53,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.29e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.3871, 0.0000, 0.0645, 0.0000, 0.0000, 0.3871, 0.1613]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.2560e-03, 8.3637e-04, 5.8624e-02, 1.7393e-04, 1.6443e-01,\n","         1.4915e-03, 7.7246e-01, 5.6922e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7441], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0432, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.0650, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  64%|██████▍   | 92/144 [01:33<00:52,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.33e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.3235, 0.2059, 0.0000, 0.0000, 0.0588, 0.0000, 0.1176, 0.2941, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.1921e-03, 7.8154e-04, 5.1483e-02, 1.5879e-04, 1.5137e-01,\n","         1.3828e-03, 7.9297e-01, 4.4465e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7483], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1108, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.5584, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  65%|██████▍   | 93/144 [01:34<00:51,  1.02s/it, Loss_pi=2.17e+00, Loss_v=2.31e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1892, 0.6216, 0.0000, 0.0000, 0.0000, 0.0000, 0.1892, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.1692e-03, 7.6056e-04, 4.5258e-02, 1.6189e-04, 1.4844e-01,\n","         1.3990e-03, 8.0225e-01, 5.3406e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7525], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3441, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.0608, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  65%|██████▌   | 94/144 [01:35<00:50,  1.02s/it, Loss_pi=2.17e+00, Loss_v=2.35e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2941, 0.1176, 0.1765, 0.0000, 0.0000, 0.1471, 0.0000, 0.2059, 0.0588]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.4057e-03, 8.5926e-04, 4.4403e-02, 1.7452e-04, 1.3892e-01,\n","         1.3943e-03, 8.1201e-01, 5.1975e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7561], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1582, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.5701, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  66%|██████▌   | 95/144 [01:36<00:49,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.38e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.2333, 0.0333, 0.5333, 0.0000, 0.0667, 0.0000, 0.1000, 0.0333]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.1177e-03, 6.8855e-04, 3.4485e-02, 1.3244e-04, 1.2610e-01,\n","         1.1711e-03, 8.3545e-01, 4.3333e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7561], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2383, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.5702, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  67%|██████▋   | 96/144 [01:37<00:48,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.36e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.1892, 0.0000, 0.0000, 0.0000, 0.0000, 0.6216, 0.1892]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.4038e-03, 8.9264e-04, 4.1351e-02, 1.7846e-04, 1.4893e-01,\n","         1.4486e-03, 8.0518e-01, 5.4896e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7553], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(1.8455, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.0594, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  67%|██████▋   | 97/144 [01:38<00:47,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.40e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1471, 0.1176, 0.2059, 0.0000, 0.0294, 0.2647, 0.0000, 0.1765, 0.0588]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.1263e-03, 7.2145e-04, 3.6163e-02, 1.4770e-04, 1.4990e-01,\n","         1.2569e-03, 8.1006e-01, 4.2021e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7470], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1635, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.5566, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  68%|██████▊   | 98/144 [01:39<00:46,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.38e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1250, 0.1667, 0.0417, 0.0833, 0.0000, 0.0833, 0.0833, 0.4167, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.1215e-03, 7.6485e-04, 3.8025e-02, 1.7059e-04, 1.5759e-01,\n","         1.3742e-03, 8.0029e-01, 4.8876e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7368], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(1.9951, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.0688, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  69%|██████▉   | 99/144 [01:40<00:45,  1.02s/it, Loss_pi=2.17e+00, Loss_v=2.41e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0882, 0.3824, 0.2647, 0.0000, 0.0000, 0.2647, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.4629e-03, 9.0122e-04, 3.9856e-02, 1.6928e-04, 1.5515e-01,\n","         1.3533e-03, 8.0029e-01, 5.2035e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7369], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3031, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.5416, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  69%|██████▉   | 100/144 [01:41<00:44,  1.01s/it, Loss_pi=2.16e+00, Loss_v=2.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1892, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1892, 0.6216, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.3361e-03, 8.9025e-04, 3.6407e-02, 1.7262e-04, 1.6833e-01,\n","         1.4343e-03, 7.9053e-01, 5.4300e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7327], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(1.8526, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.0709, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  70%|███████   | 101/144 [01:42<00:43,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.42e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2647, 0.3824, 0.0882, 0.2647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.4334e-03, 8.8310e-04, 3.6102e-02, 1.6081e-04, 1.7505e-01,\n","         1.3571e-03, 7.8418e-01, 4.7922e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7257], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3337, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.5252, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  71%|███████   | 102/144 [01:43<00:42,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.40e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.1600, 0.0400, 0.4000, 0.0000, 0.0400, 0.2400, 0.0800, 0.0400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.3294e-03, 8.1301e-04, 3.5400e-02, 1.4806e-04, 1.7969e-01,\n","         1.2398e-03, 7.8076e-01, 4.2439e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7224], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2592, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.0765, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  72%|███████▏  | 103/144 [01:44<00:41,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.6216, 0.0000, 0.0000, 0.1892, 0.0000, 0.1892]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.5192e-03, 9.8896e-04, 4.0741e-02, 2.0397e-04, 1.9739e-01,\n","         1.5793e-03, 7.5684e-01, 6.3181e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7113], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3159, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.0828, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  72%|███████▏  | 104/144 [01:45<00:40,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.37e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.2941, 0.0882, 0.0000, 0.0000, 0.2353, 0.0000, 0.1471, 0.2353]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.8873e-03, 1.0672e-03, 4.6082e-02, 1.7691e-04, 2.1643e-01,\n","         1.4019e-03, 7.3193e-01, 5.3525e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.7053], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1804, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.0863, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  73%|███████▎  | 105/144 [01:46<00:39,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.36e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0645, 0.3871, 0.3871, 0.0000, 0.1613]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.0695e-03, 1.2074e-03, 5.1361e-02, 2.1482e-04, 2.3376e-01,\n","         1.6508e-03, 7.0898e-01, 7.3671e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6955], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2464, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.0921, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  74%|███████▎  | 106/144 [01:47<00:40,  1.07s/it, Loss_pi=2.17e+00, Loss_v=2.35e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2500, 0.2500, 0.1250, 0.0833, 0.0417, 0.0417, 0.0417, 0.0833, 0.0833]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 1.7414e-03, 9.9182e-04, 5.3345e-02, 1.9538e-04, 2.7075e-01,\n","         1.5488e-03, 6.7041e-01, 5.8651e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6797], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2620, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1019, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  74%|███████▍  | 107/144 [01:48<00:38,  1.05s/it, Loss_pi=2.17e+00, Loss_v=2.37e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2647, 0.0882, 0.3824, 0.2647]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.3327e-03, 1.2779e-03, 6.6040e-02, 2.2912e-04, 3.1030e-01,\n","         1.7738e-03, 6.1719e-01, 6.4611e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6738], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0133, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.4526, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  75%|███████▌  | 108/144 [01:49<00:37,  1.03s/it, Loss_pi=2.17e+00, Loss_v=2.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1765, 0.1471, 0.0588, 0.1176, 0.0000, 0.2059, 0.2941, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.5043e-03, 1.2894e-03, 6.8237e-02, 2.2399e-04, 3.3569e-01,\n","         1.7900e-03, 5.8936e-01, 6.5207e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6609], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2519, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.4355, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  76%|███████▌  | 109/144 [01:50<00:35,  1.02s/it, Loss_pi=2.17e+00, Loss_v=2.38e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.3871, 0.0645, 0.0000, 0.1613, 0.0000, 0.3871]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.2507e-03, 1.2426e-03, 7.0557e-02, 2.1768e-04, 3.9355e-01,\n","         1.8082e-03, 5.2930e-01, 6.6876e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6524], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3006, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1201, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  76%|███████▋  | 110/144 [01:51<00:34,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.37e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.1471, 0.0000, 0.2941, 0.2353, 0.2353, 0.0882]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.6188e-03, 1.4353e-03, 8.2764e-02, 2.7609e-04, 4.3359e-01,\n","         2.0714e-03, 4.7607e-01, 7.5459e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6416], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0745, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1278, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  77%|███████▋  | 111/144 [01:52<00:33,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.36e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.4000, 0.2400, 0.1600, 0.0000, 0.0800, 0.0400, 0.0400, 0.0400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.6531e-03, 1.4887e-03, 9.0637e-02, 2.8419e-04, 4.8242e-01,\n","         2.1820e-03, 4.1919e-01, 7.7665e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6314], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2551, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1351, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  78%|███████▊  | 112/144 [01:53<00:32,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.37e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2500, 0.0833, 0.0000, 0.3750, 0.0417, 0.0417, 0.0000, 0.1667, 0.0417]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-08, 2.2488e-03, 1.1854e-03, 8.9844e-02, 2.2447e-04, 5.2539e-01,\n","         1.9245e-03, 3.7842e-01, 6.4790e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6261], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2089, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3908, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  78%|███████▊  | 113/144 [01:54<00:31,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.38e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0882, 0.0000, 0.0000, 0.3824, 0.0000, 0.0000, 0.2647, 0.2647, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.0155e-03, 1.5640e-03, 1.1230e-01, 2.7823e-04, 5.8838e-01,\n","         2.2411e-03, 2.9126e-01, 7.4327e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6190], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2080, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3820, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  79%|███████▉  | 114/144 [01:55<00:30,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.38e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2400, 0.4000, 0.0000, 0.0800, 0.0000, 0.1600, 0.0400, 0.0400, 0.0400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 2.9926e-03, 1.5163e-03, 1.3232e-01, 2.6560e-04, 5.8398e-01,\n","         2.1896e-03, 2.7588e-01, 7.4923e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6132], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2122, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1488, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  80%|███████▉  | 115/144 [01:56<00:29,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.5333, 0.0000, 0.1000, 0.0000, 0.2333, 0.0333, 0.0667, 0.0333]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.0346e-03, 1.4677e-03, 1.4624e-01, 2.6941e-04, 5.9668e-01,\n","         2.3632e-03, 2.4878e-01, 8.2135e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6111], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1566, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3722, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  81%|████████  | 116/144 [01:57<00:28,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.40e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.2333, 0.0333, 0.5333, 0.0000, 0.0667, 0.0000, 0.1000, 0.0333]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.2024e-03, 1.5974e-03, 1.7346e-01, 2.9540e-04, 6.2451e-01,\n","         2.4357e-03, 1.9348e-01, 7.8321e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6031], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1754, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3625, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  81%|████████▏ | 117/144 [01:58<00:27,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.2941, 0.0882, 0.0000, 0.0000, 0.2353, 0.0000, 0.1471, 0.2353]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.6488e-03, 1.5821e-03, 2.1216e-01, 2.7061e-04, 6.1377e-01,\n","         2.3022e-03, 1.6516e-01, 8.4519e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.6018], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1598, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1578, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  82%|████████▏ | 118/144 [01:59<00:26,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.40e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1471, 0.1176, 0.2059, 0.0000, 0.0294, 0.2647, 0.0000, 0.1765, 0.0588]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.6983e-03, 1.6546e-03, 2.3987e-01, 3.0589e-04, 6.1230e-01,\n","         2.3880e-03, 1.3879e-01, 7.3254e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5973], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1424, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3556, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  83%|████████▎ | 119/144 [02:00<00:25,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0833, 0.0417, 0.1250, 0.0833, 0.0417, 0.2500, 0.0417, 0.0833, 0.2500]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 3.5820e-03, 1.5287e-03, 2.4719e-01, 3.0565e-04, 6.2158e-01,\n","         2.4433e-03, 1.2238e-01, 8.5533e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5949], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1436, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1633, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  83%|████████▎ | 120/144 [02:01<00:24,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0417, 0.0833, 0.2500, 0.0833, 0.0417, 0.2500, 0.0833, 0.0417, 0.1250]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 4.6616e-03, 1.7691e-03, 2.6050e-01, 3.1233e-04, 6.3477e-01,\n","         2.3994e-03, 9.4360e-02, 9.7513e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5925], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1460, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1652, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  84%|████████▍ | 121/144 [02:02<00:23,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.38e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1892, 0.0000, 0.1892, 0.6216, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 4.3411e-03, 1.5593e-03, 2.5415e-01, 2.7323e-04, 6.8018e-01,\n","         2.2526e-03, 5.5847e-02, 8.0764e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5913], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1765, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1662, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  85%|████████▍ | 122/144 [02:03<00:22,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.38e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1892, 0.6216, 0.0000, 0.0000, 0.0000, 0.0000, 0.1892, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 4.5776e-03, 1.6451e-03, 2.9004e-01, 2.8372e-04, 6.6406e-01,\n","         2.2850e-03, 3.6285e-02, 7.1704e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5884], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3312, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1686, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  85%|████████▌ | 123/144 [02:04<00:21,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0333, 0.0667, 0.0333, 0.2333, 0.0000, 0.1000, 0.0000, 0.5333, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 5.2643e-03, 1.8339e-03, 3.0127e-01, 3.5262e-04, 6.5820e-01,\n","         2.8172e-03, 2.9358e-02, 1.0186e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5853], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1820, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3414, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  86%|████████▌ | 124/144 [02:05<00:20,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1471, 0.1176, 0.2059, 0.0000, 0.0294, 0.2647, 0.0000, 0.1765, 0.0588]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.1921e-07, 4.9362e-03, 1.6279e-03, 3.4082e-01, 2.8300e-04, 6.2646e-01,\n","         2.3499e-03, 2.2125e-02, 9.1851e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5836], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1621, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3394, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  87%|████████▋ | 125/144 [02:06<00:19,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.40e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1176, 0.2941, 0.0000, 0.0000, 0.0588, 0.0000, 0.3235, 0.2059, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 5.9967e-03, 1.8721e-03, 3.7671e-01, 3.1281e-04, 5.9277e-01,\n","         2.5578e-03, 1.8753e-02, 9.3937e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5812], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3257, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3366, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  88%|████████▊ | 126/144 [02:07<00:18,  1.01s/it, Loss_pi=2.17e+00, Loss_v=2.40e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0690, 0.2069, 0.0000, 0.3448, 0.0345, 0.0000, 0.2069, 0.1379, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 6.9466e-03, 2.0370e-03, 4.3652e-01, 3.2473e-04, 5.3467e-01,\n","         2.4567e-03, 1.5900e-02, 9.4533e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5781], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1758, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1772, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  88%|████████▊ | 127/144 [02:08<00:17,  1.00s/it, Loss_pi=2.17e+00, Loss_v=2.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1613, 0.3871, 0.0000, 0.0000, 0.0645, 0.0000, 0.3871, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 7.2327e-03, 2.0084e-03, 4.9927e-01, 3.2282e-04, 4.7632e-01,\n","         2.3479e-03, 1.1383e-02, 9.1076e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5746], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3263, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1801, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  89%|████████▉ | 128/144 [02:09<00:16,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2000, 0.3333, 0.0000, 0.0667, 0.0000, 0.1333, 0.1333, 0.1000, 0.0333]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 8.3542e-03, 2.1286e-03, 5.3320e-01, 3.3426e-04, 4.4214e-01,\n","         2.5082e-03, 1.0239e-02, 9.7275e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5707], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2319, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1834, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  90%|████████▉ | 129/144 [02:10<00:15,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.38e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.2619, 0.0000, 0.0000, 0.4286, 0.0000, 0.0000, 0.3095]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 8.4763e-03, 2.1591e-03, 5.4932e-01, 3.6359e-04, 4.2798e-01,\n","         2.7294e-03, 7.9575e-03, 1.0669e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5651], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1467, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1882, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  90%|█████████ | 130/144 [02:11<00:14,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.38e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.1471, 0.2353, 0.0000, 0.0000, 0.2353, 0.0000, 0.2941, 0.0882]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 9.7656e-03, 2.1629e-03, 5.4199e-01, 3.4213e-04, 4.3530e-01,\n","         2.7771e-03, 6.7139e-03, 1.1373e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5674], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2242, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1863, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  91%|█████████ | 131/144 [02:12<00:13,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2400, 0.2800, 0.1600, 0.0800, 0.0000, 0.0400, 0.0400, 0.0800, 0.0800]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.3842e-07, 1.0193e-02, 2.3289e-03, 5.2295e-01, 4.0793e-04, 4.5435e-01,\n","         3.1090e-03, 5.6305e-03, 1.0896e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5722], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2665, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3262, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  92%|█████████▏| 132/144 [02:13<00:12,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1471, 0.1176, 0.2059, 0.0000, 0.0294, 0.2647, 0.0000, 0.1765, 0.0588]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 1.0971e-02, 2.1935e-03, 4.9634e-01, 3.6383e-04, 4.8120e-01,\n","         3.0212e-03, 4.6806e-03, 9.7156e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5721], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2007, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3262, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  92%|█████████▏| 133/144 [02:14<00:11,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.3871, 0.0645, 0.0000, 0.1613, 0.0000, 0.3871]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 1.1650e-02, 2.1725e-03, 4.5117e-01, 3.5191e-04, 5.2734e-01,\n","         3.0403e-03, 3.2349e-03, 8.6904e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5760], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1555, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1789, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  93%|█████████▎| 134/144 [02:15<00:10,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0882, 0.0000, 0.0000, 0.3824, 0.0000, 0.2647, 0.2647]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.3842e-07, 1.3199e-02, 2.2945e-03, 4.5825e-01, 3.5453e-04, 5.1904e-01,\n","         3.0384e-03, 2.6207e-03, 1.1069e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5763], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1311, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3310, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  94%|█████████▍| 135/144 [02:16<00:09,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.40e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0400, 0.0800, 0.2400, 0.0800, 0.0000, 0.2800, 0.0800, 0.0400, 0.1600]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.3842e-07, 1.4244e-02, 2.3613e-03, 4.1626e-01, 3.8552e-04, 5.6006e-01,\n","         3.3035e-03, 2.4166e-03, 1.1307e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5777], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1391, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3326, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  94%|█████████▍| 136/144 [02:17<00:08,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.41e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2059, 0.1176, 0.1471, 0.2647, 0.0294, 0.0000, 0.0588, 0.1765, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 1.3710e-02, 2.2202e-03, 3.9453e-01, 3.7694e-04, 5.8301e-01,\n","         3.2558e-03, 1.9293e-03, 9.8348e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5799], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2251, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3351, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  95%|█████████▌| 137/144 [02:18<00:07,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.42e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1600, 0.0400, 0.0800, 0.2800, 0.0000, 0.0800, 0.2400, 0.0800, 0.0400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 1.5137e-02, 2.3384e-03, 3.9038e-01, 3.7599e-04, 5.8594e-01,\n","         3.2215e-03, 1.6079e-03, 1.0198e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5803], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1739, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3356, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  96%|█████████▌| 138/144 [02:19<00:06,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.41e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.1379, 0.2069, 0.0000, 0.0345, 0.3448, 0.0000, 0.2069, 0.0690]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.3842e-07, 1.5945e-02, 2.5215e-03, 4.0479e-01, 3.8671e-04, 5.7080e-01,\n","         3.2883e-03, 1.3494e-03, 1.1981e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5772], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1316, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1779, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  97%|█████████▋| 139/144 [02:20<00:05,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.41e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0645, 0.3871, 0.3871, 0.0000, 0.1613]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.3842e-07, 1.8921e-02, 2.6627e-03, 4.1089e-01, 3.8052e-04, 5.6152e-01,\n","         3.1128e-03, 1.1101e-03, 1.1426e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5774], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1123, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1778, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  97%|█████████▋| 140/144 [02:21<00:04,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.41e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.5455, 0.1212, 0.0000, 0.0000, 0.2121, 0.0000, 0.0000, 0.1212]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 1.6296e-02, 2.2392e-03, 3.6499e-01, 3.0541e-04, 6.1133e-01,\n","         2.8305e-03, 7.8630e-04, 9.6142e-05]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5790], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1938, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3340, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  98%|█████████▊| 141/144 [02:22<00:03,  1.00s/it, Loss_pi=2.18e+00, Loss_v=2.42e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2941, 0.1176, 0.1765, 0.0000, 0.0000, 0.1471, 0.0000, 0.2059, 0.0588]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 1.7090e-02, 2.5406e-03, 3.4326e-01, 3.8052e-04, 6.3135e-01,\n","         3.3398e-03, 8.6451e-04, 1.0651e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5819], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2379, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3375, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  99%|█████████▊| 142/144 [02:23<00:02,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.43e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.2647, 0.0000, 0.0000, 0.2647, 0.3824, 0.0882]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.3842e-07, 1.7441e-02, 2.5311e-03, 2.9956e-01, 3.9434e-04, 6.7480e-01,\n","         3.3283e-03, 7.4816e-04, 1.1384e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5831], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2558, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3388, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  99%|█████████▉| 143/144 [02:25<00:01,  1.07s/it, Loss_pi=2.18e+00, Loss_v=2.42e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.2069, 0.0345, 0.1379, 0.0690, 0.3448, 0.2069]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.3842e-07, 1.9073e-02, 2.7485e-03, 2.8931e-01, 4.3154e-04, 6.8311e-01,\n","         3.4752e-03, 7.4577e-04, 1.1891e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5843], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1817, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1720, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net: 100%|██████████| 144/144 [02:25<00:00,  1.01s/it, Loss_pi=2.18e+00, Loss_v=2.42e-01]\n","Self Play: 100%|██████████| 1/1 [02:39<00:00, 159.18s/it]\n"]},{"name":"stdout","output_type":"stream","text":["[(array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.04, 0.04, 0.04, 0.16, 0.0, 0.08, 0.0, 0.4, 0.24], 0.999), (array([[ 0,  1,  0],\n","       [-1,  0,  1],\n","       [-1, -1,  0]]), [0.3137254901960784, 0.0, 0.0, 0.0, 0.13725490196078433, 0.0, 0.0, 0.0, 0.5490196078431373], 0.001), (array([[ 0,  0, -1],\n","       [ 0,  1,  1],\n","       [ 0,  0, -1]]), [0.08823529411764706, 0.29411764705882354, 0.0, 0.23529411764705882, 0.0, 0.0, 0.23529411764705882, 0.14705882352941177, 0.0], 0.999), (array([[ 1, -1, -1],\n","       [ 1, -1, -1],\n","       [ 0,  1,  0]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024390243902439025, 0.0, 0.975609756097561], 0.001), (array([[ 0,  1,  0],\n","       [ 0,  0, -1],\n","       [ 0, -1,  0]]), [0.0, 0.0, 0.037037037037037035, 0.5925925925925926, 0.0, 0.0, 0.07407407407407407, 0.0, 0.2962962962962963], 0.001), (array([[ 1,  1,  0],\n","       [-1, -1,  1],\n","       [-1, -1,  0]]), [0.0, 0.0, 0.024390243902439025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.975609756097561], 0.001), (array([[ 0,  1,  0],\n","       [ 1,  0, -1],\n","       [ 0, -1,  0]]), [0.6097560975609756, 0.0, 0.0975609756097561, 0.0, 0.07317073170731707, 0.0, 0.21951219512195122, 0.0, 0.0], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.08333333333333333, 0.041666666666666664, 0.125, 0.08333333333333333, 0.041666666666666664, 0.25, 0.041666666666666664, 0.08333333333333333, 0.25], 0.999), (array([[ 0, -1,  0],\n","       [ 0, -1, -1],\n","       [ 0,  1,  1]]), [0.30952380952380953, 0.0, 0.0, 0.42857142857142855, 0.0, 0.0, 0.2619047619047619, 0.0, 0.0], 0.999), (array([[-1,  0,  0],\n","       [ 1,  1,  0],\n","       [-1,  0,  0]]), [0.0, 0.14705882352941177, 0.23529411764705882, 0.0, 0.0, 0.23529411764705882, 0.0, 0.29411764705882354, 0.08823529411764706], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.041666666666666664, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.041666666666666664, 0.041666666666666664, 0.25, 0.25, 0.125], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  0, -1],\n","       [ 0,  0,  0]]), [0.20588235294117646, 0.11764705882352941, 0.14705882352941177, 0.2647058823529412, 0.029411764705882353, 0.0, 0.058823529411764705, 0.17647058823529413, 0.0], 0.001), (array([[-1, -1,  0],\n","       [-1, -1,  1],\n","       [ 1,  1,  0]]), [0.0, 0.0, 0.975609756097561, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024390243902439025], 0.001), (array([[ 0, -1,  0],\n","       [ 0,  0,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.14705882352941177, 0.17647058823529413, 0.029411764705882353, 0.11764705882352941, 0.058823529411764705, 0.2647058823529412, 0.20588235294117646], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.0, 0.125, 0.041666666666666664, 0.375, 0.0, 0.25, 0.041666666666666664, 0.041666666666666664, 0.125], 0.999), (array([[ 0,  0,  0],\n","       [-1,  0,  0],\n","       [ 0,  0,  0]]), [0.03333333333333333, 0.2, 0.0, 0.0, 0.0, 0.4666666666666667, 0.16666666666666666, 0.06666666666666667, 0.06666666666666667], 0.001), (array([[-1,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.5333333333333333, 0.0, 0.1, 0.0, 0.23333333333333334, 0.03333333333333333, 0.06666666666666667, 0.03333333333333333], 0.001), (array([[ 0, -1,  0],\n","       [ 0,  0,  0],\n","       [ 0,  0,  0]]), [0.03333333333333333, 0.0, 0.16666666666666666, 0.2, 0.0, 0.06666666666666667, 0.0, 0.4666666666666667, 0.06666666666666667], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.16, 0.04, 0.4, 0.0, 0.04, 0.24, 0.08, 0.04], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.041666666666666664, 0.041666666666666664, 0.125, 0.375, 0.0, 0.25, 0.0, 0.125, 0.041666666666666664], 0.999), (array([[ 0,  1,  0],\n","       [-1,  0,  0],\n","       [ 0,  0,  0]]), [0.03333333333333333, 0.0, 0.2, 0.0, 0.0, 0.1, 0.0, 0.5666666666666667, 0.1], 0.999), (array([[ 0, -1,  0],\n","       [ 1,  0, -1],\n","       [ 0,  1,  0]]), [0.21951219512195122, 0.0, 0.0, 0.0, 0.07317073170731707, 0.0, 0.6097560975609756, 0.0, 0.0975609756097561], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0, -1]]), [0.13333333333333333, 0.1, 0.03333333333333333, 0.06666666666666667, 0.0, 0.13333333333333333, 0.2, 0.3333333333333333, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  0,  1],\n","       [ 0, -1,  0]]), [0.1, 0.1, 0.2, 0.5666666666666667, 0.0, 0.0, 0.0, 0.0, 0.03333333333333333], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.25, 0.375, 0.0, 0.08333333333333333, 0.041666666666666664, 0.16666666666666666, 0.0, 0.041666666666666664, 0.041666666666666664], 0.001), (array([[ 0, -1,  0],\n","       [-1,  0,  1],\n","       [ 0,  1,  0]]), [0.0, 0.0, 0.0975609756097561, 0.0, 0.07317073170731707, 0.0, 0.21951219512195122, 0.0, 0.6097560975609756], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1, -1],\n","       [ 1, -1,  1]]), [0.2647058823529412, 0.38235294117647056, 0.08823529411764706, 0.2647058823529412, 0.0, 0.0, 0.0, 0.0, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.4, 0.24, 0.16, 0.0, 0.08, 0.04, 0.04, 0.04], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.125, 0.25, 0.25, 0.041666666666666664, 0.041666666666666664, 0.08333333333333333, 0.08333333333333333, 0.08333333333333333, 0.041666666666666664], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.04, 0.08, 0.24, 0.04, 0.0, 0.4, 0.04, 0.16, 0.0], 0.999), (array([[ 0, -1,  0],\n","       [ 0,  0,  1],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.03333333333333333, 0.5666666666666667, 0.0, 0.0, 0.1, 0.1, 0.2], 0.999), (array([[ 1,  1, -1],\n","       [ 1,  1, -1],\n","       [-1, -1,  0]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], 0.999), (array([[-1, -1,  0],\n","       [ 1,  0,  1],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.3870967741935484, 0.0, 0.06451612903225806, 0.0, 0.0, 0.3870967741935484, 0.16129032258064516], 0.999), (array([[ 0, -1,  0],\n","       [ 0,  0,  0],\n","       [ 0,  0,  0]]), [0.14705882352941177, 0.0, 0.0, 0.11764705882352941, 0.029411764705882353, 0.17647058823529413, 0.20588235294117646, 0.2647058823529412, 0.058823529411764705], 0.001), (array([[ 1,  1,  0],\n","       [-1, -1,  0],\n","       [ 0, -1,  0]]), [0.0, 0.0, 0.2619047619047619, 0.0, 0.0, 0.42857142857142855, 0.0, 0.0, 0.30952380952380953], 0.999), (array([[ 0,  0,  1],\n","       [ 0, -1, -1],\n","       [ 0,  0,  0]]), [0.1, 0.225, 0.0, 0.15, 0.0, 0.0, 0.1, 0.425, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  0,  0],\n","       [ 0, -1,  0]]), [0.20588235294117646, 0.2647058823529412, 0.058823529411764705, 0.11764705882352941, 0.029411764705882353, 0.17647058823529413, 0.14705882352941177, 0.0, 0.0], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.041666666666666664, 0.125, 0.0, 0.25, 0.0, 0.375, 0.125, 0.041666666666666664, 0.041666666666666664], 0.999), (array([[ 0,  0,  0],\n","       [-1,  0,  0],\n","       [ 0,  0,  0]]), [0.14705882352941177, 0.11764705882352941, 0.20588235294117646, 0.0, 0.029411764705882353, 0.2647058823529412, 0.0, 0.17647058823529413, 0.058823529411764705], 0.001), (array([[-1,  1,  1],\n","       [-1,  1,  1],\n","       [ 0, -1, -1]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], 0.999), (array([[ 0,  1,  0],\n","       [-1,  0,  0],\n","       [ 0, -1,  0]]), [0.037037037037037035, 0.0, 0.0, 0.0, 0.0, 0.5925925925925926, 0.2962962962962963, 0.0, 0.07407407407407407], 0.001), (array([[ 0,  0, -1],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.03333333333333333, 0.13333333333333333, 0.0, 0.1, 0.0, 0.3333333333333333, 0.13333333333333333, 0.06666666666666667, 0.2], 0.999), (array([[ 0, -1,  0],\n","       [-1, -1,  0],\n","       [ 1,  1,  0]]), [0.0, 0.0, 0.30952380952380953, 0.0, 0.0, 0.42857142857142855, 0.0, 0.0, 0.2619047619047619], 0.999), (array([[ 0,  0,  0],\n","       [-1,  0, -1],\n","       [ 0,  0,  1]]), [0.11764705882352941, 0.29411764705882354, 0.0, 0.0, 0.058823529411764705, 0.0, 0.3235294117647059, 0.20588235294117646, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [-1,  0,  1],\n","       [ 0, -1,  0]]), [0.07407407407407407, 0.5925925925925926, 0.0, 0.0, 0.0, 0.0, 0.2962962962962963, 0.0, 0.037037037037037035], 0.001), (array([[ 1, -1,  0],\n","       [ 0,  0,  0],\n","       [ 0, -1,  0]]), [0.0, 0.0, 0.0, 0.20588235294117646, 0.058823529411764705, 0.29411764705882354, 0.3235294117647059, 0.0, 0.11764705882352941], 0.001), (array([[ 0, -1,  0],\n","       [-1,  0,  0],\n","       [ 0,  1,  0]]), [0.2962962962962963, 0.0, 0.07407407407407407, 0.0, 0.0, 0.5925925925925926, 0.037037037037037035, 0.0, 0.0], 0.001), (array([[ 0, -1,  0],\n","       [-1,  0,  1],\n","       [-1,  1,  1]]), [0.019230769230769232, 0.0, 0.6538461538461539, 0.0, 0.3269230769230769, 0.0, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  0,  1],\n","       [-1,  0, -1],\n","       [ 0,  0,  0]]), [0.3235294117647059, 0.20588235294117646, 0.0, 0.0, 0.058823529411764705, 0.0, 0.11764705882352941, 0.29411764705882354, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0, -1,  1]]), [0.17647058823529413, 0.14705882352941177, 0.058823529411764705, 0.11764705882352941, 0.0, 0.20588235294117646, 0.29411764705882354, 0.0, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  0,  1],\n","       [ 0,  0, -1]]), [0.06896551724137931, 0.20689655172413793, 0.0, 0.3448275862068966, 0.034482758620689655, 0.0, 0.20689655172413793, 0.13793103448275862, 0.0], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.041666666666666664, 0.25, 0.125, 0.125, 0.0, 0.041666666666666664, 0.0, 0.375, 0.041666666666666664], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.08333333333333333, 0.08333333333333333, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.08333333333333333, 0.125, 0.25, 0.25], 0.999), (array([[ 0,  1, -1],\n","       [ 0,  0,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.20689655172413793, 0.034482758620689655, 0.13793103448275862, 0.06896551724137931, 0.3448275862068966, 0.20689655172413793], 0.999), (array([[ 0,  1,  0],\n","       [ 1,  0, -1],\n","       [ 0, -1,  0]]), [0.6097560975609756, 0.0, 0.21951219512195122, 0.0, 0.07317073170731707, 0.0, 0.0975609756097561, 0.0, 0.0], 0.999), (array([[-1,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.13333333333333333, 0.03333333333333333, 0.3333333333333333, 0.0, 0.1, 0.2, 0.06666666666666667, 0.13333333333333333], 0.999), (array([[ 0, -1,  0],\n","       [-1,  0,  1],\n","       [ 0,  1,  0]]), [0.0, 0.0, 0.21951219512195122, 0.0, 0.07317073170731707, 0.0, 0.0975609756097561, 0.0, 0.6097560975609756], 0.999), (array([[ 0, -1,  0],\n","       [ 0,  1,  1],\n","       [-1,  1, -1]]), [0.1891891891891892, 0.0, 0.1891891891891892, 0.6216216216216216, 0.0, 0.0, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [-1,  1,  0],\n","       [-1,  1,  0]]), [0.12121212121212122, 0.21212121212121213, 0.12121212121212122, 0.0, 0.0, 0.5454545454545454, 0.0, 0.0, 0.0], 0.001), (array([[-1, -1,  0],\n","       [-1,  0,  1],\n","       [ 0,  1,  0]]), [0.0, 0.0, 0.5490196078431373, 0.0, 0.13725490196078433, 0.0, 0.3137254901960784, 0.0, 0.0], 0.001), (array([[ 0,  1,  0],\n","       [-1,  0,  1],\n","       [ 0, -1,  0]]), [0.0975609756097561, 0.0, 0.6097560975609756, 0.0, 0.07317073170731707, 0.0, 0.0, 0.0, 0.21951219512195122], 0.999), (array([[ 0, -1, -1],\n","       [-1,  0,  1],\n","       [ 0,  1,  1]]), [0.019230769230769232, 0.0, 0.0, 0.0, 0.3269230769230769, 0.0, 0.6538461538461539, 0.0, 0.0], 0.999), (array([[ 0,  1,  0],\n","       [-1,  0,  1],\n","       [ 0, -1,  0]]), [0.21951219512195122, 0.0, 0.6097560975609756, 0.0, 0.07317073170731707, 0.0, 0.0, 0.0, 0.0975609756097561], 0.999), (array([[-1,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.3333333333333333, 0.2, 0.13333333333333333, 0.0, 0.06666666666666667, 0.03333333333333333, 0.1, 0.13333333333333333], 0.999), (array([[ 0, -1,  1],\n","       [ 0,  0,  0],\n","       [ 0, -1,  0]]), [0.0, 0.0, 0.0, 0.29411764705882354, 0.058823529411764705, 0.20588235294117646, 0.11764705882352941, 0.0, 0.3235294117647059], 0.001), (array([[-1,  1, -1],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.29411764705882354, 0.0, 0.14705882352941177, 0.08823529411764706, 0.23529411764705882, 0.23529411764705882], 0.999), (array([[ 0,  1,  0],\n","       [-1, -1,  1],\n","       [-1, -1,  1]]), [0.975609756097561, 0.0, 0.024390243902439025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.001), (array([[ 0, -1,  0],\n","       [ 1,  0, -1],\n","       [ 0,  1,  0]]), [0.0975609756097561, 0.0, 0.0, 0.0, 0.07317073170731707, 0.0, 0.6097560975609756, 0.0, 0.21951219512195122], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.08, 0.08, 0.04, 0.04, 0.0, 0.08, 0.16, 0.28, 0.24], 0.001), (array([[ 0,  0,  0],\n","       [-1, -1,  0],\n","       [ 1, -1,  1]]), [0.08823529411764706, 0.38235294117647056, 0.2647058823529412, 0.0, 0.0, 0.2647058823529412, 0.0, 0.0, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  0,  0],\n","       [ 0,  1, -1]]), [0.06896551724137931, 0.3448275862068966, 0.20689655172413793, 0.20689655172413793, 0.034482758620689655, 0.13793103448275862, 0.0, 0.0, 0.0], 0.999), (array([[ 0, -1,  0],\n","       [ 1,  0, -1],\n","       [ 1,  1, -1]]), [0.6538461538461539, 0.0, 0.019230769230769232, 0.0, 0.3269230769230769, 0.0, 0.0, 0.0, 0.0], 0.999), (array([[ 1,  0,  0],\n","       [-1, -1,  0],\n","       [ 1, -1,  0]]), [0.0, 0.2647058823529412, 0.2647058823529412, 0.0, 0.0, 0.38235294117647056, 0.0, 0.0, 0.08823529411764706], 0.001), (array([[ 0,  0,  0],\n","       [ 1,  0,  0],\n","       [ 0, -1,  0]]), [0.2, 0.1, 0.1, 0.0, 0.0, 0.5666666666666667, 0.03333333333333333, 0.0, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  0,  0],\n","       [ 0, -1,  0]]), [0.058823529411764705, 0.2647058823529412, 0.20588235294117646, 0.17647058823529413, 0.029411764705882353, 0.11764705882352941, 0.0, 0.0, 0.14705882352941177], 0.001), (array([[-1,  1,  1],\n","       [-1,  1,  1],\n","       [ 0, -1, -1]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0], 0.999), (array([[-1,  1,  0],\n","       [ 1,  1, -1],\n","       [-1,  0,  0]]), [0.0, 0.0, 0.1891891891891892, 0.0, 0.0, 0.0, 0.0, 0.6216216216216216, 0.1891891891891892], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  0, -1],\n","       [ 0,  0,  0]]), [0.058823529411764705, 0.17647058823529413, 0.0, 0.2647058823529412, 0.029411764705882353, 0.0, 0.20588235294117646, 0.11764705882352941, 0.14705882352941177], 0.001), (array([[ 0,  0, -1],\n","       [-1,  1,  1],\n","       [ 0,  1, -1]]), [0.1891891891891892, 0.6216216216216216, 0.0, 0.0, 0.0, 0.0, 0.1891891891891892, 0.0, 0.0], 0.999), (array([[ 0, -1,  0],\n","       [ 1,  1,  0],\n","       [-1,  1, -1]]), [0.1891891891891892, 0.0, 0.1891891891891892, 0.0, 0.0, 0.6216216216216216, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1, -1],\n","       [ 0,  0,  1]]), [0.17647058823529413, 0.11764705882352941, 0.29411764705882354, 0.14705882352941177, 0.0, 0.0, 0.058823529411764705, 0.20588235294117646, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [-1,  0,  0],\n","       [ 0,  1,  0]]), [0.0, 0.5666666666666667, 0.1, 0.0, 0.0, 0.1, 0.03333333333333333, 0.0, 0.2], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1, -1],\n","       [ 0,  0,  1]]), [0.1, 0.425, 0.0, 0.15, 0.0, 0.0, 0.1, 0.225, 0.0], 0.999), (array([[ 0,  0,  1],\n","       [ 0, -1, -1],\n","       [ 0, -1,  1]]), [0.2647058823529412, 0.2647058823529412, 0.0, 0.38235294117647056, 0.0, 0.0, 0.08823529411764706, 0.0, 0.0], 0.001), (array([[-1, -1,  0],\n","       [ 1,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.12121212121212122, 0.0, 0.0, 0.21212121212121213, 0.0, 0.5454545454545454, 0.12121212121212122], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0, -1]]), [0.13333333333333333, 0.06666666666666667, 0.2, 0.1, 0.0, 0.3333333333333333, 0.03333333333333333, 0.13333333333333333, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 1, -1, -1],\n","       [ 1, -1,  0]]), [0.2619047619047619, 0.42857142857142855, 0.30952380952380953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.999), (array([[-1,  0,  0],\n","       [ 1,  1,  0],\n","       [-1,  0,  0]]), [0.0, 0.29411764705882354, 0.08823529411764706, 0.0, 0.0, 0.23529411764705882, 0.0, 0.14705882352941177, 0.23529411764705882], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.08, 0.04, 0.16, 0.08, 0.0, 0.28, 0.04, 0.08, 0.24], 0.001), (array([[-1,  1,  0],\n","       [ 0,  0,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.13793103448275862, 0.034482758620689655, 0.20689655172413793, 0.20689655172413793, 0.3448275862068966, 0.06896551724137931], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.25, 0.25, 0.125, 0.08333333333333333, 0.041666666666666664, 0.041666666666666664, 0.041666666666666664, 0.08333333333333333, 0.08333333333333333], 0.999), (array([[ 0,  0,  0],\n","       [-1,  0,  0],\n","       [ 0,  0,  0]]), [0.16666666666666666, 0.06666666666666667, 0.06666666666666667, 0.0, 0.0, 0.4666666666666667, 0.03333333333333333, 0.2, 0.0], 0.001), (array([[-1,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.1, 0.03333333333333333, 0.5333333333333333, 0.0, 0.06666666666666667, 0.0, 0.23333333333333334, 0.03333333333333333], 0.001), (array([[ 0, -1, -1],\n","       [ 1,  0,  1],\n","       [ 0,  0,  0]]), [0.3870967741935484, 0.0, 0.0, 0.0, 0.06451612903225806, 0.0, 0.16129032258064516, 0.3870967741935484, 0.0], 0.999), (array([[ 0,  1,  1],\n","       [ 0, -1, -1],\n","       [ 0, -1,  0]]), [0.2619047619047619, 0.0, 0.0, 0.42857142857142855, 0.0, 0.0, 0.30952380952380953, 0.0, 0.0], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.041666666666666664, 0.041666666666666664, 0.0, 0.16666666666666666, 0.041666666666666664, 0.08333333333333333, 0.0, 0.375, 0.25], 0.001), (array([[ 1, -1,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.225, 0.0, 0.425, 0.1, 0.15, 0.1], 0.999), (array([[ 0, -1,  0],\n","       [ 0,  0,  0],\n","       [ 0,  0,  0]]), [0.16666666666666666, 0.0, 0.03333333333333333, 0.06666666666666667, 0.0, 0.2, 0.06666666666666667, 0.4666666666666667, 0.0], 0.001), (array([[ 0,  0, -1],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.03333333333333333, 0.1, 0.0, 0.06666666666666667, 0.0, 0.5333333333333333, 0.03333333333333333, 0.23333333333333334, 0.0], 0.001), (array([[-1, -1,  1],\n","       [-1, -1,  1],\n","       [ 0,  1,  0]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.975609756097561, 0.0, 0.024390243902439025], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.041666666666666664, 0.16666666666666666, 0.125, 0.08333333333333333, 0.0, 0.08333333333333333, 0.0, 0.4166666666666667, 0.08333333333333333], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.125, 0.16666666666666666, 0.041666666666666664, 0.08333333333333333, 0.0, 0.08333333333333333, 0.08333333333333333, 0.4166666666666667, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  0,  0],\n","       [ 0, -1,  0]]), [0.0, 0.4666666666666667, 0.06666666666666667, 0.2, 0.0, 0.06666666666666667, 0.03333333333333333, 0.0, 0.16666666666666666], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.125, 0.041666666666666664, 0.041666666666666664, 0.25, 0.0, 0.375, 0.041666666666666664, 0.125, 0.0], 0.999), (array([[ 0, -1,  0],\n","       [ 0,  0, -1],\n","       [ 0,  1,  0]]), [0.07407407407407407, 0.0, 0.2962962962962963, 0.5925925925925926, 0.0, 0.0, 0.0, 0.0, 0.037037037037037035], 0.001), (array([[ 0, -1,  0],\n","       [ 0,  0,  0],\n","       [ 1, -1,  0]]), [0.3235294117647059, 0.0, 0.11764705882352941, 0.20588235294117646, 0.058823529411764705, 0.29411764705882354, 0.0, 0.0, 0.0], 0.001), (array([[-1, -1,  0],\n","       [-1,  0,  1],\n","       [ 0,  1,  0]]), [0.0, 0.0, 0.3137254901960784, 0.0, 0.13725490196078433, 0.0, 0.5490196078431373, 0.0, 0.0], 0.001), (array([[ 0, -1, -1],\n","       [-1,  1,  1],\n","       [-1,  1,  1]]), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [-1,  0,  0]]), [0.03333333333333333, 0.06666666666666667, 0.03333333333333333, 0.1, 0.0, 0.23333333333333334, 0.0, 0.5333333333333333, 0.0], 0.001), (array([[ 1, -1,  0],\n","       [-1, -1,  0],\n","       [ 1,  0,  0]]), [0.0, 0.0, 0.08823529411764706, 0.0, 0.0, 0.38235294117647056, 0.0, 0.2647058823529412, 0.2647058823529412], 0.001), (array([[-1,  1,  0],\n","       [-1,  0,  0],\n","       [ 0,  1,  0]]), [0.0, 0.0, 0.0, 0.0, 0.06451612903225806, 0.3870967741935484, 0.3870967741935484, 0.0, 0.16129032258064516], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.08333333333333333, 0.4166666666666667, 0.0, 0.08333333333333333, 0.0, 0.08333333333333333, 0.125, 0.16666666666666666, 0.041666666666666664], 0.999), (array([[ 0,  0,  0],\n","       [ 1,  0,  1],\n","       [ 0, -1, -1]]), [0.16129032258064516, 0.3870967741935484, 0.0, 0.0, 0.06451612903225806, 0.0, 0.3870967741935484, 0.0, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  0, -1],\n","       [ 0,  0,  0]]), [0.06666666666666667, 0.06666666666666667, 0.16666666666666666, 0.4666666666666667, 0.0, 0.0, 0.0, 0.2, 0.03333333333333333], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [-1,  0,  0]]), [0.03333333333333333, 0.1, 0.13333333333333333, 0.13333333333333333, 0.0, 0.06666666666666667, 0.0, 0.3333333333333333, 0.2], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.041666666666666664, 0.08333333333333333, 0.0, 0.16666666666666666, 0.0, 0.4166666666666667, 0.125, 0.08333333333333333, 0.08333333333333333], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.25, 0.08333333333333333, 0.0, 0.375, 0.041666666666666664, 0.041666666666666664, 0.0, 0.16666666666666666, 0.041666666666666664], 0.001), (array([[ 0,  1,  0],\n","       [ 1, -1, -1],\n","       [ 1, -1, -1]]), [0.024390243902439025, 0.0, 0.975609756097561, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.001), (array([[-1, -1,  0],\n","       [ 1,  0, -1],\n","       [ 1,  1,  0]]), [0.0, 0.0, 0.019230769230769232, 0.0, 0.3269230769230769, 0.0, 0.0, 0.0, 0.6538461538461539], 0.999), (array([[ 0,  0,  0],\n","       [-1, -1,  1],\n","       [ 0, -1,  1]]), [0.30952380952380953, 0.42857142857142855, 0.2619047619047619, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.04, 0.08, 0.24, 0.08, 0.0, 0.28, 0.08, 0.04, 0.16], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.125, 0.08333333333333333, 0.08333333333333333, 0.16666666666666666, 0.0, 0.4166666666666667, 0.041666666666666664, 0.08333333333333333, 0.0], 0.999), (array([[-1,  1, -1],\n","       [ 0,  1,  1],\n","       [ 0, -1,  0]]), [0.0, 0.0, 0.0, 0.6216216216216216, 0.0, 0.0, 0.1891891891891892, 0.0, 0.1891891891891892], 0.999), (array([[ 1,  1, -1],\n","       [ 1,  0, -1],\n","       [ 0, -1,  0]]), [0.0, 0.0, 0.0, 0.0, 0.3269230769230769, 0.0, 0.6538461538461539, 0.0, 0.019230769230769232], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.041666666666666664, 0.375, 0.0, 0.041666666666666664, 0.0, 0.125, 0.125, 0.25, 0.041666666666666664], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.0, 0.375, 0.25, 0.16666666666666666, 0.041666666666666664, 0.08333333333333333, 0.041666666666666664, 0.041666666666666664, 0.0], 0.001), (array([[ 0,  1,  0],\n","       [-1,  0,  0],\n","       [-1,  1,  0]]), [0.3870967741935484, 0.0, 0.16129032258064516, 0.0, 0.06451612903225806, 0.3870967741935484, 0.0, 0.0, 0.0], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.041666666666666664, 0.08333333333333333, 0.25, 0.08333333333333333, 0.041666666666666664, 0.25, 0.08333333333333333, 0.041666666666666664, 0.125], 0.999), (array([[ 0, -1, -1],\n","       [-1,  1,  1],\n","       [-1,  1,  1]]), [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.04, 0.08, 0.08, 0.08, 0.0, 0.04, 0.24, 0.28, 0.16], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [-1,  0,  0]]), [0.2, 0.06666666666666667, 0.13333333333333333, 0.3333333333333333, 0.0, 0.1, 0.0, 0.13333333333333333, 0.03333333333333333], 0.999), (array([[ 0,  0,  1],\n","       [ 0, -1, -1],\n","       [ 0,  0,  0]]), [0.058823529411764705, 0.20588235294117646, 0.0, 0.14705882352941177, 0.0, 0.0, 0.17647058823529413, 0.11764705882352941, 0.29411764705882354], 0.001), (array([[ 0, -1,  0],\n","       [-1,  0,  1],\n","       [ 0,  0,  0]]), [0.2962962962962963, 0.0, 0.037037037037037035, 0.0, 0.0, 0.0, 0.07407407407407407, 0.5925925925925926, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  0,  0],\n","       [ 0, -1,  0]]), [0.06666666666666667, 0.4666666666666667, 0.0, 0.06666666666666667, 0.0, 0.2, 0.16666666666666666, 0.0, 0.03333333333333333], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 1, -1,  0]]), [0.1, 0.15, 0.1, 0.225, 0.0, 0.425, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  0, -1],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.2, 0.3333333333333333, 0.0, 0.06666666666666667, 0.0, 0.13333333333333333, 0.13333333333333333, 0.1, 0.03333333333333333], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  1,  1],\n","       [ 0, -1, -1]]), [0.12121212121212122, 0.5454545454545454, 0.0, 0.21212121212121213, 0.0, 0.0, 0.12121212121212122, 0.0, 0.0], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.041666666666666664, 0.16666666666666666, 0.0, 0.041666666666666664, 0.041666666666666664, 0.375, 0.0, 0.08333333333333333, 0.25], 0.001), (array([[ 0,  1, -1],\n","       [-1,  1,  1],\n","       [ 0,  0, -1]]), [0.1891891891891892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1891891891891892, 0.6216216216216216, 0.0], 0.999), (array([[-1,  0,  0],\n","       [ 1,  1, -1],\n","       [-1,  1,  0]]), [0.0, 0.6216216216216216, 0.1891891891891892, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1891891891891892], 0.999), (array([[ 0,  0,  0],\n","       [ 1,  0,  1],\n","       [-1, -1,  0]]), [0.0, 0.3870967741935484, 0.16129032258064516, 0.0, 0.06451612903225806, 0.0, 0.0, 0.0, 0.3870967741935484], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.0, 0.041666666666666664, 0.041666666666666664, 0.08333333333333333, 0.041666666666666664, 0.16666666666666666, 0.25, 0.375, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.24, 0.28, 0.16, 0.08, 0.0, 0.04, 0.04, 0.08, 0.08], 0.001), (array([[ 0, -1,  0],\n","       [ 1,  0, -1],\n","       [ 0,  0,  0]]), [0.037037037037037035, 0.0, 0.2962962962962963, 0.0, 0.0, 0.0, 0.0, 0.5925925925925926, 0.07407407407407407], 0.001), (array([[-1,  0,  0],\n","       [ 1,  0,  0],\n","       [ 0,  0,  0]]), [0.0, 0.13793103448275862, 0.20689655172413793, 0.0, 0.034482758620689655, 0.3448275862068966, 0.0, 0.20689655172413793, 0.06896551724137931], 0.999), (array([[ 0, -1,  1],\n","       [-1, -1,  1],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.30952380952380953, 0.42857142857142855, 0.2619047619047619], 0.999), (array([[ 0, -1, -1],\n","       [ 0,  1,  1],\n","       [ 0,  0,  0]]), [0.12121212121212122, 0.0, 0.0, 0.21212121212121213, 0.0, 0.0, 0.12121212121212122, 0.5454545454545454, 0.0], 0.001), (array([[ 0,  0, -1],\n","       [ 0,  1,  1],\n","       [ 0,  0, -1]]), [0.23529411764705882, 0.14705882352941177, 0.0, 0.23529411764705882, 0.0, 0.0, 0.08823529411764706, 0.29411764705882354, 0.0], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.0, 0.375, 0.041666666666666664, 0.125, 0.0, 0.041666666666666664, 0.041666666666666664, 0.25, 0.125], 0.999), (array([[-1,  1, -1],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.14705882352941177, 0.0, 0.29411764705882354, 0.23529411764705882, 0.23529411764705882, 0.08823529411764706], 0.999), (array([[ 0,  1,  0],\n","       [-1,  0,  1],\n","       [-1, -1,  0]]), [0.5490196078431373, 0.0, 0.0, 0.0, 0.13725490196078433, 0.0, 0.0, 0.0, 0.3137254901960784], 0.001), (array([[ 1, -1,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.29411764705882354, 0.20588235294117646, 0.0, 0.11764705882352941, 0.058823529411764705, 0.14705882352941177, 0.17647058823529413], 0.001), (array([[ 1, -1,  1],\n","       [ 0, -1, -1],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.2647058823529412, 0.0, 0.0, 0.2647058823529412, 0.38235294117647056, 0.08823529411764706], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [-1,  1, -1]]), [0.23529411764705882, 0.23529411764705882, 0.08823529411764706, 0.14705882352941177, 0.0, 0.29411764705882354, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  1,  0],\n","       [ 1,  0, -1],\n","       [ 0, -1, -1]]), [0.0, 0.0, 0.5490196078431373, 0.0, 0.13725490196078433, 0.0, 0.3137254901960784, 0.0, 0.0], 0.001), (array([[ 0,  1, -1],\n","       [ 0,  1, -1],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.5454545454545454, 0.0, 0.0, 0.12121212121212122, 0.21212121212121213, 0.12121212121212122], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.125, 0.25, 0.041666666666666664, 0.041666666666666664, 0.0, 0.125, 0.041666666666666664, 0.375, 0.0], 0.999), (array([[ 0, -1,  1],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.29411764705882354, 0.0, 0.0, 0.11764705882352941, 0.0, 0.20588235294117646, 0.17647058823529413, 0.14705882352941177, 0.058823529411764705], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.24, 0.4, 0.0, 0.08, 0.0, 0.16, 0.04, 0.04, 0.04], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  0, -1],\n","       [ 0,  0,  0]]), [0.0, 0.2, 0.03333333333333333, 0.4666666666666667, 0.0, 0.0, 0.06666666666666667, 0.06666666666666667, 0.16666666666666666], 0.001), (array([[ 0,  1,  0],\n","       [ 0,  0, -1],\n","       [ 0,  0,  0]]), [0.2, 0.0, 0.03333333333333333, 0.1, 0.0, 0.0, 0.1, 0.5666666666666667, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [-1,  0, -1],\n","       [ 1,  0,  0]]), [0.0, 0.29411764705882354, 0.11764705882352941, 0.0, 0.058823529411764705, 0.0, 0.0, 0.20588235294117646, 0.3235294117647059], 0.001), (array([[-1, -1,  0],\n","       [ 1,  1, -1],\n","       [ 1,  1, -1]]), [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  1, -1],\n","       [ 0,  1, -1]]), [0.12121212121212122, 0.21212121212121213, 0.12121212121212122, 0.5454545454545454, 0.0, 0.0, 0.0, 0.0, 0.0], 0.001), (array([[ 1, -1,  0],\n","       [ 1, -1, -1],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2619047619047619, 0.42857142857142855, 0.30952380952380953], 0.999), (array([[ 0, -1,  0],\n","       [ 1,  0,  0],\n","       [ 0,  0,  0]]), [0.03333333333333333, 0.0, 0.0, 0.0, 0.0, 0.5666666666666667, 0.2, 0.1, 0.1], 0.999), (array([[ 0,  0, -1],\n","       [ 0,  0,  1],\n","       [ 0,  0,  0]]), [0.20689655172413793, 0.13793103448275862, 0.0, 0.3448275862068966, 0.034482758620689655, 0.0, 0.06896551724137931, 0.20689655172413793, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  0, -1],\n","       [ 0,  1,  0]]), [0.1, 0.5666666666666667, 0.0, 0.1, 0.0, 0.0, 0.2, 0.0, 0.03333333333333333], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [-1,  1, -1]]), [0.08823529411764706, 0.23529411764705882, 0.23529411764705882, 0.29411764705882354, 0.0, 0.14705882352941177, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.24, 0.08, 0.04, 0.4, 0.0, 0.04, 0.0, 0.16, 0.04], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.0, 0.4166666666666667, 0.08333333333333333, 0.08333333333333333, 0.0, 0.08333333333333333, 0.041666666666666664, 0.16666666666666666, 0.125], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.24, 0.08, 0.04, 0.28, 0.0, 0.08, 0.16, 0.04, 0.08], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0, -1,  1]]), [0.1, 0.15, 0.1, 0.425, 0.0, 0.225, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  1,  1],\n","       [-1,  0,  1],\n","       [ 0, -1, -1]]), [0.6538461538461539, 0.0, 0.0, 0.0, 0.3269230769230769, 0.0, 0.019230769230769232, 0.0, 0.0], 0.999), (array([[-1, -1,  0],\n","       [ 1,  1, -1],\n","       [ 1,  1, -1]]), [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 0.999), (array([[ 0, -1,  0],\n","       [ 0,  0,  0],\n","       [ 0, -1,  1]]), [0.11764705882352941, 0.0, 0.3235294117647059, 0.29411764705882354, 0.058823529411764705, 0.20588235294117646, 0.0, 0.0, 0.0], 0.001), (array([[-1,  1,  0],\n","       [-1,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.5454545454545454, 0.12121212121212122, 0.21212121212121213, 0.12121212121212122], 0.001), (array([[ 0, -1, -1],\n","       [ 1, -1, -1],\n","       [ 0,  1,  1]]), [0.975609756097561, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024390243902439025, 0.0, 0.0], 0.001), (array([[ 0,  1, -1],\n","       [ 0,  0, -1],\n","       [ 0,  1,  0]]), [0.0, 0.0, 0.0, 0.3870967741935484, 0.06451612903225806, 0.0, 0.16129032258064516, 0.0, 0.3870967741935484], 0.999), (array([[ 1,  1, -1],\n","       [ 1,  1, -1],\n","       [-1, -1,  0]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], 0.999), (array([[ 0,  0,  0],\n","       [-1,  0,  0],\n","       [ 0,  0,  0]]), [0.0, 0.17647058823529413, 0.058823529411764705, 0.0, 0.029411764705882353, 0.2647058823529412, 0.14705882352941177, 0.11764705882352941, 0.20588235294117646], 0.001), (array([[ 0,  0,  0],\n","       [-1, -1,  0],\n","       [ 1,  0,  0]]), [0.0, 0.425, 0.1, 0.0, 0.0, 0.15, 0.0, 0.225, 0.1], 0.999), (array([[ 0,  0,  0],\n","       [ 1,  0, -1],\n","       [ 0, -1,  0]]), [0.0, 0.5925925925925926, 0.07407407407407407, 0.0, 0.0, 0.0, 0.037037037037037035, 0.0, 0.2962962962962963], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.0, 0.08333333333333333, 0.041666666666666664, 0.4166666666666667, 0.0, 0.16666666666666666, 0.08333333333333333, 0.08333333333333333, 0.125], 0.999), (array([[ 0, -1, -1],\n","       [ 1,  0, -1],\n","       [ 0,  1,  0]]), [0.5490196078431373, 0.0, 0.0, 0.0, 0.13725490196078433, 0.0, 0.0, 0.0, 0.3137254901960784], 0.001), (array([[ 1,  0,  0],\n","       [-1,  0, -1],\n","       [ 0,  0,  0]]), [0.0, 0.20588235294117646, 0.3235294117647059, 0.0, 0.058823529411764705, 0.0, 0.0, 0.29411764705882354, 0.11764705882352941], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.0, 0.16666666666666666, 0.041666666666666664, 0.375, 0.041666666666666664, 0.041666666666666664, 0.25, 0.08333333333333333, 0.0], 0.001), (array([[ 0,  1,  0],\n","       [ 1,  0, -1],\n","       [ 0, -1, -1]]), [0.0, 0.0, 0.3137254901960784, 0.0, 0.13725490196078433, 0.0, 0.5490196078431373, 0.0, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0, -1]]), [0.03333333333333333, 0.23333333333333334, 0.0, 0.06666666666666667, 0.0, 0.5333333333333333, 0.03333333333333333, 0.1, 0.0], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.08333333333333333, 0.08333333333333333, 0.125, 0.4166666666666667, 0.0, 0.16666666666666666, 0.0, 0.08333333333333333, 0.041666666666666664], 0.999), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.125, 0.041666666666666664, 0.08333333333333333, 0.25, 0.041666666666666664, 0.08333333333333333, 0.25, 0.08333333333333333, 0.041666666666666664], 0.999), (array([[ 1,  1,  0],\n","       [ 1,  0, -1],\n","       [-1, -1,  0]]), [0.0, 0.0, 0.6538461538461539, 0.0, 0.3269230769230769, 0.0, 0.0, 0.0, 0.019230769230769232], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.16, 0.28, 0.24, 0.04, 0.0, 0.08, 0.08, 0.08, 0.04], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.04, 0.04, 0.04, 0.08, 0.0, 0.16, 0.24, 0.4, 0.0], 0.999), (array([[-1,  1, -1],\n","       [ 1,  1,  0],\n","       [ 0, -1,  0]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.6216216216216216, 0.1891891891891892, 0.0, 0.1891891891891892], 0.999), (array([[ 0, -1, -1],\n","       [ 1,  0, -1],\n","       [ 0,  1,  0]]), [0.3137254901960784, 0.0, 0.0, 0.0, 0.13725490196078433, 0.0, 0.0, 0.0, 0.5490196078431373], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 1, -1,  0]]), [0.058823529411764705, 0.14705882352941177, 0.17647058823529413, 0.20588235294117646, 0.0, 0.11764705882352941, 0.0, 0.0, 0.29411764705882354], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.25, 0.08333333333333333, 0.041666666666666664, 0.25, 0.041666666666666664, 0.08333333333333333, 0.125, 0.041666666666666664, 0.08333333333333333], 0.999), (array([[ 0, -1,  1],\n","       [ 0, -1, -1],\n","       [ 0,  0,  1]]), [0.08823529411764706, 0.0, 0.0, 0.38235294117647056, 0.0, 0.0, 0.2647058823529412, 0.2647058823529412, 0.0], 0.001), (array([[ 1,  0,  0],\n","       [-1, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.225, 0.1, 0.0, 0.0, 0.15, 0.0, 0.425, 0.1], 0.999), (array([[ 1, -1,  1],\n","       [-1, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.0, 0.0, 0.2647058823529412, 0.08823529411764706, 0.38235294117647056, 0.2647058823529412], 0.001), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.04, 0.16, 0.0, 0.04, 0.0, 0.4, 0.04, 0.08, 0.24], 0.999), (array([[ 0, -1,  1],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.0, 0.0, 0.425, 0.0, 0.225, 0.1, 0.15, 0.1], 0.999), (array([[ 0,  0,  0],\n","       [-1, -1,  0],\n","       [ 1,  0,  0]]), [0.29411764705882354, 0.11764705882352941, 0.17647058823529413, 0.0, 0.0, 0.14705882352941177, 0.0, 0.20588235294117646, 0.058823529411764705], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [-1,  0,  0]]), [0.0, 0.23333333333333334, 0.03333333333333333, 0.5333333333333333, 0.0, 0.06666666666666667, 0.0, 0.1, 0.03333333333333333], 0.001), (array([[ 0,  0,  0],\n","       [ 0,  0,  0],\n","       [-1,  1,  0]]), [0.20689655172413793, 0.3448275862068966, 0.06896551724137931, 0.13793103448275862, 0.034482758620689655, 0.20689655172413793, 0.0, 0.0, 0.0], 0.999), (array([[-1,  1,  1],\n","       [-1,  0,  1],\n","       [ 0, -1,  0]]), [0.0, 0.0, 0.0, 0.0, 0.3269230769230769, 0.0, 0.019230769230769232, 0.0, 0.6538461538461539], 0.999), (array([[ 0,  0, -1],\n","       [ 0,  1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.5333333333333333, 0.0, 0.23333333333333334, 0.0, 0.1, 0.03333333333333333, 0.06666666666666667, 0.03333333333333333], 0.001), (array([[ 0,  1,  1],\n","       [ 1, -1, -1],\n","       [ 0, -1, -1]]), [0.024390243902439025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.975609756097561, 0.0, 0.0], 0.001), (array([[0, 0, 0],\n","       [0, 0, 0],\n","       [0, 0, 0]]), [0.0, 0.08333333333333333, 0.25, 0.041666666666666664, 0.041666666666666664, 0.375, 0.041666666666666664, 0.16666666666666666, 0.0], 0.001), (array([[ 0,  0,  0],\n","       [ 1,  1,  0],\n","       [-1, -1,  0]]), [0.0, 0.5454545454545454, 0.12121212121212122, 0.0, 0.0, 0.21212121212121213, 0.0, 0.0, 0.12121212121212122], 0.001), (array([[ 0,  0,  0],\n","       [ 1,  0,  0],\n","       [-1,  0,  0]]), [0.0, 0.20689655172413793, 0.06896551724137931, 0.0, 0.034482758620689655, 0.3448275862068966, 0.0, 0.13793103448275862, 0.20689655172413793], 0.999), (array([[ 0,  0,  0],\n","       [ 0, -1,  0],\n","       [ 0,  0,  0]]), [0.16, 0.04, 0.08, 0.28, 0.0, 0.08, 0.24, 0.08, 0.04], 0.001), (array([[ 1,  0,  0],\n","       [-1, -1,  0],\n","       [ 0,  0,  0]]), [0.0, 0.20588235294117646, 0.058823529411764705, 0.0, 0.0, 0.14705882352941177, 0.29411764705882354, 0.11764705882352941, 0.17647058823529413], 0.001), (array([[ 0,  1,  0],\n","       [ 0,  0, -1],\n","       [ 0,  1, -1]]), [0.16129032258064516, 0.0, 0.3870967741935484, 0.3870967741935484, 0.06451612903225806, 0.0, 0.0, 0.0, 0.0], 0.999), (array([[ 0,  0,  0],\n","       [ 0,  1,  0],\n","       [ 0,  0, -1]]), [0.03333333333333333, 0.06666666666666667, 0.03333333333333333, 0.23333333333333334, 0.0, 0.1, 0.0, 0.5333333333333333, 0.0], 0.001)] examples\n","EPOCH ::: 1\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   0%|          | 0/216 [00:00<?, ?it/s, Loss_pi=2.18e+00, Loss_v=3.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1667, 0.0000, 0.0333, 0.0667, 0.0000, 0.2000, 0.0667, 0.4667, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.3842e-07, 2.1759e-02, 2.7676e-03, 2.8223e-01, 3.8934e-04, 6.8799e-01,\n","         3.3112e-03, 7.1049e-04, 1.2064e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5832], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1795, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3390, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   0%|          | 1/216 [00:01<03:32,  1.01it/s, Loss_pi=2.26e+00, Loss_v=3.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.3235, 0.2059, 0.0000, 0.0000, 0.0588, 0.0000, 0.1176, 0.2941, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.3842e-07, 1.9974e-02, 2.9449e-03, 2.8906e-01, 4.3106e-04, 6.8262e-01,\n","         3.5820e-03, 7.1621e-04, 1.1420e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5838], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3315, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3396, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   1%|          | 2/216 [00:02<03:32,  1.01it/s, Loss_pi=2.28e+00, Loss_v=3.38e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.9756, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0244]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[1.7881e-07, 1.8295e-02, 2.5139e-03, 3.1934e-01, 3.4571e-04, 6.5527e-01,\n","         2.9869e-03, 5.6553e-04, 1.0461e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5812], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3321, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3367, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   1%|▏         | 3/216 [00:03<03:33,  1.00s/it, Loss_pi=2.25e+00, Loss_v=2.99e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0333, 0.5667, 0.0000, 0.0000, 0.1000, 0.1000, 0.2000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.3842e-07, 2.1820e-02, 3.0479e-03, 3.4131e-01, 3.9983e-04, 6.2793e-01,\n","         3.4809e-03, 7.5293e-04, 1.2100e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5753], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1396, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1795, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   2%|▏         | 4/216 [00:04<03:32,  1.00s/it, Loss_pi=2.26e+00, Loss_v=2.75e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.6538, 0.0000, 0.0192, 0.0000, 0.3269, 0.0000, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.3842e-07, 2.5009e-02, 3.2043e-03, 3.9722e-01, 3.7670e-04, 5.6934e-01,\n","         3.2291e-03, 6.5088e-04, 1.0961e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5726], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3300, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1818, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   2%|▏         | 5/216 [00:05<03:30,  1.00it/s, Loss_pi=2.22e+00, Loss_v=2.60e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.2250, 0.0000, 0.4250, 0.1000, 0.1500, 0.1000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.9802e-07, 2.5192e-02, 3.7155e-03, 4.2603e-01, 4.6873e-04, 5.3857e-01,\n","         3.8033e-03, 8.4209e-04, 1.3745e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5705], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0052, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1836, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   3%|▎         | 6/216 [00:06<03:29,  1.00it/s, Loss_pi=2.23e+00, Loss_v=2.69e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.2059, 0.3235, 0.0000, 0.0588, 0.0000, 0.0000, 0.2941, 0.1176]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.9802e-07, 2.7100e-02, 4.0588e-03, 4.5117e-01, 4.5204e-04, 5.1123e-01,\n","         3.6678e-03, 9.0599e-04, 1.5140e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5694], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3226, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3230, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   3%|▎         | 7/216 [00:07<03:28,  1.00it/s, Loss_pi=2.24e+00, Loss_v=2.59e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1892, 0.6216, 0.0000, 0.0000, 0.0000, 0.0000, 0.1892, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.3842e-07, 2.5589e-02, 3.3550e-03, 4.6777e-01, 3.5381e-04, 4.9805e-01,\n","         2.9850e-03, 6.4564e-04, 1.0622e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5675], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3136, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1862, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   4%|▎         | 8/216 [00:08<03:28,  1.00s/it, Loss_pi=2.24e+00, Loss_v=2.65e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.2059, 0.0588, 0.0000, 0.0000, 0.1471, 0.2941, 0.1176, 0.1765]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.9802e-07, 2.5909e-02, 3.9444e-03, 4.5923e-01, 4.5633e-04, 5.0439e-01,\n","         3.8509e-03, 8.5258e-04, 1.3185e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5657], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2490, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3189, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   4%|▍         | 9/216 [00:09<03:27,  1.00s/it, Loss_pi=2.24e+00, Loss_v=2.58e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.2069, 0.0345, 0.1379, 0.0690, 0.3448, 0.2069]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.9802e-07, 2.7985e-02, 4.1580e-03, 4.8071e-01, 4.6659e-04, 4.8071e-01,\n","         3.9978e-03, 9.5749e-04, 1.4794e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5630], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1631, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1901, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   5%|▍         | 10/216 [00:10<03:26,  1.00s/it, Loss_pi=2.24e+00, Loss_v=2.63e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0800, 0.0800, 0.0400, 0.0400, 0.0000, 0.0800, 0.1600, 0.2800, 0.2400]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.9802e-07, 3.2501e-02, 4.2610e-03, 5.0830e-01, 4.5276e-04, 4.4873e-01,\n","         3.8509e-03, 8.7976e-04, 1.2672e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5593], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2697, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3117, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   5%|▌         | 11/216 [00:11<03:26,  1.01s/it, Loss_pi=2.23e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2619, 0.0000, 0.0000, 0.4286, 0.0000, 0.0000, 0.3095, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.9802e-07, 3.3630e-02, 4.4479e-03, 5.2637e-01, 4.4727e-04, 4.2944e-01,\n","         3.8052e-03, 7.9107e-04, 1.1134e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5592], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1029, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1935, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   6%|▌         | 12/216 [00:12<03:25,  1.01s/it, Loss_pi=2.23e+00, Loss_v=2.61e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.5926, 0.0741, 0.0000, 0.0000, 0.0000, 0.0370, 0.0000, 0.2963]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.9802e-07, 3.6743e-02, 4.7073e-03, 5.5713e-01, 4.6253e-04, 3.9502e-01,\n","         4.0283e-03, 8.5735e-04, 1.2839e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5562], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3077, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3083, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   6%|▌         | 13/216 [00:13<03:24,  1.01s/it, Loss_pi=2.23e+00, Loss_v=2.57e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.2069, 0.0690, 0.0000, 0.0345, 0.3448, 0.0000, 0.1379, 0.2069]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.9802e-07, 3.6407e-02, 4.6272e-03, 5.7861e-01, 4.9162e-04, 3.7354e-01,\n","         4.4174e-03, 9.7036e-04, 1.2732e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5513], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1939, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2005, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   6%|▋         | 14/216 [00:14<03:23,  1.01s/it, Loss_pi=2.23e+00, Loss_v=2.53e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0417, 0.1667, 0.1250, 0.0833, 0.0000, 0.0833, 0.0000, 0.4167, 0.0833]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.3842e-07, 3.3997e-02, 4.1237e-03, 5.6592e-01, 4.6611e-04, 3.8892e-01,\n","         4.4594e-03, 9.4891e-04, 1.3673e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5520], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2445, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1998, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   7%|▋         | 15/216 [00:15<03:22,  1.01s/it, Loss_pi=2.23e+00, Loss_v=2.50e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.4167, 0.0833, 0.0833, 0.0000, 0.0833, 0.0417, 0.1667, 0.1250]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[3.5763e-07, 3.8849e-02, 4.6768e-03, 5.6201e-01, 5.4169e-04, 3.8647e-01,\n","         4.9400e-03, 1.1377e-03, 1.5509e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5503], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2338, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.2013, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   7%|▋         | 16/216 [00:16<03:21,  1.01s/it, Loss_pi=2.23e+00, Loss_v=2.47e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0400, 0.0800, 0.2400, 0.0400, 0.0000, 0.4000, 0.0400, 0.1600, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[3.5763e-07, 4.4647e-02, 5.1689e-03, 5.4395e-01, 5.4502e-04, 3.9795e-01,\n","         5.3329e-03, 1.1358e-03, 1.5247e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5523], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1434, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1996, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   8%|▊         | 17/216 [00:17<03:20,  1.01s/it, Loss_pi=2.22e+00, Loss_v=2.44e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0833, 0.0417, 0.1250, 0.0833, 0.0417, 0.2500, 0.0417, 0.0833, 0.2500]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[3.5763e-07, 4.3152e-02, 5.1918e-03, 5.3369e-01, 5.7364e-04, 4.0942e-01,\n","         5.4855e-03, 1.1501e-03, 1.5926e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5579], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1792, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1946, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   8%|▊         | 18/216 [00:18<03:19,  1.01s/it, Loss_pi=2.22e+00, Loss_v=2.41e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.1613, 0.0000, 0.3871, 0.3871, 0.0645, 0.0000, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[3.5763e-07, 5.9875e-02, 5.3558e-03, 5.1758e-01, 4.7541e-04, 4.0918e-01,\n","         5.2757e-03, 1.1406e-03, 1.6427e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5583], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1255, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1942, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   9%|▉         | 19/216 [00:19<03:17,  1.00s/it, Loss_pi=2.22e+00, Loss_v=2.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.3095, 0.4286, 0.2619, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[3.5763e-07, 5.1605e-02, 5.2299e-03, 4.8193e-01, 5.2214e-04, 4.5288e-01,\n","         5.6114e-03, 1.0624e-03, 1.4842e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5618], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3048, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1911, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:   9%|▉         | 20/216 [00:20<03:16,  1.00s/it, Loss_pi=2.23e+00, Loss_v=2.36e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.3095, 0.4286, 0.2619, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[3.5763e-07, 5.8044e-02, 5.4855e-03, 4.7852e-01, 5.0211e-04, 4.4946e-01,\n","         5.6572e-03, 1.1320e-03, 1.5676e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5644], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3015, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1889, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  10%|▉         | 21/216 [00:21<03:15,  1.00s/it, Loss_pi=2.23e+00, Loss_v=2.40e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.2059, 0.3235, 0.0000, 0.0588, 0.0000, 0.0000, 0.2941, 0.1176]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[3.5763e-07, 6.3354e-02, 5.7564e-03, 4.3970e-01, 4.7231e-04, 4.8291e-01,\n","         5.5351e-03, 1.0900e-03, 1.5581e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5681], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3123, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3216, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  10%|█         | 22/216 [00:22<03:14,  1.00s/it, Loss_pi=2.23e+00, Loss_v=2.38e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.6216, 0.1892, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1892]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[2.9802e-07, 6.2683e-02, 5.2299e-03, 4.1528e-01, 4.0007e-04, 5.0879e-01,\n","         5.2681e-03, 9.9754e-04, 1.3721e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5711], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2882, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1831, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  11%|█         | 23/216 [00:23<03:13,  1.00s/it, Loss_pi=2.23e+00, Loss_v=2.35e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0000, 0.6216, 0.0000, 0.0000, 0.1892, 0.0000, 0.1892]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[4.7684e-07, 7.1777e-02, 6.9389e-03, 4.0649e-01, 5.4359e-04, 5.0586e-01,\n","         5.9814e-03, 1.1415e-03, 1.5700e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5739], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0731, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1807, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  11%|█         | 24/216 [00:24<03:12,  1.00s/it, Loss_pi=2.22e+00, Loss_v=2.39e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0741, 0.0000, 0.2963, 0.5926, 0.0000, 0.0000, 0.0000, 0.0000, 0.0370]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[4.7684e-07, 7.9041e-02, 6.9618e-03, 3.8892e-01, 5.5790e-04, 5.1562e-01,\n","         6.5880e-03, 1.2980e-03, 1.7703e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5736], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.0947, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3278, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  12%|█▏        | 25/216 [00:25<03:12,  1.01s/it, Loss_pi=2.22e+00, Loss_v=2.42e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0588, 0.2059, 0.0000, 0.1471, 0.0000, 0.0000, 0.1765, 0.1176, 0.2941]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[4.7684e-07, 8.3618e-02, 7.4806e-03, 4.1797e-01, 5.5885e-04, 4.8120e-01,\n","         6.5498e-03, 1.3409e-03, 1.7869e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5705], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2462, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3243, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  12%|█▏        | 26/216 [00:26<03:11,  1.01s/it, Loss_pi=2.22e+00, Loss_v=2.40e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0333, 0.1000, 0.1333, 0.1333, 0.0000, 0.0667, 0.0000, 0.3333, 0.2000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.3644e-07, 9.7778e-02, 8.2169e-03, 4.2480e-01, 5.9032e-04, 4.5923e-01,\n","         6.9199e-03, 1.4057e-03, 1.9479e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.9990], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5683], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.2270, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.1855, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  12%|█▎        | 27/216 [00:27<03:09,  1.00s/it, Loss_pi=2.23e+00, Loss_v=2.43e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.9756, 0.0000, 0.0244, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[4.7684e-07, 9.7046e-02, 8.6823e-03, 4.6289e-01, 5.9080e-04, 4.2163e-01,\n","         6.6566e-03, 1.3523e-03, 1.9479e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5674], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3259, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3208, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  13%|█▎        | 28/216 [00:28<03:08,  1.00s/it, Loss_pi=2.22e+00, Loss_v=2.46e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.2647, 0.2647, 0.0000, 0.3824, 0.0000, 0.0000, 0.0882, 0.0000, 0.0000]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[4.7684e-07, 1.2000e-01, 9.2545e-03, 4.9731e-01, 5.4693e-04, 3.6377e-01,\n","         6.5613e-03, 1.2922e-03, 1.8179e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5615], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.1025, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3142, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  13%|█▎        | 29/216 [00:29<03:06,  1.00it/s, Loss_pi=2.23e+00, Loss_v=2.48e-01]"]},{"name":"stdout","output_type":"stream","text":["Target_pi:  tensor([[0.0000, 0.0000, 0.0244, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9756]],\n","       device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_pi tensor([[5.9605e-07, 1.1700e-01, 9.7580e-03, 5.2441e-01, 6.1893e-04, 3.3862e-01,\n","         6.8665e-03, 1.4963e-03, 2.0576e-04]], device='cuda:0',\n","       dtype=torch.float16, grad_fn=<IndexBackward0>) targetv tensor([0.0010], device='cuda:0', grad_fn=<ToCopyBackward0>) predicted_v tensor([0.5554], device='cuda:0', grad_fn=<SumBackward1>) policy_loss tensor(2.3259, device='cuda:0', grad_fn=<DivBackward1>) value_loss tensor(0.3073, device='cuda:0', grad_fn=<MseLossBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["Training Net:  14%|█▍        | 30/216 [00:30<03:09,  1.02s/it, Loss_pi=2.23e+00, Loss_v=2.48e-01]\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 15&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">15</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">learn</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">118</span>                                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">37</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_policy</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">hooks.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">165</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">new_forward</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 │   │   │   │   </span>output = old_forward(*args, **kwargs)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>165 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>output = old_forward(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">166 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> module._hf_hook.post_forward(module, output)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">167 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">168 │   </span>module.forward = new_forward                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/transformers/models/llama/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_llama.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">687</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">684 │   │   </span>return_dict = return_dict <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> return_dict <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.use_return   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">685 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">686 │   │   # decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>687 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model(                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">688 │   │   │   </span>input_ids=input_ids,                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">689 │   │   │   </span>attention_mask=attention_mask,                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">690 │   │   │   </span>position_ids=position_ids,                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">hooks.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">165</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">new_forward</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 │   │   │   │   </span>output = old_forward(*args, **kwargs)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>165 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>output = old_forward(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">166 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> module._hf_hook.post_forward(module, output)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">167 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">168 │   </span>module.forward = new_forward                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/transformers/models/llama/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_llama.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">577</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">574 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">575 │   │   │   │   </span>)                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">576 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>577 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>layer_outputs = decoder_layer(                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">578 │   │   │   │   │   </span>hidden_states,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">579 │   │   │   │   │   </span>attention_mask=attention_mask,                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">580 │   │   │   │   │   </span>position_ids=position_ids,                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">hooks.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">165</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">new_forward</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 │   │   │   │   </span>output = old_forward(*args, **kwargs)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>165 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>output = old_forward(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">166 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> module._hf_hook.post_forward(module, output)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">167 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">168 │   </span>module.forward = new_forward                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/transformers/models/llama/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_llama.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">305</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">302 │   │   # Fully Connected</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">303 │   │   </span>residual = hidden_states                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">304 │   │   </span>hidden_states = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.post_attention_layernorm(hidden_states)                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>305 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>hidden_states = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.mlp(hidden_states)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">306 │   │   </span>hidden_states = residual + hidden_states                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">307 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">308 │   │   </span>outputs = (hidden_states,)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">hooks.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">165</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">new_forward</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 │   │   │   │   </span>output = old_forward(*args, **kwargs)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>165 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>output = old_forward(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">166 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> module._hf_hook.post_forward(module, output)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">167 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">168 │   </span>module.forward = new_forward                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/transformers/models/llama/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_llama.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">157</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">154 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.act_fn = ACT2FN[hidden_act]                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">155 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">156 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, x):                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>157 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.down_proj(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.act_fn(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.gate_proj(x)) * <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.up_proj(x))            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">158 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">159 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">160 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">LlamaAttention</span>(nn.Module):                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 │   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 │   │   # Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 │   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 │   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">hooks.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">165</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">new_forward</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 │   │   │   │   </span>output = old_forward(*args, **kwargs)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>165 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>output = old_forward(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">166 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> module._hf_hook.post_forward(module, output)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">167 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">168 │   </span>module.forward = new_forward                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/bitsandbytes/nn/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modules.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">320</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">317 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias.dtype != x.dtype:                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">318 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias.data = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias.data.to(x.dtype)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">319 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>320 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>out = bnb.matmul(x, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.weight, bias=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.bias, state=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state)                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">321 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">322 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state.has_fp16_weights:                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">323 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state.CB <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state.CxB <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/bitsandbytes/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_functions.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">500</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">matmul</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">497 │   </span>state = state <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> MatmulLtState()                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">498 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> threshold &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.0</span>:                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">499 │   │   </span>state.threshold = threshold                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>500 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> MatMul8bitLt.apply(A, B, out, bias, state)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">501 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/torch/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">function.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">506</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">apply</span>                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">503 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> torch._C._are_functorch_transforms_active():                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">504 │   │   │   # See NOTE: [functorch vjp and autograd interaction]</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">505 │   │   │   </span>args = _functorch.utils.unwrap_dead_wrappers(args)                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>506 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().apply(*args, **kwargs)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># type: ignore[misc]</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">507 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">508 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>.setup_context == _SingleLevelFunction.setup_context:                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">509 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/bitsandbytes/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_functions.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">323</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">320 │   │   # 1. Quantize A</span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">321 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(A.shape) == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>:                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">322 │   │   │   </span>A = A.view(-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, A.shape[-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>]).contiguous()                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>323 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>CA, CAt, SCA, SCAt, coo_tensorA = F.double_quant(A.to(torch.float16), threshold=   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">324 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">325 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> state.threshold &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.0</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> coo_tensorA <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">326 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> state.has_fp16_weights:                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.9/dist-packages/bitsandbytes/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">functional.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1686</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">double_quant</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1683 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1684 │   │   │   </span>val, idx = torch.sort(coo_tensor.rowidx)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1685 │   │   │   </span>coo_tensor.rowidx = val                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1686 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>coo_tensor.colidx = coo_tensor.colidx[idx]                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1687 │   │   │   </span>coo_tensor.values = coo_tensor.values[idx]                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1688 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1689 │   │   │   </span>lib.cdouble_rowcol_quant(                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n","</pre>\n"],"text/plain":["\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92m<cell line: 15>\u001b[0m:\u001b[94m15\u001b[0m                                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92mlearn\u001b[0m:\u001b[94m118\u001b[0m                                                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92mtrain\u001b[0m:\u001b[94m37\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92mget_policy\u001b[0m:\u001b[94m6\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/accelerate/\u001b[0m\u001b[1;33mhooks.py\u001b[0m:\u001b[94m165\u001b[0m in \u001b[92mnew_forward\u001b[0m                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   │   │   │   \u001b[0moutput = old_forward(*args, **kwargs)                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m165 \u001b[2m│   │   │   \u001b[0moutput = old_forward(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m module._hf_hook.post_forward(module, output)                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m│   \u001b[0mmodule.forward = new_forward                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/models/llama/\u001b[0m\u001b[1;33mmodeling_llama.py\u001b[0m:\u001b[94m687\u001b[0m in        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m684 \u001b[0m\u001b[2m│   │   \u001b[0mreturn_dict = return_dict \u001b[94mif\u001b[0m return_dict \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[96mself\u001b[0m.config.use_return   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m685 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m686 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m687 \u001b[2m│   │   \u001b[0moutputs = \u001b[96mself\u001b[0m.model(                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m688 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids=input_ids,                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m689 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=attention_mask,                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m690 \u001b[0m\u001b[2m│   │   │   \u001b[0mposition_ids=position_ids,                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/accelerate/\u001b[0m\u001b[1;33mhooks.py\u001b[0m:\u001b[94m165\u001b[0m in \u001b[92mnew_forward\u001b[0m                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   │   │   │   \u001b[0moutput = old_forward(*args, **kwargs)                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m165 \u001b[2m│   │   │   \u001b[0moutput = old_forward(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m module._hf_hook.post_forward(module, output)                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m│   \u001b[0mmodule.forward = new_forward                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/models/llama/\u001b[0m\u001b[1;33mmodeling_llama.py\u001b[0m:\u001b[94m577\u001b[0m in        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m574 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mNone\u001b[0m,                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m575 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m576 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m577 \u001b[2m│   │   │   │   \u001b[0mlayer_outputs = decoder_layer(                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m578 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mhidden_states,                                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m579 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mattention_mask=attention_mask,                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m580 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mposition_ids=position_ids,                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/accelerate/\u001b[0m\u001b[1;33mhooks.py\u001b[0m:\u001b[94m165\u001b[0m in \u001b[92mnew_forward\u001b[0m                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   │   │   │   \u001b[0moutput = old_forward(*args, **kwargs)                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m165 \u001b[2m│   │   │   \u001b[0moutput = old_forward(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m module._hf_hook.post_forward(module, output)                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m│   \u001b[0mmodule.forward = new_forward                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/models/llama/\u001b[0m\u001b[1;33mmodeling_llama.py\u001b[0m:\u001b[94m305\u001b[0m in        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m302 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Fully Connected\u001b[0m                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m303 \u001b[0m\u001b[2m│   │   \u001b[0mresidual = hidden_states                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m304 \u001b[0m\u001b[2m│   │   \u001b[0mhidden_states = \u001b[96mself\u001b[0m.post_attention_layernorm(hidden_states)                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m305 \u001b[2m│   │   \u001b[0mhidden_states = \u001b[96mself\u001b[0m.mlp(hidden_states)                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m306 \u001b[0m\u001b[2m│   │   \u001b[0mhidden_states = residual + hidden_states                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m307 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m308 \u001b[0m\u001b[2m│   │   \u001b[0moutputs = (hidden_states,)                                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/accelerate/\u001b[0m\u001b[1;33mhooks.py\u001b[0m:\u001b[94m165\u001b[0m in \u001b[92mnew_forward\u001b[0m                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   │   │   │   \u001b[0moutput = old_forward(*args, **kwargs)                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m165 \u001b[2m│   │   │   \u001b[0moutput = old_forward(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m module._hf_hook.post_forward(module, output)                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m│   \u001b[0mmodule.forward = new_forward                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/transformers/models/llama/\u001b[0m\u001b[1;33mmodeling_llama.py\u001b[0m:\u001b[94m157\u001b[0m in        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[92mforward\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m154 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.act_fn = ACT2FN[hidden_act]                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m155 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, x):                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m157 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.down_proj(\u001b[96mself\u001b[0m.act_fn(\u001b[96mself\u001b[0m.gate_proj(x)) * \u001b[96mself\u001b[0m.up_proj(x))            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m158 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m160 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mLlamaAttention\u001b[0m(nn.Module):                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/accelerate/\u001b[0m\u001b[1;33mhooks.py\u001b[0m:\u001b[94m165\u001b[0m in \u001b[92mnew_forward\u001b[0m                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   │   │   │   \u001b[0moutput = old_forward(*args, **kwargs)                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m165 \u001b[2m│   │   │   \u001b[0moutput = old_forward(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m module._hf_hook.post_forward(module, output)                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m│   \u001b[0mmodule.forward = new_forward                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/bitsandbytes/nn/\u001b[0m\u001b[1;33mmodules.py\u001b[0m:\u001b[94m320\u001b[0m in \u001b[92mforward\u001b[0m                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m317 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.bias \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m \u001b[96mself\u001b[0m.bias.dtype != x.dtype:                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m318 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.bias.data = \u001b[96mself\u001b[0m.bias.data.to(x.dtype)                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m319 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m320 \u001b[2m│   │   \u001b[0mout = bnb.matmul(x, \u001b[96mself\u001b[0m.weight, bias=\u001b[96mself\u001b[0m.bias, state=\u001b[96mself\u001b[0m.state)                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m321 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m322 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m \u001b[96mself\u001b[0m.state.has_fp16_weights:                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m323 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.state.CB \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m \u001b[96mself\u001b[0m.state.CxB \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/bitsandbytes/autograd/\u001b[0m\u001b[1;33m_functions.py\u001b[0m:\u001b[94m500\u001b[0m in \u001b[92mmatmul\u001b[0m         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m497 \u001b[0m\u001b[2m│   \u001b[0mstate = state \u001b[95mor\u001b[0m MatmulLtState()                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m498 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m threshold > \u001b[94m0.0\u001b[0m:                                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m499 \u001b[0m\u001b[2m│   │   \u001b[0mstate.threshold = threshold                                                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m500 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m MatMul8bitLt.apply(A, B, out, bias, state)                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m501 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/torch/autograd/\u001b[0m\u001b[1;33mfunction.py\u001b[0m:\u001b[94m506\u001b[0m in \u001b[92mapply\u001b[0m                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m503 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m torch._C._are_functorch_transforms_active():                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m504 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# See NOTE: [functorch vjp and autograd interaction]\u001b[0m                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m505 \u001b[0m\u001b[2m│   │   │   \u001b[0margs = _functorch.utils.unwrap_dead_wrappers(args)                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m506 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96msuper\u001b[0m().apply(*args, **kwargs)  \u001b[2m# type: ignore[misc]\u001b[0m                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m507 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m508 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mcls\u001b[0m.setup_context == _SingleLevelFunction.setup_context:                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m509 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/bitsandbytes/autograd/\u001b[0m\u001b[1;33m_functions.py\u001b[0m:\u001b[94m323\u001b[0m in \u001b[92mforward\u001b[0m        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m320 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# 1. Quantize A\u001b[0m                                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m321 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(A.shape) == \u001b[94m3\u001b[0m:                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m322 \u001b[0m\u001b[2m│   │   │   \u001b[0mA = A.view(-\u001b[94m1\u001b[0m, A.shape[-\u001b[94m1\u001b[0m]).contiguous()                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m323 \u001b[2m│   │   \u001b[0mCA, CAt, SCA, SCAt, coo_tensorA = F.double_quant(A.to(torch.float16), threshold=   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m324 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m325 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m state.threshold > \u001b[94m0.0\u001b[0m \u001b[95mand\u001b[0m coo_tensorA \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m326 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m state.has_fp16_weights:                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.9/dist-packages/bitsandbytes/\u001b[0m\u001b[1;33mfunctional.py\u001b[0m:\u001b[94m1686\u001b[0m in \u001b[92mdouble_quant\u001b[0m           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1683 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1684 \u001b[0m\u001b[2m│   │   │   \u001b[0mval, idx = torch.sort(coo_tensor.rowidx)                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1685 \u001b[0m\u001b[2m│   │   │   \u001b[0mcoo_tensor.rowidx = val                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1686 \u001b[2m│   │   │   \u001b[0mcoo_tensor.colidx = coo_tensor.colidx[idx]                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1687 \u001b[0m\u001b[2m│   │   │   \u001b[0mcoo_tensor.values = coo_tensor.values[idx]                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1688 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1689 \u001b[0m\u001b[2m│   │   │   \u001b[0mlib.cdouble_rowcol_quant(                                                     \u001b[31m│\u001b[0m\n","\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n","\u001b[1;91mKeyboardInterrupt\u001b[0m\n"]},"metadata":{},"output_type":"display_data"}],"source":["log.info('Loading %s...', Game.__name__)\n","g = Game(3)\n","\n","# log.info('Loading %s...', nn.__name__)\n","\n","\n","log.info('Loading the Coach...')\n","c = Coach(g, args)\n","\n","if args.load_model:\n","    log.info(\"Loading 'trainExamples' from file...\")\n","    c.loadTrainExamples()\n","\n","log.info('Starting the learning process 🎉')\n","c.learn()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2kwbpe9VQZjM"},"outputs":[],"source":["model.save_pretrained(\"/content/drive/MyDrive/cs229proj/pretraind3\", from_pt=True) "]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPy9TrpSNyh9tIHCC/+JzeE","machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"02b58fd6e3e64702813aa310c2b8e459":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"02dc901719cf458eab4c0072e3e7ee67":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"033ff16b1afa42798711765acec529aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_492fdfd3ca1b42e9a78ccadc5bc678d5","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d6268ff8599240d8a8375a889d7178c4","value":404770755}},"03adc8dc38a14ddd80beeddb44c2fa8e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03adfaa468ec4706ba014c391ebe4632":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ce67e35bef4454e854db35295282849","IPY_MODEL_6f1c0d6641094de9b1a623bbbb4bcfec","IPY_MODEL_6306ae343baf4a4c828be4b0c4d514f3"],"layout":"IPY_MODEL_f6ddc9d7ab304ac4a1da614f6c129ffa"}},"044fbbb90c6640cc8b9ebda3c16cd72b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"04892873b0e642e989cbbace33973e88":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"049a698cbb7d4ccc98c072da50c9d915":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0531d1d2b374414ea1242d4029b5392e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"056101b4e28e43b5b257f9ef134203fd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"057123908a194f5190a0bedad16ece13":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f59330d0c0434aac8820e38c010be4e0","placeholder":"​","style":"IPY_MODEL_20fd5e0f65e94b518d9ebefb31f98a59","value":" 405M/405M [00:00&lt;00:00, 425MB/s]"}},"05986de6d71044f1a39292f028c84921":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05bc929b21e24ee29077884eade39751":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"07429a9e87b843f2b01d5c761d6e6c29":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07cdb99081ac44c2b3d06ef63b66cabc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"080ef55e07d14c788a6bae9d1166b572":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0869b7b66edd4b0dbc7e6b62d08d5855","placeholder":"​","style":"IPY_MODEL_b2bae635a39645c6bddddb4e31de11c8","value":"Downloading (…)okenizer_config.json: 100%"}},"0869b7b66edd4b0dbc7e6b62d08d5855":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08c8d23e49b74e4a8b848bb481b03729":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09202b7416b5416eb99a040f02293956":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09638b80c97949899b88253c2575c21f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_342a675926d14cc184917d0ab3074ad4","placeholder":"​","style":"IPY_MODEL_e67f476d217b485087454ad07e053a5e","value":"Downloading (…)l-00032-of-00033.bin: 100%"}},"0a254c8160a04f7797102087d8f5aa28":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0b7ec61c651249c48568a46a9c72e6f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0c7be7bbf37740ec82a7c4562345ca68":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cc5104baa8a4944acc7c4b148941c4a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d1ca330de0047cf90dd6232c2aa17fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0f6315bc1e5e43f5bb65fb4a8ab74814":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"101a83129c444fb68140afc15438ce7b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_37084fc1cd32448dbed5fc80ac4794f2","max":124,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c80f0aab39d447b5bff1b2a7225cdbfc","value":124}},"10cfb716814a4f36a30c482ce13a0054":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8b12ec0bb7c4b3bb64f6206b18e6d87","placeholder":"​","style":"IPY_MODEL_bd705b411c6d42d5af3dbe8c02572a4f","value":" 405M/405M [00:00&lt;00:00, 455MB/s]"}},"10e5af09ba1a453b826d03432f1b34b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fdb2016f20c247eeaaedbea0c98e57a0","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a5afdee8207411180d7fb93734b35cb","value":2}},"11791b9feecb4afbb839134be84b342c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11e90d7d4c4c47258ce5512837bde636":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6fdd0174607a4a5589a0ebab24c73868","placeholder":"​","style":"IPY_MODEL_f65d31b8674b4050867b8e8eee3125f8","value":" 405M/405M [00:00&lt;00:00, 461MB/s]"}},"12be3ef31b4e40dd939a44aa49d9f88e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f477940af1a43bcb186c9775692558a","placeholder":"​","style":"IPY_MODEL_2aac1b6b485048e3970547613ccfe391","value":"Downloading (…)l-00012-of-00033.bin: 100%"}},"12dc8dd6213444618b1e9d33d15a4a1e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6e4110cd072425684f1b13fd6ce81c2","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c8a126219ca842b9a551e5b13f3c9a11","value":404770755}},"13639ece1395409fb71fae2e508dbd41":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"136e7f4b3ffc43e5a6d22407502fec38":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1375ad7d5d40476fab2b41d424045918":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"140b62fca0d344d094faba56f0f93a06":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fdde59fcba0a4734b697d6eb5b0c7084","max":524297676,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a4bc89930d346588b8b532c08dfe166","value":524297676}},"163d16c53d334b33ae25eaf622ff20af":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f06eef64926441e9be98abf6736527db","placeholder":"​","style":"IPY_MODEL_56c82ae40cc84d3a8d95e8a22b14ca85","value":"Downloading (…)l-00007-of-00033.bin: 100%"}},"1659e741da2844aaad85fb2ab90f9c14":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"174faf8507e8469b94c840bbef42b078":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18b592fab0fb44c3aafc77ce68659f62":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54a2c3994d044c43987febdd36b36488","placeholder":"​","style":"IPY_MODEL_b323ba493b434d7a929dd72473b59ec0","value":"Downloading (…)l-00028-of-00033.bin: 100%"}},"18beb410ec99404f814fa354e5edda80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2393441c1684f508b6712410bd1b6b3","placeholder":"​","style":"IPY_MODEL_3c835be0c7004679859649ba023d5823","value":"Downloading (…)l-00025-of-00033.bin: 100%"}},"19ea2782063445bbb92e0b0e6dd2a1ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ba42c0c2c57450f85ed2e644804a8de":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bfb58e5f599444e87e915f406e48dd2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c4027366f3c4d448c3f30a3f87a1c95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c28ae6e6c554e7c939b92f6f30bab87","placeholder":"​","style":"IPY_MODEL_8d13cb6c86aa4dd9ab00550048ba0b30","value":" 405M/405M [00:01&lt;00:00, 469MB/s]"}},"1cd303bec54e4a54a9f55831c5c9cbd7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ce6563d3d7440eebdd7808f54507d96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_47ff2747e6d74c159296eedb2bbc209e","placeholder":"​","style":"IPY_MODEL_4a660e1a3ee048299381990a0ac0e5bf","value":" 405M/405M [00:00&lt;00:00, 474MB/s]"}},"1e1935bd9f094eb0b8041b8f3b95436c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e2fe830fb644298b100999eb81170b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_da2cc3f552d746fc81e3f5b0ee54695f","IPY_MODEL_bb09e98724d0469abffd21d174e3036d","IPY_MODEL_11e90d7d4c4c47258ce5512837bde636"],"layout":"IPY_MODEL_8c12b2ed681047c4b94031715d27c2d2"}},"1fe4ded222154edeba30e77e9260773d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03adc8dc38a14ddd80beeddb44c2fa8e","placeholder":"​","style":"IPY_MODEL_ef407fa0457e443192cc617cbe5e0f49","value":" 405M/405M [00:01&lt;00:00, 449MB/s]"}},"20fd5e0f65e94b518d9ebefb31f98a59":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"217cbdc4549b452992bf1e3312f93da1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"221c8471f00945aaa5221b007ebe751a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_09202b7416b5416eb99a040f02293956","placeholder":"​","style":"IPY_MODEL_c17bfe158dbd4a429145be8794851869","value":"Downloading (…)l-00029-of-00033.bin: 100%"}},"22380dbd2b7a4fd1894a83edcd906705":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"224199e5048c49ff9ee7bb530437ccc6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"228ba66c821f456593c94930cefdd193":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_436ce45d7fcb40a6b0852ec4b3d0efa7","placeholder":"​","style":"IPY_MODEL_761932d5e36749e0ae65f17020696a9f","value":"Downloading (…)l-00024-of-00033.bin: 100%"}},"2292e961586e4bcfb3ccb65458943e8c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"230ac2c689f44216bb50e24d7449bf4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"230c5a394fc6433bbbb5134fa3dd42cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2323fe279cd046b1bc75563a1cc8314a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45806317c9a9451d9e1780a487b379bb","placeholder":"​","style":"IPY_MODEL_259536c9d8304d0f8185920ca4210352","value":"Downloading (…)l-00015-of-00033.bin: 100%"}},"237cf120d9b6486993cf19f8a64f985e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83611a87a4b340e5afa9e34cab0df33c","placeholder":"​","style":"IPY_MODEL_b0c5b68eb43f48a189357a331b2afdf9","value":" 405M/405M [00:00&lt;00:00, 449MB/s]"}},"259536c9d8304d0f8185920ca4210352":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25ed5328fce94fa1ab41287b722b1e55":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab66dd82694d449c94d19e09491264f3","placeholder":"​","style":"IPY_MODEL_90a03cdf588c40109801ee0289d3cfad","value":" 405M/405M [00:00&lt;00:00, 462MB/s]"}},"267a440ce7b14ad49aec86f627b6af29":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2713b560b609439b8f17f4684b414eef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_806df847872f47e58bc4f628a0a0dcee","placeholder":"​","style":"IPY_MODEL_6d08e81fc23443b68c7603c504510a13","value":"Downloading (…)l-00002-of-00033.bin: 100%"}},"275e32f137ab423b886440f186f8600c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"279270a5962547beacca7ab6bfab92f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5a1a18d1d334d4baddfe5fdbed680fa","placeholder":"​","style":"IPY_MODEL_05986de6d71044f1a39292f028c84921","value":" 405M/405M [00:00&lt;00:00, 436MB/s]"}},"27e3bc5aa9bc4b759846b99964807bb2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"28b729ad75fb433486a5f82e8a639193":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ac89649a165475fa915d6717306c065","placeholder":"​","style":"IPY_MODEL_b08d5602d5d3421fbf66cd0bae9a16fc","value":" 405M/405M [00:01&lt;00:00, 416MB/s]"}},"291b4ae422794f39acc4c50658f8c398":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4dc1761688ad4f4fa9a36423188aa122","placeholder":"​","style":"IPY_MODEL_f0d9da7ab2a944d39f0f88f109499864","value":"Downloading (…)l-00021-of-00033.bin: 100%"}},"2920268322564183b5e64ba60a27c3ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"296e6204fc0c441ab46800ed0bbd3605":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2af88ddbbe6841919a59e1d659545a74","placeholder":"​","style":"IPY_MODEL_5dcaf658a59b48b7bcbfd0487fec1698","value":" 141/141 [00:00&lt;00:00, 10.2kB/s]"}},"2989d9a1d56d48d2acfbb7487633193d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c48881e87784ede84833a2a6404ac5f","IPY_MODEL_de30cb9c6a38436297cdbba37885a2ef","IPY_MODEL_3ddfcea1fe5042e6aef2f1638fa9fd0b"],"layout":"IPY_MODEL_1659e741da2844aaad85fb2ab90f9c14"}},"2a3299bf46ae44ec973732fc8bd33aa6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_136e7f4b3ffc43e5a6d22407502fec38","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5609894760754a999d40baf8a5157318","value":404770755}},"2aac1b6b485048e3970547613ccfe391":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2af07e00df4240fd9c014b0cd0ba695a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2af88ddbbe6841919a59e1d659545a74":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b6bc72951174cfdbca6bc0f277e313f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b9bd1d5afe14f95b64cd73868e8200c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b0dd2d0718604186ae849f36d3671654","IPY_MODEL_383e3567218d4771873f4788014bf741","IPY_MODEL_7b5bf6746a85489db22893309a5ae2a8"],"layout":"IPY_MODEL_e1adbaaa713b446885865937817bf0fd"}},"2bbeb52be9114e05b7477d6b8a6413e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c28ae6e6c554e7c939b92f6f30bab87":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cc77f6ca28b4e95922573984db1bbbf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cf3594ff9e34e3e8c9d3744c1845b3a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d2db084ba374a6aa25305b394c5ca6d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f1acb21268a4cf9bf3eb2dab5b43c44":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"300f4b03d77e4782a58f12613868d757":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3019805d5fd14a68ae12583aaa109edb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e7563fc0e2e641a187254627f785b8f0","IPY_MODEL_5b7ad6dd5b0c48efbf8b5abd5b4439c6","IPY_MODEL_950a01ac64324e2ca920b3f211b39d0c"],"layout":"IPY_MODEL_02dc901719cf458eab4c0072e3e7ee67"}},"30564e66c93641018d0ea9080d6e9178":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_39c2ed9224184e2d87146fc535c759f6","IPY_MODEL_a4ba4dc5ea8c402c9ac517108f8a8513","IPY_MODEL_34e8dbaae7d24356bb729e901dc02ff6"],"layout":"IPY_MODEL_bedc33aac60d41b3add4c05a091252d4"}},"309071bf77984ce79967e84407b73269":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3192e0d3d4c64c298ba9db2300ed805b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31cca05966c84f6cb3a7cbefd6d975a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_080ef55e07d14c788a6bae9d1166b572","IPY_MODEL_891030b031774d2ebbfc49b54daef975","IPY_MODEL_296e6204fc0c441ab46800ed0bbd3605"],"layout":"IPY_MODEL_4ee3c20df98347aeb0e16e8d45bcbda0"}},"326a0370bbc94612ac8843cdbdcdc6f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aa5d1cf956d04f39ae2978580a0414d1","IPY_MODEL_ba2a42f9119740b5a6a9edfb1d000f55","IPY_MODEL_76200c148d1d4ad09ded14e13c388e14"],"layout":"IPY_MODEL_300f4b03d77e4782a58f12613868d757"}},"33260738fdfc4faa80bc5d2b772ded81":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33ea174a446a4c8bb5749cf35aa9991a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"33ee693d3ab148e38582516043ff96bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"342a675926d14cc184917d0ab3074ad4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34b35fce32174340897d65c99c83db52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34e8dbaae7d24356bb729e901dc02ff6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_69261fc2e9044af78fd33e971f5da467","placeholder":"​","style":"IPY_MODEL_bfe17488de134e64abf775e1aa244843","value":" 405M/405M [00:00&lt;00:00, 433MB/s]"}},"3661989d4b854295899d2619a27099fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"37084fc1cd32448dbed5fc80ac4794f2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"383e3567218d4771873f4788014bf741":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_496f31de0798436caec837c2d98afa88","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5406db2bf51a4200a2aa50a0b9b89346","value":404770755}},"39c2ed9224184e2d87146fc535c759f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7cab19974bd4cbf86e5fcf3b571b3ab","placeholder":"​","style":"IPY_MODEL_230ac2c689f44216bb50e24d7449bf4c","value":"Downloading (…)l-00011-of-00033.bin: 100%"}},"3c835be0c7004679859649ba023d5823":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c9f789b2659472c97fa75382751c4b3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ccfbc27c29043acbcef6af6d1a47b5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_767c78406a5a4f03a3ea04a0726497d5","placeholder":"​","style":"IPY_MODEL_459e3bcaa84e445d982a2cfe3f10768d","value":"Downloading (…)l-00008-of-00033.bin: 100%"}},"3ce67e35bef4454e854db35295282849":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2292e961586e4bcfb3ccb65458943e8c","placeholder":"​","style":"IPY_MODEL_217cbdc4549b452992bf1e3312f93da1","value":"Downloading shards: 100%"}},"3ddfcea1fe5042e6aef2f1638fa9fd0b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d03feda17f894c2f8b2a8591377a3e5a","placeholder":"​","style":"IPY_MODEL_19ea2782063445bbb92e0b0e6dd2a1ed","value":" 25.5k/25.5k [00:00&lt;00:00, 1.35MB/s]"}},"3eaf2830c25b4e108f7d8ff4f5e0d555":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_221c8471f00945aaa5221b007ebe751a","IPY_MODEL_a2350b42aa05470c835636f8983e5e0e","IPY_MODEL_10cfb716814a4f36a30c482ce13a0054"],"layout":"IPY_MODEL_e424354dec9f4226be42ab07c6d10d1a"}},"3eb5221191504acaa2f3023f57d01f9e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b51f833be9d14aa08796417d5131fb89","placeholder":"​","style":"IPY_MODEL_d5ec81c262634d1aa3fb31efbe1cfa7e","value":" 405M/405M [00:07&lt;00:00, 75.3MB/s]"}},"3fc2bd19a41b430981f031a71cfa942d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbd592116f7f4b8480e2f18a3b2b9cb4","placeholder":"​","style":"IPY_MODEL_77e0b189478c49c5acca113fce59b211","value":" 405M/405M [00:00&lt;00:00, 486MB/s]"}},"4058530a8a4c4fd68d18615da5ab3d66":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4096833b255544bca501af863de2a48f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad1914fc0dd4424291770669656f3c77","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_33ee693d3ab148e38582516043ff96bf","value":404770755}},"40bdefd10a784082ad1b0992534db63a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b96734b4f8574204bd8e02e6d5d5880e","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ee91a18ae6a449c192e8681ca5012107","value":404770755}},"40ea8208a76a48b3aba23ac0005d2071":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4251140e871b43c599b53562f2fca638":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"431b1c4498454d3a993c8002731a6c32":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"436ce45d7fcb40a6b0852ec4b3d0efa7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43e272d30b0d450d9afe265412964be2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"444677ff9b1f46ffa8aadeefb4c0f888":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c7be7bbf37740ec82a7c4562345ca68","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d1ca330de0047cf90dd6232c2aa17fa","value":404770755}},"44bb6daf2909444a8603b048544a7b14":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45806317c9a9451d9e1780a487b379bb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"459e3bcaa84e445d982a2cfe3f10768d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"474125e3d35b4c5b8cd6088a4536e299":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_174faf8507e8469b94c840bbef42b078","placeholder":"​","style":"IPY_MODEL_f58400974faf4296b83b6392b7c08bca","value":" 405M/405M [00:00&lt;00:00, 419MB/s]"}},"47ff2747e6d74c159296eedb2bbc209e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"492fdfd3ca1b42e9a78ccadc5bc678d5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"496b150c67104f1cb6c17d82a67f355c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_553576da43a8411bba036a97eac1b444","placeholder":"​","style":"IPY_MODEL_bbff36bba0804aff935d06f1d136dec8","value":"Downloading (…)l-00009-of-00033.bin: 100%"}},"496f31de0798436caec837c2d98afa88":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49e3d2cd0c7540f1893892c594fb9e56":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a57a9a827ba4ba8a5f212b668810187":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ba42c0c2c57450f85ed2e644804a8de","placeholder":"​","style":"IPY_MODEL_fdada141380a42f69a83f2c86301a833","value":" 405M/405M [00:00&lt;00:00, 462MB/s]"}},"4a660e1a3ee048299381990a0ac0e5bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b5b9a0a5fea44c389ad9caf8b2a420a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c46f89faf034a82ab5dadb290190c14":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ca93de37e82426f992f55fed3e929a1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cab97120b7b487298e31250679ee56b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cbda4eeff7a4d9c84686a7a1812be32":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d2e19951ebe46ce9226aa0a171efd34":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d3d457757854832be472bbc42e2d00c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dab4ad120d745c29b2f42307003523b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cbda4eeff7a4d9c84686a7a1812be32","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_93359a1442a6497dbe9e096e230cdf34","value":404770755}},"4dc1761688ad4f4fa9a36423188aa122":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e62f76ae9544686b166f24493783dfe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e9667e23331a48cd83cd197bb2ec9db8","IPY_MODEL_2a3299bf46ae44ec973732fc8bd33aa6","IPY_MODEL_bef8027ac5694b819c1eb2e95f8e25a5"],"layout":"IPY_MODEL_50b7c3f0c68343359174acbd2e256da7"}},"4ee3c20df98347aeb0e16e8d45bcbda0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f3ff3ee545b471f9983cee836361061":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f477940af1a43bcb186c9775692558a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"509ac9e404aa40f3a1812629f9dfea40":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50b7c3f0c68343359174acbd2e256da7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51050ea48e534131aab846c44da12b50":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51635d3d50204d91a67852afe2d21fcc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"524b2064b9844e6980f2395edd39962c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5252574f0d344d79814fac0e0c5ba1e7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"538365548bc34cb9a79e1cf3c05e4452":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53b4fc3df5024193abdfa37f6c11d244":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ed1a155ec81d40adaaaa578b3fc982d5","placeholder":"​","style":"IPY_MODEL_62fe9547e6404e72a628a6f0ddd169d3","value":"Downloading (…)l-00013-of-00033.bin: 100%"}},"5406db2bf51a4200a2aa50a0b9b89346":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"54a2c3994d044c43987febdd36b36488":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5525992033a043ed8958851e0a20d757":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"553576da43a8411bba036a97eac1b444":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55a991d196d34b309524268e681ff433":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55dc35414c7e42dbb8682b953a8b06e9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5609894760754a999d40baf8a5157318":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"56c82ae40cc84d3a8d95e8a22b14ca85":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57faa31bb00d4b0881ba092167024be5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5901207325ce46aeaf752a752127251a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59269357b6644033b7a55afd4225543b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5954be8ed4de45dca077a61827f58f7d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"59f9515d99e043d387d7548fed99c29b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b7ad6dd5b0c48efbf8b5abd5b4439c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1cd303bec54e4a54a9f55831c5c9cbd7","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_524b2064b9844e6980f2395edd39962c","value":404770755}},"5b8aa4241cf94ca6bfc76b10ed0a579b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cab97120b7b487298e31250679ee56b","placeholder":"​","style":"IPY_MODEL_7db5d7c87836463eabcd6f4d4d0a7ca6","value":" 427/427 [00:00&lt;00:00, 22.7kB/s]"}},"5bc9f721e8fc469593108daa03cb6574":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e21c7f3c3b34424980d7cdddbd26f0e2","placeholder":"​","style":"IPY_MODEL_b7710d76d4ce43f78db7297f110c6bd5","value":"Downloading (…)l-00033-of-00033.bin: 100%"}},"5c800f3e95a747e8b97a1209a50ceb2b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5dcaf658a59b48b7bcbfd0487fec1698":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ed86517d80b4ca6b143be263a39ee38":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1b63017ec9e46acae9cd00cf4c7b583","placeholder":"​","style":"IPY_MODEL_65a3267c85e246869e408a0ff4a97a2b","value":" 500k/500k [00:00&lt;00:00, 17.7MB/s]"}},"5fc5b2a4b7c9432996ab114e71fd2ce5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6051455ec9304e73beb2b21c892f8f0b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"611bcfd221314b67b107741761e9ecd1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b36d93c5ccb14b8690d173bd5f73c2f3","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_27e3bc5aa9bc4b759846b99964807bb2","value":404770755}},"61b179a79400441f801c319a5ca06dfa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61ccad893b494587b538d1d4789c078f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"621ecaf45a3d4fd7a5779b558d7eba9c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"622b8620e4f24d6880fe750eb5e32296":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9c8d439953f4241bd424a8de55366e3","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b7f83d7c8b19459fb603122b5a5db404","value":404770755}},"62f5e6d2df744773bfd1d38f8bc8726f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c71d50520c564ce08c2fe8ef82ea444e","placeholder":"​","style":"IPY_MODEL_94b554e148a4459787597e960b4c94a6","value":"Downloading (…)l-00022-of-00033.bin: 100%"}},"62fe9547e6404e72a628a6f0ddd169d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6306ae343baf4a4c828be4b0c4d514f3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4251140e871b43c599b53562f2fca638","placeholder":"​","style":"IPY_MODEL_6b65c0f4e0eb44a09c67207e2dc3b256","value":" 33/33 [00:48&lt;00:00,  1.29s/it]"}},"6324ffc664b54a92817c0b9e53855ada":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6338aea8892f40048863ccba6d800c33":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63bc83a2ff11415ab82234960b2de4ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6491df7e510a49609a9c971f4c046cb5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2af07e00df4240fd9c014b0cd0ba695a","placeholder":"​","style":"IPY_MODEL_5525992033a043ed8958851e0a20d757","value":"Downloading (…)l-00017-of-00033.bin: 100%"}},"65a3267c85e246869e408a0ff4a97a2b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"675ae21144054138a9a27496f546124a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6897df6af87c453c99902b732599a0db":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68b504c242fd4a3a8822cba4e15aebed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72604a0a39cf4d96907bc1a85b4adcf2","placeholder":"​","style":"IPY_MODEL_13639ece1395409fb71fae2e508dbd41","value":"Downloading (…)l-00006-of-00033.bin: 100%"}},"69261fc2e9044af78fd33e971f5da467":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a633e4948f846a59a20ef06d87f0f1a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_12be3ef31b4e40dd939a44aa49d9f88e","IPY_MODEL_89d8bd0d45e34080b0cd8a1b49a87a8c","IPY_MODEL_4a57a9a827ba4ba8a5f212b668810187"],"layout":"IPY_MODEL_837095352e2f4827a07c25aa39e6c73c"}},"6af6692c58e04fdeaa5cb1794a2502ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d663936857b34349b663f04e658d4f79","placeholder":"​","style":"IPY_MODEL_c7ef005be75b44688983b750b670aa83","value":" 2.00/2.00 [00:00&lt;00:00, 111B/s]"}},"6b65c0f4e0eb44a09c67207e2dc3b256":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b6b14dcfaf640e28123232d130af904":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_163d16c53d334b33ae25eaf622ff20af","IPY_MODEL_033ff16b1afa42798711765acec529aa","IPY_MODEL_1ce6563d3d7440eebdd7808f54507d96"],"layout":"IPY_MODEL_4ca93de37e82426f992f55fed3e929a1"}},"6d08e81fc23443b68c7603c504510a13":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d662b3e834d4d3e8b2924bb155dff6e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eaf5d16ad0d6476f8114f3d48382d5bc","max":499723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc4e77f23f0345e28362eaf5b1fdcf4b","value":499723}},"6f1c0d6641094de9b1a623bbbb4bcfec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6051455ec9304e73beb2b21c892f8f0b","max":33,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9fefd41b0f6f41eb8e6b30c61afe65ff","value":33}},"6fd5c0b2b30e4a9baeaa1e7438684750":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f2991dc06b0649488805508d7c4ab514","IPY_MODEL_622b8620e4f24d6880fe750eb5e32296","IPY_MODEL_d5b05b085c5f479889a904311a2607ea"],"layout":"IPY_MODEL_538365548bc34cb9a79e1cf3c05e4452"}},"6fdd0174607a4a5589a0ebab24c73868":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70569314bb03436d87a5cc466e4af9dc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70f301f0ac404fd2beb36bed90f5f87e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_291b4ae422794f39acc4c50658f8c398","IPY_MODEL_80e81f4bc0cd4e2c8c12a9c745a5ab46","IPY_MODEL_057123908a194f5190a0bedad16ece13"],"layout":"IPY_MODEL_8f28afab2d364f849ae34bc24bdbe047"}},"716cad98991248acb3f7e40b83811a4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8f062c5fa3c54dbb8e7849fe04b764e0","IPY_MODEL_101a83129c444fb68140afc15438ce7b","IPY_MODEL_b2a06ca62e2f47d1b76d88e7e3f3153e"],"layout":"IPY_MODEL_dc3bddd862f74488a3bb94de941b5253"}},"72604a0a39cf4d96907bc1a85b4adcf2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7327897a1fc14ffb88a80c09d09741d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7369b61e99d94034a8c84f6b51496584":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"73a0fe92b5a049868e0f2e04f949b8cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"749dd6dfa80948c58a6ebb241851d2aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74b522861d6f4a12959fbb2801cb3a91":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fccc9f29b16b4eab9c57a26141bf564e","IPY_MODEL_da34bb387f12428c858ef69e4fe0ed39","IPY_MODEL_1c4027366f3c4d448c3f30a3f87a1c95"],"layout":"IPY_MODEL_c63781df290b40929fe0b92aac51790b"}},"761932d5e36749e0ae65f17020696a9f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76200c148d1d4ad09ded14e13c388e14":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81d1482374ff4fac9880d604f8c3fcf2","placeholder":"​","style":"IPY_MODEL_309071bf77984ce79967e84407b73269","value":" 405M/405M [00:00&lt;00:00, 453MB/s]"}},"767c78406a5a4f03a3ea04a0726497d5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76ae2522e0334b6fbaa1c4df0a0358b5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"772ebb281bdc449fa5973c63957c6dab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_275e32f137ab423b886440f186f8600c","placeholder":"​","style":"IPY_MODEL_a93fd5d66649411aab73d8dbe5b1d131","value":"Downloading (…)l-00005-of-00033.bin: 100%"}},"77c14af5b2f94e49a7e5442e4666b4fa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77e0b189478c49c5acca113fce59b211":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"78cef5111af246bc9c580cc24b4f4291":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5bc9f721e8fc469593108daa03cb6574","IPY_MODEL_140b62fca0d344d094faba56f0f93a06","IPY_MODEL_7e252a6428844436a9eedc0cd7bde7d5"],"layout":"IPY_MODEL_a165b1d9d6d9411ebbfa19872942c2f3"}},"79c336da6677462abc0d43b0d75a8798":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_edd6fa8825194c8aa15396dcee532f56","IPY_MODEL_f1a604336e6642ac8d8576cce68103be","IPY_MODEL_3fc2bd19a41b430981f031a71cfa942d"],"layout":"IPY_MODEL_c203332179b140b4854ae6a2af347f5e"}},"7a4bc89930d346588b8b532c08dfe166":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a5afdee8207411180d7fb93734b35cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a6bdd782f2843fb95c3df481b5e86a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c07282a57d5a4ca1be9cb0e4a84c58dc","IPY_MODEL_edd1d59f8331467fa8f7935a9c6bbfb3","IPY_MODEL_5b8aa4241cf94ca6bfc76b10ed0a579b"],"layout":"IPY_MODEL_07429a9e87b843f2b01d5c761d6e6c29"}},"7aa7585d4690435ab4373397e79e0744":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ac89649a165475fa915d6717306c065":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b5bf6746a85489db22893309a5ae2a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd41362a444649be961103bedbba6742","placeholder":"​","style":"IPY_MODEL_dc63e0b9527846c4bb843617c3a92e16","value":" 405M/405M [00:00&lt;00:00, 464MB/s]"}},"7c10fffe2ddb421e9e5c3d0a590e1e91":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c3497c97cb24475ac1e198ca2a63cc3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d3e34a22d674575b6f62c4e261fffa4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7db5d7c87836463eabcd6f4d4d0a7ca6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e252a6428844436a9eedc0cd7bde7d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70569314bb03436d87a5cc466e4af9dc","placeholder":"​","style":"IPY_MODEL_c6ef1df59fd84a6d8e5fa8d59612c387","value":" 524M/524M [00:01&lt;00:00, 450MB/s]"}},"8033f1942ec5422a8c71a3102211e8d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb48a65651bc46b09c397bb517ce7cb9","IPY_MODEL_4dab4ad120d745c29b2f42307003523b","IPY_MODEL_1fe4ded222154edeba30e77e9260773d"],"layout":"IPY_MODEL_81bf2ba42fe64e639967f2e54b6af73c"}},"806df847872f47e58bc4f628a0a0dcee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80e81f4bc0cd4e2c8c12a9c745a5ab46":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c865db7d7af1446c8441e2fec5fc96b8","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b2c603cc81af48b6bdf4e56bf3c71a9d","value":404770755}},"811723bc79b14d7cbdeaf4b8fedb9067":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3192e0d3d4c64c298ba9db2300ed805b","placeholder":"​","style":"IPY_MODEL_0b7ec61c651249c48568a46a9c72e6f4","value":" 405M/405M [00:00&lt;00:00, 474MB/s]"}},"81bf2ba42fe64e639967f2e54b6af73c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81d1482374ff4fac9880d604f8c3fcf2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"834327cdea334a8a8f155c4e636c9b05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"83611a87a4b340e5afa9e34cab0df33c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"837095352e2f4827a07c25aa39e6c73c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86463fa528c04a0f9cf0bf11cdd2a996":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86650cf5f66349aa88bc6c6246955a29":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db796914c43448cdb07c55df71216b82","placeholder":"​","style":"IPY_MODEL_f74fe44e1bb341809436acbb5e5abc8c","value":" 405M/405M [00:00&lt;00:00, 459MB/s]"}},"86be58cdc80d494a9283592cfff434f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"875b15f894574b9cbbf0c150dcb5257c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87852e152acb42ce9905812b314d04b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c1063d696d8d417a8470c9cf5131d30d","IPY_MODEL_12dc8dd6213444618b1e9d33d15a4a1e","IPY_MODEL_86650cf5f66349aa88bc6c6246955a29"],"layout":"IPY_MODEL_11791b9feecb4afbb839134be84b342c"}},"88ef750286674c39bb2170ac58d983ca":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"891030b031774d2ebbfc49b54daef975":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6a2dfd63b75451db3b4b977581b059e","max":141,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9db8b790e14c49a6b3c0d5b419df24ed","value":141}},"89d8bd0d45e34080b0cd8a1b49a87a8c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c9f789b2659472c97fa75382751c4b3","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd31cb861c114218a1ab377a607b1667","value":404770755}},"8b1d07ac27944d079ba03cbfdc367019":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6491df7e510a49609a9c971f4c046cb5","IPY_MODEL_611bcfd221314b67b107741761e9ecd1","IPY_MODEL_feaf16c83b314035b4cfce3554ff5490"],"layout":"IPY_MODEL_43e272d30b0d450d9afe265412964be2"}},"8bebcc05ca254a5c8e81081c67bdba1e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bf6bd57937041109750a62a1f605aa1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c12b2ed681047c4b94031715d27c2d2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ca3047266884168a377bba848f646dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_04892873b0e642e989cbbace33973e88","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fdbba0bd6a194816b6750772a886f211","value":404770755}},"8d13cb6c86aa4dd9ab00550048ba0b30":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e7e9e1857634db981d9aee2e63ec374":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9ba0c629bb74e6aa42e3b55c3ee378b","placeholder":"​","style":"IPY_MODEL_cf5436a706c148e1a75cad0ac25598e1","value":"Downloading (…)l-00030-of-00033.bin: 100%"}},"8f062c5fa3c54dbb8e7849fe04b764e0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a93bd244eb0f4e8a8cb778314b2a1e8f","placeholder":"​","style":"IPY_MODEL_b296f220dc5a4df881eb984e30b3c242","value":"Downloading (…)neration_config.json: 100%"}},"8f28afab2d364f849ae34bc24bdbe047":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f6dbe64e5ae4eada01ed59a72163a3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_55a991d196d34b309524268e681ff433","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_049a698cbb7d4ccc98c072da50c9d915","value":404770755}},"9036bd5283d14584822543a779408dbb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"904b2155d41b4a7d8cd95c1b8d885e04":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_228ba66c821f456593c94930cefdd193","IPY_MODEL_d56110e3f7b0453cabe6f0a741b4fb80","IPY_MODEL_25ed5328fce94fa1ab41287b722b1e55"],"layout":"IPY_MODEL_97ff210e18fb43469b1d5e796b5076cd"}},"906b92e0dc2a42459530769df13081ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6fb4431bb3d4ce88aaa987de311d74b","placeholder":"​","style":"IPY_MODEL_05bc929b21e24ee29077884eade39751","value":" 33/33 [00:19&lt;00:00,  1.85it/s]"}},"90a03cdf588c40109801ee0289d3cfad":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"917de8cc343e49ffa35d83808ca2ca67":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93359a1442a6497dbe9e096e230cdf34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"93ccf0d2022b465fb99d68dae70d4d68":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"941e9ef486ca4725be64315930371b31":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_59f9515d99e043d387d7548fed99c29b","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e170b0563734813b2cca07e30698ef0","value":404770755}},"94b554e148a4459787597e960b4c94a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"950a01ac64324e2ca920b3f211b39d0c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2cc77f6ca28b4e95922573984db1bbbf","placeholder":"​","style":"IPY_MODEL_b5c7b6dd0212458abd3878695c29307d","value":" 405M/405M [00:00&lt;00:00, 441MB/s]"}},"95dce5ca6887461a860852357dfaa2d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55dc35414c7e42dbb8682b953a8b06e9","placeholder":"​","style":"IPY_MODEL_0a254c8160a04f7797102087d8f5aa28","value":" 405M/405M [00:00&lt;00:00, 433MB/s]"}},"96ba4e86d54347c4a205dfa2b54e0fe1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96f09e2e68dc4a22980d584beecb2692":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"976761ca52034ed0ba22356c0821e84d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97a595ea27794f838a64dc1c2e060263":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a87f84ff30f241d2ab883c234d8d52a2","placeholder":"​","style":"IPY_MODEL_044fbbb90c6640cc8b9ebda3c16cd72b","value":" 405M/405M [00:01&lt;00:00, 406MB/s]"}},"97ff210e18fb43469b1d5e796b5076cd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99fee544842249d59ede89e21aeda41b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d2e19951ebe46ce9226aa0a171efd34","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a7d9818c24e54c199907ea236bb725fc","value":404770755}},"9c48881e87784ede84833a2a6404ac5f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0cc5104baa8a4944acc7c4b148941c4a","placeholder":"​","style":"IPY_MODEL_2f1acb21268a4cf9bf3eb2dab5b43c44","value":"Downloading (…)model.bin.index.json: 100%"}},"9c80b2dbd26c4f5d8b36312032c9423e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9db8b790e14c49a6b3c0d5b419df24ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9e170b0563734813b2cca07e30698ef0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9e40a606239547398923e187d088256a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_76ae2522e0334b6fbaa1c4df0a0358b5","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8bf6bd57937041109750a62a1f605aa1","value":404770755}},"9e7c2943ea034b4dbb34ef61720c527e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fefd41b0f6f41eb8e6b30c61afe65ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a165b1d9d6d9411ebbfa19872942c2f3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1a2760281254e7bb74af8e2909bba01":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_18beb410ec99404f814fa354e5edda80","IPY_MODEL_fec17c6b41894f63ab7bbb81d62657cb","IPY_MODEL_474125e3d35b4c5b8cd6088a4536e299"],"layout":"IPY_MODEL_b391f47369d043a8b0697f22e67d53ee"}},"a2350b42aa05470c835636f8983e5e0e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3cb484eb0dd4889a0d17addf7e9e3bc","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_40ea8208a76a48b3aba23ac0005d2071","value":404770755}},"a274061fabf74a3fa60f8bd6fba18581":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4afbc35d1664c48b764ba3bad454466":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4ba4dc5ea8c402c9ac517108f8a8513":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_33260738fdfc4faa80bc5d2b772ded81","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_73a0fe92b5a049868e0f2e04f949b8cc","value":404770755}},"a52e950e50564e8abaa2cd03d4efc0d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c46f89faf034a82ab5dadb290190c14","placeholder":"​","style":"IPY_MODEL_07cdb99081ac44c2b3d06ef63b66cabc","value":"Downloading tokenizer.model: 100%"}},"a5c865cf2f334096979fcd805351876b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e1935bd9f094eb0b8041b8f3b95436c","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_02b58fd6e3e64702813aa310c2b8e459","value":404770755}},"a664fadb5c84459eade67e52e9fa3841":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ece4ebd5a024472da4632c9ad3df489c","IPY_MODEL_4096833b255544bca501af863de2a48f","IPY_MODEL_b916676b7076423f8c616328a391666d"],"layout":"IPY_MODEL_976761ca52034ed0ba22356c0821e84d"}},"a6e4110cd072425684f1b13fd6ce81c2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7d757c5e2aa4578aed32d65038e36f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab6e0280765040d381698a4ab7955cd4","placeholder":"​","style":"IPY_MODEL_da901fcb1941421e9445915a33d85195","value":" 405M/405M [00:00&lt;00:00, 481MB/s]"}},"a7d9818c24e54c199907ea236bb725fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a87f84ff30f241d2ab883c234d8d52a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a93bd244eb0f4e8a8cb778314b2a1e8f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a93fd5d66649411aab73d8dbe5b1d131":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a98cbefbfa5e4b8fbcb0017f2f508583":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa5d1cf956d04f39ae2978580a0414d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49e3d2cd0c7540f1893892c594fb9e56","placeholder":"​","style":"IPY_MODEL_f19ab356113b4926bd8f370f929cfc97","value":"Downloading (…)l-00003-of-00033.bin: 100%"}},"aaf8d98ee15544aabc069ff4a5b99ec4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_53b4fc3df5024193abdfa37f6c11d244","IPY_MODEL_d9e75af7c70a4a3985e740cfcaf4808d","IPY_MODEL_95dce5ca6887461a860852357dfaa2d8"],"layout":"IPY_MODEL_1bfb58e5f599444e87e915f406e48dd2"}},"ab66dd82694d449c94d19e09491264f3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab6e0280765040d381698a4ab7955cd4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acf2b6eaec424613967d90464e52323f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_224199e5048c49ff9ee7bb530437ccc6","placeholder":"​","style":"IPY_MODEL_4b5b9a0a5fea44c389ad9caf8b2a420a","value":" 405M/405M [00:00&lt;00:00, 485MB/s]"}},"ad1914fc0dd4424291770669656f3c77":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adf2a17d826749438a74b4eeb050ed8e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b08d5602d5d3421fbf66cd0bae9a16fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0c5b68eb43f48a189357a331b2afdf9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0dd2d0718604186ae849f36d3671654":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_86463fa528c04a0f9cf0bf11cdd2a996","placeholder":"​","style":"IPY_MODEL_d60df0c6f9364b0bb9db5455f6a2498d","value":"Downloading (…)l-00027-of-00033.bin: 100%"}},"b2215ef477b641d486a65a049f138a4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_68b504c242fd4a3a8822cba4e15aebed","IPY_MODEL_40bdefd10a784082ad1b0992534db63a","IPY_MODEL_97a595ea27794f838a64dc1c2e060263"],"layout":"IPY_MODEL_88ef750286674c39bb2170ac58d983ca"}},"b296f220dc5a4df881eb984e30b3c242":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2a06ca62e2f47d1b76d88e7e3f3153e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec92d8aa4c804d1fbfd1b3f8d5a389a4","placeholder":"​","style":"IPY_MODEL_7aa7585d4690435ab4373397e79e0744","value":" 124/124 [00:00&lt;00:00, 7.62kB/s]"}},"b2bae635a39645c6bddddb4e31de11c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b2c603cc81af48b6bdf4e56bf3c71a9d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b323ba493b434d7a929dd72473b59ec0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b36185910e4f4e2b8703c59531be8917":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b36d93c5ccb14b8690d173bd5f73c2f3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b391f47369d043a8b0697f22e67d53ee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b45b8a3049694e21903984bdaaed1b34":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b51f833be9d14aa08796417d5131fb89":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5c7b6dd0212458abd3878695c29307d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7710d76d4ce43f78db7297f110c6bd5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7f83d7c8b19459fb603122b5a5db404":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b916676b7076423f8c616328a391666d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61ccad893b494587b538d1d4789c078f","placeholder":"​","style":"IPY_MODEL_5c800f3e95a747e8b97a1209a50ceb2b","value":" 405M/405M [00:00&lt;00:00, 460MB/s]"}},"b96734b4f8574204bd8e02e6d5d5880e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b99f9088154d402f92e64c5a86125810":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba2a42f9119740b5a6a9edfb1d000f55":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_63bc83a2ff11415ab82234960b2de4ee","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_daf3e22b4dbe455484d54560856114dc","value":404770755}},"bb09e98724d0469abffd21d174e3036d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4e8fa4e620a4cd2bc11dea1b8c64009","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_96f09e2e68dc4a22980d584beecb2692","value":404770755}},"bb41f5814bdd470e821954a561278297":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bbff36bba0804aff935d06f1d136dec8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd31cb861c114218a1ab377a607b1667":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bd705b411c6d42d5af3dbe8c02572a4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bedc33aac60d41b3add4c05a091252d4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bef8027ac5694b819c1eb2e95f8e25a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a98cbefbfa5e4b8fbcb0017f2f508583","placeholder":"​","style":"IPY_MODEL_bb41f5814bdd470e821954a561278297","value":" 405M/405M [00:00&lt;00:00, 508MB/s]"}},"bfe17488de134e64abf775e1aa244843":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bfebb4958fc848b0ab9f9a4fd9e8b0ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ccfbc27c29043acbcef6af6d1a47b5e","IPY_MODEL_c96d84b11d0a47919fc49964a44d2a23","IPY_MODEL_279270a5962547beacca7ab6bfab92f0"],"layout":"IPY_MODEL_2bbeb52be9114e05b7477d6b8a6413e1"}},"c07282a57d5a4ca1be9cb0e4a84c58dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_675ae21144054138a9a27496f546124a","placeholder":"​","style":"IPY_MODEL_e6e0a79f815c4bbc832cb2456349f39a","value":"Downloading (…)lve/main/config.json: 100%"}},"c09383fbe20345bfa3552beebc06c6cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_056101b4e28e43b5b257f9ef134203fd","placeholder":"​","style":"IPY_MODEL_44bb6daf2909444a8603b048544a7b14","value":"Loading checkpoint shards: 100%"}},"c1063d696d8d417a8470c9cf5131d30d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61b179a79400441f801c319a5ca06dfa","placeholder":"​","style":"IPY_MODEL_d9dd0458c7df4f29830db1cce793a465","value":"Downloading (…)l-00023-of-00033.bin: 100%"}},"c17bfe158dbd4a429145be8794851869":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c203332179b140b4854ae6a2af347f5e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4bdf3a1d07048d6adb32d88bdd0dcf4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a274061fabf74a3fa60f8bd6fba18581","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ea65daa886c2432cb8d2486c0c2795e6","value":404770755}},"c5a1a18d1d334d4baddfe5fdbed680fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c63781df290b40929fe0b92aac51790b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6ef1df59fd84a6d8e5fa8d59612c387":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c71d50520c564ce08c2fe8ef82ea444e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c76a85d2f842492ebbd6c350a23ea125":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c77ca6c604cc44a69d7f9f6c4f725176","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_230c5a394fc6433bbbb5134fa3dd42cb","value":404770755}},"c77ca6c604cc44a69d7f9f6c4f725176":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7ef005be75b44688983b750b670aa83":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c80f0aab39d447b5bff1b2a7225cdbfc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c865db7d7af1446c8441e2fec5fc96b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8a126219ca842b9a551e5b13f3c9a11":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c8b12ec0bb7c4b3bb64f6206b18e6d87":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c96d84b11d0a47919fc49964a44d2a23":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f8a7a2b0f1084f9c9b0295ff697832bf","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_86be58cdc80d494a9283592cfff434f5","value":404770755}},"c9c8d439953f4241bd424a8de55366e3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb48a65651bc46b09c397bb517ce7cb9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2612f3ab4f84a9a8def02dc2c3c124c","placeholder":"​","style":"IPY_MODEL_96ba4e86d54347c4a205dfa2b54e0fe1","value":"Downloading (…)l-00004-of-00033.bin: 100%"}},"cc8b877145d5422aa4abb1fa69d872b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_496b150c67104f1cb6c17d82a67f355c","IPY_MODEL_9e40a606239547398923e187d088256a","IPY_MODEL_3eb5221191504acaa2f3023f57d01f9e"],"layout":"IPY_MODEL_f26e617647ef4740bdb4df6ecacf12ce"}},"ccc9c9302ff849738d953afc3c528b7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c09383fbe20345bfa3552beebc06c6cc","IPY_MODEL_de1c52b1b72e43a296d495563cbbc69f","IPY_MODEL_906b92e0dc2a42459530769df13081ac"],"layout":"IPY_MODEL_6338aea8892f40048863ccba6d800c33"}},"cd41362a444649be961103bedbba6742":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce393a99d58c47c2b2ec8ce1f704d0e8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce450ceaf7964143a5525cffffcc1fb0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf05d1ab847a4b7da15ca8e7c47c7066":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8e7e9e1857634db981d9aee2e63ec374","IPY_MODEL_99fee544842249d59ede89e21aeda41b","IPY_MODEL_a7d757c5e2aa4578aed32d65038e36f4"],"layout":"IPY_MODEL_875b15f894574b9cbbf0c150dcb5257c"}},"cf5436a706c148e1a75cad0ac25598e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d03feda17f894c2f8b2a8591377a3e5a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d19e7998c9154fe7aa74c1dd0a5ac0e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2393441c1684f508b6712410bd1b6b3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2612f3ab4f84a9a8def02dc2c3c124c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d29327c4fd4941c4a87d47854d2d3939":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d304e664b57240dc833f06b6dc55c5d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_09638b80c97949899b88253c2575c21f","IPY_MODEL_941e9ef486ca4725be64315930371b31","IPY_MODEL_237cf120d9b6486993cf19f8a64f985e"],"layout":"IPY_MODEL_431b1c4498454d3a993c8002731a6c32"}},"d32f233ee3124d49945e71dbe71ed11d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d3cb484eb0dd4889a0d17addf7e9e3bc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3f34db45df34f67b8df3940e7707d50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_772ebb281bdc449fa5973c63957c6dab","IPY_MODEL_8ca3047266884168a377bba848f646dc","IPY_MODEL_28b729ad75fb433486a5f82e8a639193"],"layout":"IPY_MODEL_08c8d23e49b74e4a8b848bb481b03729"}},"d4e8fa4e620a4cd2bc11dea1b8c64009":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d56110e3f7b0453cabe6f0a741b4fb80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4afbc35d1664c48b764ba3bad454466","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7327897a1fc14ffb88a80c09d09741d1","value":404770755}},"d5b05b085c5f479889a904311a2607ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff39181bdd104a7e8a6e447e8996dc64","placeholder":"​","style":"IPY_MODEL_7c10fffe2ddb421e9e5c3d0a590e1e91","value":" 405M/405M [00:01&lt;00:00, 419MB/s]"}},"d5ec81c262634d1aa3fb31efbe1cfa7e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d60df0c6f9364b0bb9db5455f6a2498d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d6268ff8599240d8a8375a889d7178c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d663936857b34349b663f04e658d4f79":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7251ab77c64462087ea4b645d16b7ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ce393a99d58c47c2b2ec8ce1f704d0e8","placeholder":"​","style":"IPY_MODEL_77c14af5b2f94e49a7e5442e4666b4fa","value":" 405M/405M [00:00&lt;00:00, 476MB/s]"}},"d7eff3cb51f141278054d630255c6ada":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b36185910e4f4e2b8703c59531be8917","placeholder":"​","style":"IPY_MODEL_509ac9e404aa40f3a1812629f9dfea40","value":"Downloading (…)l-00018-of-00033.bin: 100%"}},"d93464e84cc147169bbb2523d0794a5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e7c2943ea034b4dbb34ef61720c527e","placeholder":"​","style":"IPY_MODEL_ce450ceaf7964143a5525cffffcc1fb0","value":" 405M/405M [00:00&lt;00:00, 456MB/s]"}},"d9dd0458c7df4f29830db1cce793a465":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d9e75af7c70a4a3985e740cfcaf4808d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4058530a8a4c4fd68d18615da5ab3d66","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fa85c23f76ea415ba22dc00372d5b076","value":404770755}},"da2cc3f552d746fc81e3f5b0ee54695f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d29327c4fd4941c4a87d47854d2d3939","placeholder":"​","style":"IPY_MODEL_34b35fce32174340897d65c99c83db52","value":"Downloading (…)l-00019-of-00033.bin: 100%"}},"da34bb387f12428c858ef69e4fe0ed39":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d3e34a22d674575b6f62c4e261fffa4","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5fc5b2a4b7c9432996ab114e71fd2ce5","value":404770755}},"da901fcb1941421e9445915a33d85195":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"daf3e22b4dbe455484d54560856114dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"db796914c43448cdb07c55df71216b82":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbcb503d914b42ea9bc5236e5d0359dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_621ecaf45a3d4fd7a5779b558d7eba9c","placeholder":"​","style":"IPY_MODEL_5954be8ed4de45dca077a61827f58f7d","value":"Downloading (…)cial_tokens_map.json: 100%"}},"dc3bddd862f74488a3bb94de941b5253":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc4e77f23f0345e28362eaf5b1fdcf4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dc5f56ce4be94c88b01533f1777d33dd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc63e0b9527846c4bb843617c3a92e16":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de1c52b1b72e43a296d495563cbbc69f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e58c88f5046e4aabb2720cd189a41449","max":33,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0f6315bc1e5e43f5bb65fb4a8ab74814","value":33}},"de30cb9c6a38436297cdbba37885a2ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5d677b263e44a5691cc69806ba7b2b8","max":25477,"min":0,"orientation":"horizontal","style":"IPY_MODEL_33ea174a446a4c8bb5749cf35aa9991a","value":25477}},"ded04993afcc4fbfb18a0e54a295d3f5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a52e950e50564e8abaa2cd03d4efc0d5","IPY_MODEL_6d662b3e834d4d3e8b2924bb155dff6e","IPY_MODEL_5ed86517d80b4ca6b143be263a39ee38"],"layout":"IPY_MODEL_1375ad7d5d40476fab2b41d424045918"}},"dfbc96b7a92b45f380229d13b7817ce6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc5f56ce4be94c88b01533f1777d33dd","placeholder":"​","style":"IPY_MODEL_f28a2b6ce504415db8b90671da5259f8","value":"Downloading (…)l-00010-of-00033.bin: 100%"}},"e1adbaaa713b446885865937817bf0fd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1b63017ec9e46acae9cd00cf4c7b583":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e21c7f3c3b34424980d7cdddbd26f0e2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e424354dec9f4226be42ab07c6d10d1a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e58c88f5046e4aabb2720cd189a41449":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e67f476d217b485087454ad07e053a5e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6a2dfd63b75451db3b4b977581b059e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6e0a79f815c4bbc832cb2456349f39a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7563fc0e2e641a187254627f785b8f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_917de8cc343e49ffa35d83808ca2ca67","placeholder":"​","style":"IPY_MODEL_3661989d4b854295899d2619a27099fd","value":"Downloading (…)l-00016-of-00033.bin: 100%"}},"e8b6b8d2382646ea9db91c6b381174ea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2713b560b609439b8f17f4684b414eef","IPY_MODEL_a5c865cf2f334096979fcd805351876b","IPY_MODEL_acf2b6eaec424613967d90464e52323f"],"layout":"IPY_MODEL_0531d1d2b374414ea1242d4029b5392e"}},"e9667e23331a48cd83cd197bb2ec9db8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b45b8a3049694e21903984bdaaed1b34","placeholder":"​","style":"IPY_MODEL_2cf3594ff9e34e3e8c9d3744c1845b3a","value":"Downloading (…)l-00031-of-00033.bin: 100%"}},"e9ba0c629bb74e6aa42e3b55c3ee378b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea65daa886c2432cb8d2486c0c2795e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eaf5d16ad0d6476f8114f3d48382d5bc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eba8f36a561b48f58b971ba849c1873e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d7eff3cb51f141278054d630255c6ada","IPY_MODEL_444677ff9b1f46ffa8aadeefb4c0f888","IPY_MODEL_811723bc79b14d7cbdeaf4b8fedb9067"],"layout":"IPY_MODEL_b99f9088154d402f92e64c5a86125810"}},"ec92d8aa4c804d1fbfd1b3f8d5a389a4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecb27d8aa7804e399e8dc4ddd4fffc49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dbcb503d914b42ea9bc5236e5d0359dd","IPY_MODEL_10e5af09ba1a453b826d03432f1b34b7","IPY_MODEL_6af6692c58e04fdeaa5cb1794a2502ca"],"layout":"IPY_MODEL_2920268322564183b5e64ba60a27c3ab"}},"ece4ebd5a024472da4632c9ad3df489c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_51635d3d50204d91a67852afe2d21fcc","placeholder":"​","style":"IPY_MODEL_7c3497c97cb24475ac1e198ca2a63cc3","value":"Downloading (…)l-00020-of-00033.bin: 100%"}},"ed1a155ec81d40adaaaa578b3fc982d5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edd1d59f8331467fa8f7935a9c6bbfb3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5252574f0d344d79814fac0e0c5ba1e7","max":427,"min":0,"orientation":"horizontal","style":"IPY_MODEL_834327cdea334a8a8f155c4e636c9b05","value":427}},"edd6fa8825194c8aa15396dcee532f56":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2b6bc72951174cfdbca6bc0f277e313f","placeholder":"​","style":"IPY_MODEL_22380dbd2b7a4fd1894a83edcd906705","value":"Downloading (…)l-00014-of-00033.bin: 100%"}},"ee3ad2d627ab49198327c38b9a274041":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_adf2a17d826749438a74b4eeb050ed8e","placeholder":"​","style":"IPY_MODEL_267a440ce7b14ad49aec86f627b6af29","value":" 405M/405M [00:00&lt;00:00, 468MB/s]"}},"ee91a18ae6a449c192e8681ca5012107":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eed3fd84f2ce47aeb7192d35071893c3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2323fe279cd046b1bc75563a1cc8314a","IPY_MODEL_c76a85d2f842492ebbd6c350a23ea125","IPY_MODEL_ee3ad2d627ab49198327c38b9a274041"],"layout":"IPY_MODEL_5901207325ce46aeaf752a752127251a"}},"ef407fa0457e443192cc617cbe5e0f49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f06eef64926441e9be98abf6736527db":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0d9da7ab2a944d39f0f88f109499864":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f19ab356113b4926bd8f370f929cfc97":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1a604336e6642ac8d8576cce68103be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_749dd6dfa80948c58a6ebb241851d2aa","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_93ccf0d2022b465fb99d68dae70d4d68","value":404770755}},"f20ddfa75a3f4439aa794c1048e4e6f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_18b592fab0fb44c3aafc77ce68659f62","IPY_MODEL_8f6dbe64e5ae4eada01ed59a72163a3f","IPY_MODEL_d93464e84cc147169bbb2523d0794a5e"],"layout":"IPY_MODEL_51050ea48e534131aab846c44da12b50"}},"f26e617647ef4740bdb4df6ecacf12ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f28a2b6ce504415db8b90671da5259f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2991dc06b0649488805508d7c4ab514":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f3ff3ee545b471f9983cee836361061","placeholder":"​","style":"IPY_MODEL_2d2db084ba374a6aa25305b394c5ca6d","value":"Downloading (…)l-00001-of-00033.bin: 100%"}},"f58400974faf4296b83b6392b7c08bca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f59330d0c0434aac8820e38c010be4e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5d677b263e44a5691cc69806ba7b2b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f65d31b8674b4050867b8e8eee3125f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f6ddc9d7ab304ac4a1da614f6c129ffa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6fb4431bb3d4ce88aaa987de311d74b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f74e733ce2964fa79643b7ae2d7cb9dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_62f5e6d2df744773bfd1d38f8bc8726f","IPY_MODEL_ff585de9a9c745e5a7b9c3e93e25e1d8","IPY_MODEL_d7251ab77c64462087ea4b645d16b7ae"],"layout":"IPY_MODEL_7369b61e99d94034a8c84f6b51496584"}},"f74fe44e1bb341809436acbb5e5abc8c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7cab19974bd4cbf86e5fcf3b571b3ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8a7a2b0f1084f9c9b0295ff697832bf":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa85c23f76ea415ba22dc00372d5b076":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fbd592116f7f4b8480e2f18a3b2b9cb4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fccc9f29b16b4eab9c57a26141bf564e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d3d457757854832be472bbc42e2d00c","placeholder":"​","style":"IPY_MODEL_59269357b6644033b7a55afd4225543b","value":"Downloading (…)l-00026-of-00033.bin: 100%"}},"fd4b7c0f6eaf44418df7a5ca7f627d00":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdada141380a42f69a83f2c86301a833":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fdb2016f20c247eeaaedbea0c98e57a0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdbba0bd6a194816b6750772a886f211":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fdde59fcba0a4734b697d6eb5b0c7084":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe8126a27c9e4eed9d802043ec2bcd98":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6897df6af87c453c99902b732599a0db","placeholder":"​","style":"IPY_MODEL_d32f233ee3124d49945e71dbe71ed11d","value":" 405M/405M [00:00&lt;00:00, 453MB/s]"}},"feaf16c83b314035b4cfce3554ff5490":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8bebcc05ca254a5c8e81081c67bdba1e","placeholder":"​","style":"IPY_MODEL_d19e7998c9154fe7aa74c1dd0a5ac0e4","value":" 405M/405M [00:01&lt;00:00, 440MB/s]"}},"fec17c6b41894f63ab7bbb81d62657cb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd4b7c0f6eaf44418df7a5ca7f627d00","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9036bd5283d14584822543a779408dbb","value":404770755}},"ff39181bdd104a7e8a6e447e8996dc64":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff585de9a9c745e5a7b9c3e93e25e1d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c80b2dbd26c4f5d8b36312032c9423e","max":404770755,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6324ffc664b54a92817c0b9e53855ada","value":404770755}},"ff5b01bd39f24d96aac95835fab709f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dfbc96b7a92b45f380229d13b7817ce6","IPY_MODEL_c4bdf3a1d07048d6adb32d88bdd0dcf4","IPY_MODEL_fe8126a27c9e4eed9d802043ec2bcd98"],"layout":"IPY_MODEL_57faa31bb00d4b0881ba092167024be5"}}}}},"nbformat":4,"nbformat_minor":0}
